    
    Note also that the number of Li’s direct ties (6) is barely above average, but he is 17th in terms of closeness centrality among those young enough to be eligible for the Politburo. He may owe his advancement less to specific direct ties, but to his central position relatively close to several patrons in the network, as seen in figure 7.
 

 Social Network Analysis (Class 4)
  Gregory M. Eirich QMSS
  1. It’s not all social science stuff ...
  George Costanza
Let’s test the Independent George hypothesis
  
  The Independent George hypothesis
George Costanza: Ah you have no idea of the magnitude of this thing. If she [his fiancee] is allowed to infiltrate this world, then George Costanza as you know him, Ceases to Exist! You see, right now, I have Relationship George, but there is also Independent George. That's the George you know, the George you grew up with - Movie George, Coffee shop George, Liar George, Bawdy George.
Jerry Seinfeld: I, I love that George.
George Costanza: Me Too! And he's Dying Jerry! If Relationship George walks through this door, he will Kill Independent George! A George, divided against itself, Cannot Stand! -- "Seinfeld: The Pool Guy (#7.8)" (1995)
 
  Formalizing this hypothesis ...
 If a person’s spouse is more densely connected to the other intimate people in that person’s network, then that person will be less happy
 The person will not be able to maintain an Independent George and a Relationship George
 
  Sorry! All of this is in STATA
  Step #1 - Find the spouse
set mem 550m
set maxvar 7000
use "mypath\gss-combined-no-NAs.dta" aorder
/// let’s find out what number person the spouse is ///
foreach var of varlist spouse1-spouse5 {
  recode `var' 1=1 2=0, gen( new`var' )
}
/// let’s assign that number to the spouse ///
gen numspouse1=1*newspouse1
gen numspouse2=2*newspouse2
gen numspouse3=3*newspouse3
gen numspouse4=4*newspouse4
gen numspouse5=5*newspouse5
  
  Interesting tidbit
Why would someone not choose a spouse as their Number One
network alter?
. tab spouse1, gen(sp1)
 person #1 is |
    rs spouse |      Freq.     Percent        Cum.
--------------+-----------------------------------
    mentioned |      1,738       33.02       33.02
not mentioned |      3,526       66.98      100.00
--------------+-----------------------------------
        Total |      5,264      100.00
  
  Interesting tidbit
Let’s just reverse the coding on marital happiness
ssc install vreverse
vreverse hapmar, gen(rhapmar)
. tab rhapmar
 happiness of |
     marriage |      Freq.     Percent        Cum.
--------------+-----------------------------------
                                                3.25
                                             40.21
                                            100.00
--------------+-----------------------------------
        Total |      4,738      100.00
not too happy |
 pretty happy |
   very happy |
  154
1,751
2,833
 3.25
36.96
59.79
  Interesting tidbit
A person very happy in their marriage is 31 percentage points more likely (on average) to name their spouse as Number One, compared to a very unhappily-married person
  . reg sp11 i.rhapmar if marital==1
      Source |       SS       df       MS
-------------+------------------------------
       Model |   11.832611     2  5.91630552
    Residual |  534.104194  2244  .238014347
-------------+------------------------------
       Total |  545.936805  2246  .243070706
Number of obs =    2247
F(  2,  2244) =   24.86
Prob > F      =  0.0000
R-squared     =  0.0217
Adj R-squared =  0.0208
Root MSE      =  .48787
------------------------------------------------------------------------------
        sp11 |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
     rhapmar |
          2  |   .1966606   .0615052     3.20   0.001     .0760476    .3172736
          3  |   .3137182   .0606484     5.17   0.000     .1947853     .432651
             |
       _cons |   .3235294   .0591626     5.47   0.000     .2075103    .4395485
------------------------------------------------------------------------------
  Step #2 - Find out how densely connected spouse is to others
 /// calculate spouse’s density vis-a-vis other alters ///
egen spclose1=rmean( rclose12 rclose13 rclose14 rclose15)
egen spclose2=rmean( rclose12  rclose23 rclose24 rclose25)
egen spclose3=rmean( rclose13  rclose23 rclose34 rclose35)
egen spclose4=rmean( rclose14  rclose24 rclose34 rclose45)
egen spclose5=rmean( rclose15  rclose25 rclose35 rclose45)
  Step #2 - Find out how densely connected spouse is-- cont’d
 /// only save spousal density if the Person Number is actually the
spouse’s ///
replace  spclose1=. if   numspouse1~=1
replace  spclose2=. if   numspouse2~=2
replace  spclose3=. if   numspouse3~=3
replace  spclose4=. if   numspouse4~=4
replace  spclose5=. if   numspouse5~=5
/// figure out a single spousal density for each respondent ///
 egen spcloseall=rmax( spclose1- spclose5)
  Now, testing our hypothesis
If someone’s spouse is more densely connected to the rest of their network, their log-odds of being in a higher category of happiness are slightly higher (B=0.0098, n.s.), net of network size
. ologit rhappy spcloseall numgiven
Ordered logistic regression                       Number of obs   =        489
                                                  LR chi2(2)      =       0.68
                                                  Prob > chi2     =     0.7106
Log likelihood =  -422.6612                       Pseudo R2       =     0.0008
------------------------------------------------------------------------------
      rhappy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
  spcloseall |   .0098044   .1787019     0.05   0.956     -.340445    .3600538
    numgiven |   .0611451   .0744636     0.82   0.412    -.0848008    .2070911
-------------+----------------------------------------------------------------
       /cut1 |  -2.368845   .5363297                     -3.420032   -1.317658
       /cut2 |    .871776   .5176185                     -.1427376     1.88629
------------------------------------------------------------------------------
  
  How about for men?
If a man’s wife is more densely connected to the rest of his network, his log-odds of being in a higher category of happiness are lowered (B=- 0.087, n.s.), net of network size
  . ologit rhappy spcloseall numgiven if sex==1
Ordered logistic regression
Log likelihood = -177.61757
Number of obs   =        213
LR chi2(2)      =       0.51
Prob > chi2     =     0.7746
Pseudo R2       =     0.0014
------------------------------------------------------------------------------
      rhappy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
  spcloseall |  -.0871426   .2669786    -0.33   0.744     -.610411    .4361258
    numgiven |   .0719523   .1121734     0.64   0.521    -.1479035     .291808
-------------+----------------------------------------------------------------
       /cut1 |  -2.752527   .8103226                      -4.34073   -1.164324
       /cut2 |   .7228247   .7689376                     -.7842652    2.229915
------------------------------------------------------------------------------
  How about for women?
If a woman’s husband is more densely connected to the rest of her network, her log-odds of being in a higher category of happiness are increased (B=+0.089, n.s.), net of network size
. ologit rhappy spcloseall numgiven if sex==2
Ordered logistic regression                       Number of obs   =        276
                                                  LR chi2(2)      =       0.42
                                                  Prob > chi2     =     0.8088
Log likelihood =  -244.3891                       Pseudo R2       =     0.0009
------------------------------------------------------------------------------
      rhappy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
  spcloseall |   .0889549   .2437269     0.36   0.715    -.3887411    .5666509
    numgiven |   .0515469   .0996862     0.52   0.605    -.1438345    .2469283
-------------+----------------------------------------------------------------
       /cut1 |  -2.080707   .7248625                     -3.501411   -.6600027
       /cut2 |    1.00042   .7070325                     -.3853388    2.386178
------------------------------------------------------------------------------
  
  We could push this further ...
 Maybe it is really only friends who need to be separated from spouses, so it is not all alters, but just non-kin
 Okay. I tried some of this, and it gets complicated fast (I have some code, poorly commented, if you want). The results mimic what we found here, though, anyway
 Feel free to explore this further :)
 
  2. Continuing from last week
  Why study ego networks?
 We usually are interested in one of the following things about people’s immediate social networks:
- How big are people’s social circles (size, or degree)?
- How closely-knit together is someone’s social circle (density)? - How strong are the connections within someone’s social circle (intensity, or valued density)?
- What kinds of people compose a person’s social circle (composition)?
 
  Question 4a
Do the characteristics of people’s social circles affect their own outcomes?
Or - If my social circle has (on average) higher education, does this increase my excitement with life?
 
 That will wait until lab for results to that question ...
 
  Another Question 4a
Do the characteristics of people’s social circles affect their own outcomes?
Or - If my social circle has more coworkers in it, does it correlate with higher job satisfaction?
 
  Excitement with life -
   The greater the proportion
of coworkers in one’s social circle, the more satisfied someone is at their job
  How did I do this?
gss$rsatjob=5-gss$satjob
reg1 <- lm(rsatjob ~ pctcw, data=gss)
plot(gss$pctcw, gss$rsatjob)
abline(reg1)
 
  Job satisfaction ...
These education levels are measured differently from
. tab educ1
      education |
       level of |
      person #1 |      Freq.     Percent        Cum.
   -------------+-----------------------------------
  1-6 years |
   7-9 years |
 10-12 years |
   h.s. grad |
some college |
asso. degree |
bach. degree |
grad or prof |
 25        1.04
116        4.82
275       11.42
760       31.56
400       16.61
134        5.56
401       16.65
297       12.33
1.04
 5.86
17.28
48.84
65.45
71.01
87.67
                                           100.00
-------------+-----------------------------------
Total |      2,408      100.00
  Job satisfaction ...
I have to calculate the percent of someone’s social network is made up of coworkers:
   > gss$cw1=ifelse(gss$cowork1==1,1,0)
   > gss$cw2=ifelse(gss$cowork2==1,1,0)
   > gss$cw3=ifelse(gss$cowork3==1,1,0)
   > gss$cw4=ifelse(gss$cowork4==1,1,0)
   > gss$cw5=ifelse(gss$cowork5==1,1,0)
   > cw = c("cw1", "cw2", "cw3", "cw4", "cw5")
   > gss$pctcw=rowMeans(gss[, cw], na.rm=TRUE)
   > summary(gss$pctcw)
      Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's
     0.000   0.000   0.000   0.132   0.200   1.000    5802
 
  We need a maximum occupational prestige score
  prestiges = c("prestige", "prestg80")
  sub <- gss[, prestiges]
  sub2=transform(sub, max=apply(sub,1, max, na.rm = TRUE))
  colnames(sub2)[3] <- "maxpr"
  gss <- data.frame(gss, sub2[,"maxpr"])
  colnames(gss)
  colnames(gss)[2118] <- "maxpr"
 
  Multivariate analyses ...
                                                     (rsatjob)
                              (1)                      (2)                       (3)
------------------------------------------------------------------------------------
 pctcw
numgiven
maxpr
pctcw:maxpr
0.122**
(0.051)
 0.013
(0.010)
 0.096*
 (0.051)
 -0.004
 (0.010)
0.006***
 (0.001)
 -0.276*
 (0.155)
 -0.006
 (0.010)
0.005***
 (0.001)
 0.009**
 (0.003)
------------------------------------------------------------------------------------
Observations                3,501                    3,485                     3,485
Adjusted R2                 0.002                    0.052                     0.052
------------------------------------------------------------------------------------
Note:                                                    *p<0.1; **p<0.05; ***p<0.01
  How did I do this?
lm1 = lm(rsatjob ~ pctcw + numgiven, gss, subset=maxpr>-1)
lm2 = lm(rsatjob ~ pctcw + numgiven + as.factor(year) + educ + age +
maxpr + as.factor(marital) + as.factor(race) + childs + sex, gss,
subset=maxpr>-1)
lm3 = lm(rsatjob ~ pctcw*maxpr + numgiven + as.factor(year) + educ +
age + as.factor(race) + childs + sex, gss, subset=maxpr>-1)
library(stargazer)
stargazer(lm1, lm2, lm3, type = "text")
 
  Multivariate analyses ...
Increasing the percentage of coworkers in one’s social circle from 0% to 100%, on average, increases someone’s satisfaction with their job by 0.12 points, net of degree, in Model 1
                                                     (rsatjob)
                              (1)                      (2)                       (3)
------------------------------------------------------------------------------------
  pctcw
numgiven
maxpr
pctcw:maxpr
0.122**
(0.051)
 0.013
(0.010)
 0.096*
 (0.051)
 -0.004
 (0.010)
0.006***
 (0.001)
 -0.276*
 (0.155)
 -0.006
 (0.010)
0.005***
 (0.001)
 0.009**
 (0.003)
------------------------------------------------------------------------------------
Observations                3,501                    3,485                     3,485
  Multivariate analyses ...
The effect of increasing the percentage of coworkers in one’s social
circle on job satisfaction is weakened somewhat when additional
controls are added to the model, in Model 2
                                                     (rsatjob)
                              (1)                      (2)                       (3)
------------------------------------------------------------------------------------
  pctcw
numgiven
maxpr
pctcw:maxpr
0.122**                  0.096*
(0.051)                  (0.051)
 0.013                   -0.004
(0.010)                  (0.010)
                        0.006***
                         (0.001)
 -0.276*
 (0.155)
 -0.006
 (0.010)
0.005***
 (0.001)
 0.009**
 (0.003)
------------------------------------------------------------------------------------
Observations                3,501                    3,485                     3,485
  Multivariate analyses ...
People’s job satisfaction increases even more and faster, if both the
percentage of their ego network is made up of coworkers and they
have a more prestigious job, net of other factors, in Model 3
                                                     (rsatjob)
                              (1)                      (2)                       (3)
------------------------------------------------------------------------------------
  pctcw
numgiven
maxpr
pctcw:maxpr
0.122**                  0.096*
(0.051)                  (0.051)
 0.013                   -0.004
(0.010)                  (0.010)
                        0.006***
                         (0.001)
 -0.276*
 (0.155)
 -0.006
 (0.010)
0.005***
 (0.001)
0.009**
                                                                              (0.003)
------------------------------------------------------------------------------------
Observations                3,501                    3,485                     3,485
  Interpreting continuous by continuous interactions
 Job_sat = 2.63 - 0.28*Pct_cw + 0.005*Prestige + 0.009 *Pct_cw*Prestige
Set Prestige=0, then:
Job_sat = 2.63 - 0.28*Pct_cw + 0.005*(0) + 0.009
*Pct_cw*(0)
Job_sat = 2.63 - 0.28*Pct_cw
 *
 Interpreting continuous by continuous interactions
If you plug in values for X2, then you can figure out both the intercept and slope for each line ...
    (c) Eirich 2012 *
  Interpreting continuous by continuous interactions
 Job_sat = 2.63 - 0.28*Pct_cw + 0.005*Prestige + 0.009 *Pct_cw*Prestige
Set Prestige=50, then:
Job_sat = 2.63 - 0.28*Pct_cw + 0.005*(50) + 0.009
*Pct_cw*(50)
Job_sat = 2.88 + 0.17*Pct_cw
 *
  Interpreting continuous by continuous interactions
 Job_sat = 2.63 - 0.28*Pct_cw + 0.005*Prestige + 0.009 *Pct_cw*Prestige
Set Prestige=100, then:
Job_sat = 2.63 - 0.28*Pct_cw + 0.005*(100) + 0.009
*Pct_cw*(100)
Job_sat = 3.13 + 0.72*Pct_cw
 *
  Interpreting continuous by continuous interactions
   When Prestige=0, Job_sat = 2.63 - 0.28*Pct_cw When Prestige=50, Job_sat = 2.88 + 0.17*Pct_cw When Prestige=100, Job_sat = 3.13 + 0.72*Pct_cw
  As Prestige increases, the intercept increases
As Prestige increases, the (c) Eirich 2012 slope increases too *
  
 Graphing this relationship
 *
  The code
visreg(lm3, "pctcw", by = "maxpr", breaks = c(0, 50, 100),  overlay=T, band =
F, partial = F, bty = "l", legend = F,  line = list(col = c("darkgreen",
"darkorchid","royalblue")))
legend("bottomright", paste("Prestige = ", c(0, 50, 100)), bty = "n", lwd = 2,
col = c("darkgreen", "darkorchid","royalblue"), cex = 0.8)
   (c) Eirich 2012 *
  But maybe there is more to it ...
Perhaps people who have lots of coworkers in their social circle are just happier in general ...
   (c) Eirich 2012 *
  Marital satisfaction ...
These education levels are measured differently from
. tab educ1
      education |
       level of |
      person #1 |      Freq.     Percent        Cum.
   -------------+-----------------------------------
  1-6 years |
   7-9 years |
 10-12 years |
   h.s. grad |
some college |
asso. degree |
bach. degree |
grad or prof |
 25        1.04
116        4.82
275       11.42
760       31.56
400       16.61
134        5.56
401       16.65
297       12.33
1.04
 5.86
17.28
48.84
65.45
71.01
87.67
                                           100.00
-------------+-----------------------------------
Total |      2,408      100.00
  Multivariate analyses ...
--------------------------------------------------------------------------------------
 rsatjob
                       rhapmar
(2)                      (3)
                                (1)
--------------------------------------------------------------------------------------
pctcw
numgiven
maxpr
 0.091
(0.062)
 0.005
(0.013)
0.005***
(0.001)
-0.462**
(0.187)
 0.005
(0.013)
 0.003
(0.002)
 0.010
(0.044)
 0.009
(0.009)
 0.001
(0.001)
pctcw:maxpr
--------------------------------------------------------------------------------------
Married people only?
Observations
Adjusted R2
======================================================================================
Note:                                                      *p<0.1; **p<0.05; ***p<0.01
  Yes
1,971
0.046
   Yes
1,971
0.051
Yes 2,157
0.013***
(0.004)
0.025
  Multivariate analyses ...
Models 1 and 2 are the same models as before, just only for married people ...
--------------------------------------------------------------------------------------
  rsatjob
                       rhapmar
(2)                      (3)
                                (1)
--------------------------------------------------------------------------------------
pctcw
numgiven
maxpr
pctcw:maxpr
 0.091
(0.062)
 0.005
(0.013)
0.005***
(0.001)
-0.462**
(0.187)
 0.005
(0.013)
 0.003
(0.002)
0.013***
 0.010
(0.044)
 0.009
(0.009)
 0.001
(0.001)
                                                     (0.004)
--------------------------------------------------------------------------------------
Married people only?           Yes                       Yes                        Yes
Observations                 1,971                    1,971                    2,157
  Multivariate analyses ...
But in Model 3, we see that marital satisfaction does not have any relation to the percent of coworkers in someone’s social circle
--------------------------------------------------------------------------------------
  rsatjob
                       rhapmar
(2)                      (3)
                                (1)
--------------------------------------------------------------------------------------
pctcw
numgiven
maxpr
pctcw:maxpr
 0.091
(0.062)
 0.005
(0.013)
0.005***
(0.001)
-0.462**
(0.187)
 0.005
(0.013)
 0.003
(0.002)
0.013***
 0.010
(0.044)
 0.009
(0.009)
 0.001
(0.001)
                                                     (0.004)
--------------------------------------------------------------------------------------
Married people only?           Yes                       Yes                        Yes
Observations                 1,971                    1,971                    2,157
  How did I do this?
lm4 = lm(rsatjob ~ pctcw + numgiven + as.factor(year) + educ + age +
maxpr + as.factor(race) + childs + sex, gss, subset=maxpr>-1 &
marital==1)
lm5 = lm(rsatjob ~ pctcw*maxpr + numgiven + as.factor(year) + educ +
age + as.factor(race) + childs + sex, gss, subset=maxpr>-1 &
marital==1)
lm6 = lm(rhapmar ~ pctcw + numgiven + as.factor(year) + educ + age +
maxpr + as.factor(race) + childs + sex, gss, subset=maxpr>-1 &
marital==1)
stargazer(lm4, lm5, lm6, type = "text")
 
  The standard deviation of the ego network ...
 It is always important to look at the variability (or diversity, or inequality) on some variable within someone’s ego network
 For quantitative (continuous or continuous enough) variables, the standard deviation is the default/preferred measure of network diversity on that variable
 
  3. Diversity in social networks
  Question 4b
What determines the racial make-up of one’s social circle?
 
  How white is your social circle?
 There is a bit of regional variation in how white someone’s social circle is
 But the main predictor looks like one’s own race
  
  How did I do this?
foreach var of varlist race1-race5 {
  recode `var' 4=1 1/3 5=0, gen( new`var' )
}
egen pctwht=rmean( newrace1- newrace5)
recode region (1/2=1 "northeast") (3/4=2 "midwest") (5/7=3 "south")
(8/9=4 "west"), gen(bigreg)
graph hbar pctwht, over(bigreg) over(race)
  
  How white is your social circle?
 Huge racial segregation within people’s intimate social networks
  
  How did I do this?
foreach var of varlist race1-race5 {
  recode `var' 4=1 1/3 5=0, gen( new`var' )
}
egen pctwht=rmean( newrace1- newrace5)
  
  Measures of qualitative diversity
 The books advocate the index of qualitative variation to measure diversity on some categorical variable
 I prefer the Herfindahl–Hirschman Index, or HHI. It is calculated as the sum of the squares of the market shares of the groups under study, where their market shares are expressed as fractions.
 It can range from ~0 to 1
 
  HHI-
 Increases in the index generally indicate an increase in the concentration of one large group, while decrease indicate more equitable distribution of somewhat smaller groups
 The formula is:
where s 2 is the market share of group i i
      
  Watch me calculate the HHI for each ego net
   foreach var of varlist race1-race5 {
  recode `var' 4=1 1/3 5=0, gen( new`var' )
}
egen pctwht=rmean( newrace1- newrace5)
foreach var of varlist race1-race5 {
  recode `var' 1=1 2/5=0, gen( a`var' )
}
egen pctas=rmean( arace1- arace5)
foreach var of varlist race1-race5 {
  recode `var' 2=1 1 3/5=0, gen( b`var' )
}
egen pctbl=rmean( brace1- brace5)
foreach var of varlist race1-race5 {
  recode `var' 3=1 1/2 4/5=0, gen( h`var' )
}
egen pcthis=rmean( hrace1- hrace5)
foreach var of varlist race1-race5 {
  recode `var' 5=1 1/4=0, gen( o`var' )
}
egen pctoth=rmean( orace1- orace5)
gen hhi=pctwht^2 + pctas^2 + pctbl^2 + pcthis^2 +
pctoth^2
     
  How diverse is your social circle?
 Almost all races in all regions have very high HHIs
 Whites do have the most
segregated networks, but not by much
  
  How did I do this?
recode region (1/2=1 "northeast") (3/4=2 "midwest") (5/7=3 "south")
(8/9=4 "west"), gen(bigreg)
graph hbar hhi, over(bigreg) over(race)
 
  Compare to sex segregation
 All groups of people have lower HHIs on sex than with regard to race
 Married folks have the most gender- diverse ego networks
  
  How did I do this?
oreach var of varlist sex1-sex5 {
  recode `var' 1=1 2=0, gen( new`var' )
}
egen pctmale = rmean( newsex1-newsex5)
foreach var of varlist sex1-sex5 {
  recode `var' 1=0 2=1, gen( w`var' )
}
egen pctfe = rmean( wsex1-wsex5)
gen hhisex=pctmale^2+pctfe^2
recode marital (1=1 "married") (2/4=2 "once married") (5=3 "never married"), gen
(mar)
   ciplot hhisex, by(mar)
  4. Measures of cohesion
  Many measures of cohesion
 Homophily
 Reciprocity (directed)  Balance
 Transitivity
 
  Cohesion measure
 We want to measure how similar ego and their alters are - and how much they all know and like each other
 We already started this above, with our measures of density and diversity of ego’s social network
 We are going to continue that now
 
  But first ...
 A new dataset. Yay!
 A network study of a Northeastern corporate law firm in 1988-1991
 Emmanuel Lazega, The Collegial Phenomenon: The Social Mechanisms of Cooperation Among Peers in a Corporate Law Partnership, Oxford University Press (2001).
 
  The Lazega law data
 Information on 71 attorneys (partners and associates) of this firm
 Lawyer attributes include:
1. Status (1=partner; 2=associate)
2. Gender (1=man; 2=woman)
3. Office (1=Boston; 2=Hartford; 3=Providence)
4. Years with the firm
5. Age
6. Practice (1=litigation; 2=corporate)
7. Law school (1: Harvard or Yale; 2: UConn; 3: other)
 
  The Lazega law data
 Three (non-symmetric, binary)* social network matrices on these lawyers’ --
1. Co-worker relationships 2. Advice relationships
3. Friendship relationships
* “non-symmetric and binary” is the same as “valued and directed”
 
  1. The Lazega co-worker network
 "Because most firms like yours are also organized very informally, it is difficult to get a clear idea of how the members really work together. Think back over the past year, consider all the lawyers in your Firm. Would you go through this list and check the names of those with whom you have worked with.
 (By "worked with" I mean that you have spent time together on at least one case, that you have been assigned to the same case, that they read or used your work product or that you have read or used their work product; this includes professional work done within the Firm like Bar association work, administration, etc.)"
 
  2. The Lazega advice network
 "Think back over the past year, consider all the lawyers in your Firm. To whom did you go for basic professional advice? For instance, you want to make sure that you are handling a case right, making a proper decision, and you want to consult someone whose professional opinions are in general of great value to you. By advice I do not mean simply technical advice. Would you go through this list and check the names of those from whom you have sought advice."
 
  3. The Lazega friendship network
 "Would you go through this list, and check the names of those you socialize with outside work. You know their family, they know yours, for instance. I do not mean all the people you are simply on a friendly level with, or people you happen to meet at Firm functions."
 
  4. The Lazega valued network
 We can make a fourth social network matrix, which is valued and directed
 We do this by adding up the three other matrices together and putting them into a new one
 That means that values will range from 0 (no relationship on anything) to 3 (do everything together) for each lawyer and from each lawyer
 
  5. The dyad
  The dyad
 The simplest building block of social networks is a tie between two actors
 Often we want to know what makes a dyad form, what makes it continue and what makes it dissolve
 We will return to those questions, but for today, we will focus on another question ...
 
  Homophily
 We want to measure how similar ego and their alters are - and how much they all know and like each other
 We already started that last time with our measures of density and diversity
 We are going to continue that now ...
 
  Homophily
 Homophily refers to ego’s tendency to have alters who share ego’s attributes
 For example, we might measure the extent to which egos tend to have ties with alters of the same gender as themselves
 Homophily - or “birds of a feather flocking together” - is pretty ubiquitous in social networks
 
  Percent Homophilic: Gender
 Number of ties where ego and alter share an attribute, divided by ego's total number of ties
 In this case, it is only calculated on out-going ties on the friendship network (who ego thinks are friends, but perhaps not vice versa)
 . sum  EHFOPctHomophilous
     Variable |       Obs        Mean    Std. Dev.       Min        Max
 -------------+--------------------------------------------------------
 EHFOPctHom~s |        70    .6310893    .3273073          0          1
   
  % Homophilous on gender, by ID
 Partners (<ID36) maybe are a bit more homophilous on gender, maybe
   
  How did I do this?
scatter  EHFOPctHomophilous  , msymbol(circle_hollow) mlabel(IDC)
jitter(3)
 
  Gender proportions at the firm
 This is the baseline to work from
   
  How did I do this (in R)?
laz = read.csv(file.choose()) ## pick Lazega Attribute file ##
plot(prop.table(table(laz$gender)))
 
  % Homophilous, by gender
 Should we read this as good
news for these women? Bad news? Neither? Both?
   
  How did I do this?
graph box  EHFOPctHomophilous, over(GENDER)
 
  Percent Homophilic: Gender
 In this case, only on reciprocated ties on the friendship network (when both ego and alter nominate each other as friends)
 Only 57 egos have reciprocated friendships from work, vs. almost everybody (70 out of 71) who nominates someone
 . sum  EHFRPctHomophilous
     Variable |       Obs        Mean    Std. Dev.       Min        Max
 -------------+--------------------------------------------------------
 EHFRPctHom~s |        57    .6663052    .3550314          0          1
   
  % Homophilous on gender, by ID
 Women nominate more heterophilous people than who reciprocate back
 These two measures (for out- going and reciprocal ties) are correlated at 0.71
   
  How did I do this?
graph twoway (scatter EHFOPctHomophilous EHFRPctHomophilous if
GENDER==1, msymbol(Oh) mlabel(IDC) jitter(3)) ///
  (scatter EHFOPctHomophilous EHFRPctHomophilous if GENDER==2, msymbol
(S) mlabel(IDC) jitter(3)), ///
  legend(label(1 men) label(2 women))
 
  % Homophilous, by gender
 Same pattern as we saw on the
earlier graph ...
  
  How did I do this?
graph box  EHFOPctHomophilous  EHFRPctHomophilous, over(GENDER)
 
  Krackhardt and Stern E-I Index
 For each ego,
(E - I)/(E + I)
where E is number of ties to members in different groups (external), I is number of ties to members of same group (internal)
 Varies between -1 (homophily) and +1 (heterophily)
 
  The E-I Index
   The E-I Index is 100% correlated with the Pct_Homophilous measure
  A variety of other measures of
association
 Matches- This accounts for both the presence of homophilous ties and the absence of heterophilous ties divided by the total number of possible ties (n-1, where n is the number of nodes in the network specified by the input dataset).
 
  More measures of association
 Log Odds- This is the log of the odds ratio (OR) of homophilous behavior over heterophilous behavior, or the log of the simple cross-product ratio of a 2×2 table of traits. Cannot be calculated for perfect heterophily or perfect homophily because they approach infinite levels.
 Yules Q. Ranges from -1 for perfect heterophily to +1 for perfect homophily. A value of 0 means no pattern of homophily. Actually, Yule’s Q = (OR - 1)/(OR + 1)
 
  More measures of association
 Cohen’s Kappa. The measure of categorical agreement on the specified attribute for the ego with each alter. A value of 1 means complete agreement. A value of 0 means no more agreement than expected by chance.
 
  Last measures of association
 Correlation. This is a correlation between the presence or absence of a tie between ego and each alter in the network and a vector indicating ego and alter's similarity on the selected attribute. As a correlation, a value of +1 indicates perfect correlation (i.e., perfect homophily) and a value of -1 indicates a perfect negative correlation (i.e., perfect heterophily).
 
  Comparing the measures
Here is a listing from UCINET of all of the measures of dyadic similarity and difference
. sum  EHFOPctHomophilous EHFOEIIndex EHFOMatches EHFOYulesQ EHFOCohenKappa EHFOCorr_PBSC
EHFOfInGroup EHFOfOutGroup
    Variable |       Obs        Mean    Std. Dev.       Min        Max
-------------+--------------------------------------------------------
                                                            0          1
                                                         -1          1
                                                   .2142857         .8
                                                         -1          1
                                                   -.239145   .2449923
-------------+--------------------------------------------------------
EHFOCorr_P~C |        70    .0363686    .1707155  -.3759094   .3736257
EHFOPctHom~s |
 EHFOEIIndex |
 EHFOMatches |
70    .6310893
70   -.2621786
70    .4420408
70    .1490501
70     .022617
.3273073
.6546146
.1546841
  EHFOYulesQ |
EHFOCohenK~a |
 .583363
.0997215
  Comparing the measures
These various measures are often highly correlated; the lowest correlations (at least for our dataset) are with this “Matches” measure
. corr  EHFOPctHomophilous-  EHFOCorr_PBSC
(obs=70)
             | EHFOPc~s EHFOEI~x EHFOMa~s EHFOYu~Q EHFOCo~a EHFOCo~C
-------------+------------------------------------------------------
EHFOPctHom~s |   1.0000
 EHFOEIIndex |  -1.0000   1.0000
 EHFOMatches |  -0.3530   0.3530   1.0000
  EHFOYulesQ |   0.8339  -0.8339   0.0910   1.0000
EHFOCohenK~a |   0.6862  -0.6862   0.1934   0.8406   1.0000
EHFOCorr_P~C |   0.7619  -0.7619   0.2569   0.9493   0.9276   1.0000
  
  Reciprocity
 Another dynamic usually thought of as between a dyad (if I befriend you, you befriend me)
 But we will wait to calculate it with a whole network analysis, not ego
 
  BTW, gender homophily on Tuenti
 Volkovich, Yana, et al. "Gender patterns in a large online social network."Social Informatics. Springer International Publishing, 2014. 139-150.
 Tuenti is a Spanish social networking site (25% of Spain on it)
 Even more gender-balanced result for Facebook: See Ugander, Johan, et al. "The anatomy of the
facebook social graph." arXiv preprint arXiv:1111.4503 (2011).
   
  BTW, political homophily on Facebook
 Bakshy, Eytan, Solomon Messing, and Lada A. Adamic. "Exposure to ideologically diverse news and opinion on Facebook." Science 348.6239 (2015): 1130-1132.
  
  BTW, football homophily on Facebook
 Research at Facebook, “NFL Fan Friendships on Facebook”
    
  6. Sampling from whole networks?
  7- How to get homophily measures from whole networks in R
  #1- Get full network data
You want it to be a .csv file that has IDs along the top (as the first row), but no IDs as the first column
Like this
   
  #2- Get an attribute file too
This looks like a regular dataset or data-frame
   Like this
  #3- Load your full network into R
Do this:
 install.packages(“igraph”)
 library(igraph)
 ### import your Lazega Friend data ###
 test=read.csv(file.choose(),header=TRUE,row.names=NULL,check.names=FALSE)
 ### turn your dataframe into a matrix ###
 testm=as.matrix(test) # coerces the data set as a matrix ##
 ### makes your data into a sociomatrix ###
 ### “undirected” will put a maximum of 1 for both edges (A->B and B->A), if either edge
 has a 1; other options are available, including “directed”, “max”, “min”, etc ###
 testmg=graph.adjacency(testm,mode="undirected",weighted=NULL)
  
  #4- View your full network in R
Do this:
 > test
    1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28
  1 0 1
2 1 0
3 0 1
4 1 1
5 1 0
6 0 0
7 0 1
8 1 0
9 0 0
10 0 1 0 0 0 0 0 0 0  0  0  0  0  0  0  1  1  0  0  0  0  0  0  1  0  1  0  0
11 1 0 0 0 0 0 0 1 0  0  0  1  0  0  0  0  1  0  0  0  1  0  0  0  0  0  0  0
12 0 1 0 1 0 0 0 1 1  1  1  0  1  1  1  1  1  0  1  0  0  0  0  0  1  1  0  0
13 0 0 0 0 0 0 0 1 0  0  1  1  0  0  1  1  1  0  0  1  1  0  0  1  0  1  0  0
14 0 0 1 1 0 1 0 0 0  0  0  1  0  0  1  1  1  0  0  0  0  0  0  0  1  0  0  1
15 0 1 0 0 0 1 0 0 0  0  0  0  1  1  0  1  0  0  0  0  0  1  0  0  0  1  0  0
16 1 1 0 1 0 1 1 0 1  1  0  1  0  1  1  0  1  0  1  0  0  0  0  1  1  1  0  1
000 0000 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 000 1000 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 0 000 1000 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 100 1001 0 0 1 1 1 0 0 1 0 1 1 1 1 0 1 0 1 0 1 000 1000 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 000 0000 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 000 0000 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 000 0000 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 000 0000 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0
  #5- Load your attribute file into R and attach attributes to vertices
 ### import your attribute data ###
testatt=read.csv(file.choose(), header=TRUE) # see “Lazega-atts.csv” on Courseworks
### attach the attributes to the Vertices of the igraph ###
V(testmg)$name
V(testmg)$status=testatt$status[match(V(testmg)$name,testatt$ID)]
V(testmg)$gender=testatt$gender[match(V(testmg)$name,testatt$ID)]
V(testmg)$office=testatt$office[match(V(testmg)$name,testatt$ID)]
V(testmg)$seniority=testatt$seniority[match(V(testmg)$name,testatt$ID)]
V(testmg)$age=testatt$age[match(V(testmg)$name,testatt$ID)]
V(testmg)$practice=testatt$practice[match(V(testmg)$name,testatt$ID)]
V(testmg)$lawschool=testatt$lawschool[match(V(testmg)$name,testatt$ID)]
  #6- View your attribute file in R
Do this:
 > testatt
    ID status gender office seniority age practice lawschool
11 1 1 1 3164 1 1 22 1 1 1 3262 2 1 33 1 1 2 1367 1 1 44 1 1 1 3159 2 3 55 1 1 2 3159 1 2 66 1 1 2 2955 1 1 77 1 1 2 2963 2 3 88 1 1 1 2853 1 3 99 1 1 1 2553 2 1 10 10 1 1 1 25 53 2 3 11 11 1 1 1 23 50 1 1 12 12 1 1 1 24 52 2 2 13 13 1 1 1 22 57 1 2 14 14 1 1 2 1 56 2 1 15 15 1 1 3 21 48 2 3 16 16 1 1 1 20 46 2 1
  
  #7- Make an edge list to more easily calculate ego measures
 ### to create ego networks, this is the way to do it to capture attributes ###
 edge=get.edgelist(testmg)
 ### I need this package to turn my list into a dataframe ###
 require(devtools)
 source_gist(4676064)
 ### turn the list of an edgelist into a dataframe ###
 e = as.data.frame(edge)
 ### if you had brought your data in as “directed” this would be enough ###
 
  #8- View your edge list
>e
V1 V2
112 214 315 418 5 1 11 6 1 16 7 1 17 8 1 20 9 1 30 10 1 35 11 1 40 12 1 44 13 1 57 14 2 3 15 2 4 16 2 6 17 2 7 18 2 10 19 2 12
 20 2 15
  #9- Further organize your edge list, for merging and appending
 ### to capture the relationships in undirected ties, we have to have the edgelist again,
 but reverse the order of the pairs; this will give us all the edges for each ego network
 ... otherwise, we would have only had half of them ###
 e2 <- e[c(2,1)]
 library(plyr)
 ### rename the columns to reflect the reverse order ###
 e2 = rename(e2, c("V1"="V2", "V2"="V1"))
 ### append the 2 edgelists together via rbind ###
 mydata <- rbind(e, e2)
 ### rename columns of the edge list for later merging ###
 mydata = rename(mydata, c("V1"="ID1", "V2"="ID2"))
 
  #10- Apply attributes to alter and ego and then merge ...
 ### rename all the attributes to correspond with the pairs in the edgelist in ID1 ###
 id1 = testatt
 id1 = rename(id1, c("ID"="ID1", "status"="status1", "gender"="gender1", "office"="
 office1", "seniority"="seniority1", "age"="age1", "practice"="practice1", "lawschool"="
 lawschool1"))
 ### rename all the attributes to correspond with the pairs in the edgelist in ID2 ###
 id2 = testatt
 id2 = rename(id2, c("ID"="ID2", "status"="status2", "gender"="gender2", "office"="
 office2", "seniority"="seniority2", "age"="age2", "practice"="practice2", "lawschool"="
 lawschool2"))
 ### merge the ego and alter attributes together, first for ID1 and then ID2 ###
 all <- merge(mydata, id1, by=c("ID1"))
 all <- merge(all, id2, by=c("ID2"))
 
  #11- View your data-frame
Do this:
> all
ID2 ID1 status1 gender1 office1 seniority1 age1 practice1 lawschool1 status2 gender2 office2 seniority2 age2 practice2 lawschool2 homog homos
1 14 1 0 1 3159 2 3 1 0 1 3164 1 11 1 1 2 15 1 0 2 3159 1 2 1 0 1 3164 1 21 1 1 3 116 1 0 1 2046 2 1 1 0 1 3164 1 31 1 1 4 117 1 0 1 2350 2 1 1 0 1 3164 1 41 1 1 5 18 1 0 1 2853 1 3 1 0 1 3164 1 51 1 1 6 12 1 0 1 3262 2 1 1 0 1 3164 1 61 1 1 7 140 2 0 1 634 1 1 1 0 1 3164 1 71 1 0 8 130 1 0 2 739 1 3 1 0 1 3164 1 81 1 1 9 111 1 0 1 2350 1 1 1 0 1 3164 1 91 1 1 10 157 2 1 1 333 1 2 1 0 1 3164 1 101 0 0 11 120 1 0 1 1949 1 1 1 0 1 3164 1 111 1 1 12 135 1 0 2 833 2 3 1 0 1 3164 1 121 1 1 13 144 2 1 3 553 2 1 1 0 1 3164 1 131 0 0 14 10 29 1 1 1 10 38 2 3 1 0 1 25 53 2 143 0 1 15 10 24 1 0 1 15 44 1 2 1 0 1 25 53 2 153 1 1
   
  #12- Make your homophily measures, for instance
 ### recode to reflect whether ego and alter share an attribute ###
 all$homog = ifelse(all$gender1==all$gender2, 1,0)
 all$homos = ifelse(all$status1==all$status2, 1,0)
 ### get an overall percentage by aggregated by ego's ID1 ###
 aggdata <-aggregate(all, by=list(all$ID1), FUN=mean, na.rm=TRUE)
 
  #13- Merge everything together
 ### rename column 1 to ID so it can be merged back into the big file ###
colnames(aggdata)[1] <- "ID"
### new <- data.frame(testatt, aggdata)
### merge all of the data back together ###
aggdatanew <- merge(aggdata, testatt, by=c("ID"))
  #14- View your data-frame
 Do this:
  > aggdatanew ID ID2 ID1 11NANA
2 10NANA
3 11NANA
4 12NANA
5 13NANA
6 14NANA
7 15NANA
8 16NANA
9 17NANA
10 18NANA
11 19NANA
12 2NANA
13 20NANA
14 21NANA
15 22NANA
status1 gender1 office1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 2 1 0 3 1 0 1 1 0 1 1 0 2 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1
seniority1 age1 practice1 31 64 1 25 53 2 23 50 1 24 52 2 22 57 1 156 2 21 48 2 20 46 2 23 50 2 18 45 1 19 46 2 32 62 2 19 49 1 17 43 1 949 1
lawschool1 status2 1 1.230769 3 1.153846 1 1.285714 2 1.153846 2 1.466667 1 1.263158 3 1.000000 1 1.285714 1 1.303030 2 1.333333 1 1.111111 1 1.173913 1 1.266667 2 1.368421 3 1.086957
gender2 office2 seniority2 0.15384615 1.384615 18.153846 0.15384615 1.384615 15.230769 0.19047619 1.285714 14.142857 0.15384615 1.423077 14.961538 0.26666667 1.300000 11.066667 0.21052632 1.578947 12.947368 0.16666667 1.333333 15.416667 0.17142857 1.428571 13.942857 0.27272727 1.242424 13.666667 0.22222222 1.777778 12.888889 0.00000000 1.111111 20.444444 0.13043478 1.434783 16.217391 0.06666667 1.200000 15.066667 0.36842105 1.315789 10.473684 0.08695652 1.347826 15.826087
age2 practice2 47.69231 1.461538 44.07692 1.692308 44.66667 1.380952 45.53846 1.576923 41.23333 1.433333 44.57895 1.578947 47.00000 1.500000 45.20000 1.628571 45.81818 1.515152 44.44444 1.111111 49.77778 1.666667 46.78261 1.565217 44.53333 1.466667 41.89474 1.473684 47.69565 1.565217
lawschool2
1 1.769231
2 2.230769
3 2.142857
4 2.153846
5 2.066667
6 2.157895
7 2.083333
8 2.171429
9 1.969697
10 2.000000
11 2.222222
12 1.956522
13 2.000000
14 2.263158
15 1.956522
homog 0.84615385 0.84615385 0.80952381 0.84615385 0.73333333 0.78947368 0.83333333 0.82857143 0.72727273 0.77777778 1.00000000 0.86956522 0.93333333 0.63157895 0.91304348
homos 0.7692308 0.8461538 0.7142857 0.8461538 0.5333333 0.7368421 1.0000000 0.7142857 0.6969697 0.6666667 0.8888889 0.8260870 0.7333333 0.6315789 0.9130435
status gender 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0
offic
  #15- Run a model
Women have 47%-age points less homophily on gender than do men at the law firm, on average
  ### run a model with these variables ###
  summary(lm(homog ~ gender, aggdatanew))
  Coefficients:
              Estimate Std. Error t value Pr(>|t|)
  (Intercept)  0.72055    0.02776  25.960  < 2e-16 ***
  gender      -0.47844    0.05513  -8.679 1.15e-12 ***
  ---
  Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
  Residual standard error: 0.2021 on 69 degrees of freedom
  Multiple R-squared:  0.5219,  Adjusted R-squared:  0.515
  F-statistic: 75.33 on 1 and 69 DF,  p-value: 1.147e-12
  
  #16- Add other ego network measures in, like degree
 ### calculate degree, ego network size, like this ###
 V(testmg)$degree <- degree(testmg)
 ### do this to get degree attached to the big file ###
 dd <-data.frame(ID = V(testmg)$name)
 cb1 <- cbind(dd, V(testmg)$degree)
 aggdatanew2 <- merge(aggdata, cb1, by=c("ID"))
 
  #17- Run a model, including degree
Women have only 12.7%-age points less homophily on gender than do men at the law firm, on average, once we control for degree
 ### run a model with these variables ###
 summary(lm(homog ~ gender + V(testmg)$degree, aggdatanew2))
 Coefficients:
                   Estimate Std. Error t value Pr(>|t|)
 (Intercept)       0.520660   0.075310   6.914 2.03e-09 ***
 gender           -0.127013   0.077066  -1.648   0.1039
 V(testmg)$degree  0.007036   0.004010   1.755   0.0838 .
 ---
 Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
 Residual standard error: 0.2817 on 68 degrees of freedom
 Multiple R-squared:  0.08438, Adjusted R-squared:  0.05744
 F-statistic: 3.133 on 2 and 68 DF,  p-value: 0.04993
  
  #18- Add other ego network measures in, like density
 ### calculate density of ego network ###
 dens = data.frame( transitivity=transitivity(testmg, type="local") )
 ### do this to get density added into the file ###
 dd <-data.frame(ID = V(testmg)$name)
 cb2 <- cbind(dd, dens)
 aggdatanew3 <- merge(aggdatanew2, cb2, by=c("ID"))
 
  #19- Run a model, including density (i.e., local transitivity)
Going from no ego network density (0) to complete network density (1),
homophily on gender is predicted to increase 65%-age points on average, net
of other factors
  ### run a model to see if this worked ###
  summary(lm(homog ~ gender + V(testmg)$degree + transitivity, aggdatanew3))
                    Estimate Std. Error t value Pr(>|t|)
  (Intercept)       0.316994   0.119896   2.644   0.0103 *
  gender           -0.074771   0.074439  -1.004   0.3189
  V(testmg)$degree  0.004153   0.003828   1.085   0.2819
  transitivity      0.656274   0.264710   2.479   0.0158 *
  ---
  Residual standard error: 0.2604 on 65 degrees of freedom
    (2 observations deleted due to missingness)
  Multiple R-squared:  0.1451,  Adjusted R-squared:  0.1057
  F-statistic: 3.678 on 3 and 65 DF,  p-value: 0.01642
  
  #20- View your final data-frame
Some early stuff omitted, but here are the final columns:
    lawschool2      homog     homos V(testmg)$degree transitivity
  1    1.769231 0.84615385 0.7692308
2    2.230769 0.84615385 0.8461538
3    2.142857 0.80952381 0.7142857
4    2.153846 0.84615385 0.8461538
5    2.066667 0.73333333 0.5333333
6    2.157895 0.78947368 0.7368421
7    2.083333 0.83333333 1.0000000
8    2.171429 0.82857143 0.7142857
9    1.969697 0.72727273 0.6969697
10   2.000000 0.77777778 0.6666667
11   2.222222 1.00000000 0.8888889
12   1.956522 0.86956522 0.8260870
13   2.000000 0.93333333 0.7333333
14   2.263158 0.63157895 0.6315789
15   1.956522 0.91304348 0.9130435
13    0.5000000
13    0.5769231
21    0.4666667
26    0.4461538
30    0.3701149
19    0.4736842
12    0.6060606
35    0.3260504
33    0.3806818
9 0.4166667
 9    0.6666667
23    0.4189723
15    0.5523810
19    0.5087719
23    0.3992095
  7. Triads
  Triads
 This is where things get really interesting- coalitions, splintering, tertius gaudens (the third rejoices [by being in the middle]), divide and conquer, etc.
 Let me tell you about Georg Simmel on the “non-uniqueness” of triads vs. dyads
 Almost everything about a whole network you can figure out from a census of its triads
 
  Cohesion
 Homophily
 Reciprocity (directed)
  Usually applies to triads:  Balance
 Transitivity
  Triad census I
 All undirected triads can be characterized into 4 types (depending on the number of ties within the triad):
1. no ties (and lots of these suggests a global network full of isolates)
2. one tie (and lots of these suggests a global network full of paired- off people)
  
  Triad census I- contintued
 All undirected triads can be characterized into 4 types (depending on the number of ties within the triad)- continued:
3. two ties (and lots of these suggests a global network full of structural holes-- and more on that shortly)
4. three ties (and lots of these suggests a global network full of big cohesive groups-- and more on that in a couple of weeks)
  
  Triad census II
 All directed triads can be characterized into 16 types, depending on the number of M.A.N. ties, where M=mutual, A=asymmetric, and N=null:
 For example, a 003 triad is one where none of the 3 nodes is tied to any of the other two nodes, while a 300 triad is one where all 3 nodes are connected to the other two
 These reflect the full range of group configurations (in miniature): hierarchy, equality, coalition (exclusivity) and brokerage
  
  Transivity
 If A likes B and B likes C, then it is likely that A likes C too
 Just like with reciprocity (for dyads), transitivity (within triads) can be calculated for the whole network too, and that is where we will deal with it more
 
  Balance
 A person’s psychological (conscious or not) desire to have equilibrium among their friends
 Extended with the idea of cognitive dissonance, where people had trouble keeping things straight in their minds relationships that were not transitive
 
  The anti-balance argument
 Many social scientists have considered whether it is nonetheless beneficial in other ways to resist balance in a variety of relationships, but especially professional ones
 Burt incessantly highlights this especially (and maybe Granovetter too)
 That leads naturally to discussions of competition ...
 

 Social Network Analysis (Class 2)
  Gregory M. Eirich QMSS
  The basics: Nodes
 Also known as vertices=points=agents=actors
 They can be people, employees, students, companies, countries, words, events, occasions, associations ... and so on.
 
  Boundaries on the nodes
 How do we determine what is the set of nodes who could potentially be connected together? --Theoretically, the list could go on forever ...
 Many strategies exist to determine a stopping rule for choosing sets of nodes
 
  1. Nominalist approach
 The most common approach is usually a nominalist strategy
 The analyst chooses a priori an inclusion rule into the network for nodes
 Example: All students who are in 7th grade. --Vickers, M. & S. Chan. 1981. Representing Classroom Social Structure. Melbourne: Victoria Institute of Secondary Education.
  
  The 7th-graders ...
 The data were collected by Vickers from 29 7th-grade students in a school in Victoria, Australia
 Students were asked to check off from the list of their classmates:
○ Who do you get on with in the class?
○ Who are your best friends in the class?
○ Who would you prefer to work with?
 
  The 7th-graders ...
 What is the benefit of choosing nodes based on nominalist criteria?
 
  The 7th-graders ...
 What is the benefit of choosing nodes based on nominalist criteria?
- It is a category that has some reality for everyone, usually
- People’s lives may be actively (knowingly or not) structured around these categories; e.g., easy to know other 7th-graders
- These categories often bound people in space and time
 
  The 7th-graders ...
 What are the drawbacks of choosing nodes in this nominalist way?
 
  The 7th-graders ...
 What are the drawbacks of choosing nodes in this nominalist way?
- It may not be how the participants themselves see their connections to others
- It might miss lots of people who are important to our focal population (e.g., 8th-graders, siblings in different grades, kids from neighborhood and other schools, etc.)
- It is an artificial boundary, not organically discovered
 
  ~1. Nominalist approach
 Another name for the nominalist approach is a positional strategy
 The analyst determines a network boundary based on certain attributes of the actors, their memberships in formal organizations or their occupancy of a well-defined position
 Classic example: CEOs (positions) of Fortune 500 companies (formal organizations)
 
  You know it is a nominalist ...
 ... if you have the whole list of the network from Day 1
 
  2. Realist approach
 This is a less common approach
 The analyst asks the various actors to define who is a relevant possible member of their field
 Example: Rosengren, K. E. (1968). Sociological Aspects of the Literary System. Stockholm: Natur och Culture.
 
  Literary critics “nominating”
 Rosengren collected data on Swedish literary critics writing during the stylistic revolution in Swedish literature in 1881 to 1883
 He recorded sets of authors, other than the author being reviewed, who were mentioned together in any published literary review in the Swedish press during those years
 
  Literary critics “nominating”
 He then dropped any pairs that were mentioned together less than five times and he included only those pairs of authors whose proportion of co-mentions was more than three standard errors above its expectation.
 By the way: this is also a form of a co-citation network, which we will deal with later as well
 
  The literary landscape ...
  Classical Swedish romantic poets (right) and the modern Scandenavian novelists (left), connected by Goethe and Shakespeare (of all people!)
  One more thing ...
 From a fully realist approach, Rosengren should not have dropped any co-cited authors, which allows the network to be much more organic, have more components and almost-isolates (more like a true network). But you get the idea ...
 
  2. Realist approach
 What is the benefit of choosing nodes based on realist criteria?
 
  2. Realist approach
 What is the benefit of choosing nodes based on realist criteria?
- Who is included is based on who is actually involved in the network
- This should essentially correspond with people’s lived interactions and relationships
- Captures peripheral relationships too
 
  2. Realist approach
 What are the drawbacks of choosing nodes based on realist criteria?
 
  2. Realist approach
 What are the drawbacks of choosing nodes based on realist criteria?
- This approach is contingent on having a representative set of informants on the network as a whole
- Analyst must still make determinations if actors are in or out (what if only one person nominates someone? what if another person explicitly says another node does not fit?)
 - A lot more work to follow all the leads
  ~2. Realist approach
 A classic form of realist inclusion is snowball sampling
 The analyst starts somewhere (anywhere) and then follows all those nodes connected to (or nominated by) the original source, building a bigger always-connected sample as it goes
 Example-- Rosenfeld, Richard, Timothy M. Bray, & Arlen Egley. “Facilitating violence: A comparison of gang-motivated, gang- affiliated, and nongang youth homicides.” Journal of Quantitative Criminology 15.4 (1999): 495-516.
 
  The snowball approach
 In the 1990s, Rick Rosenfeld and Norm White used police records to collect data on crime in St. Louis
 They began with 5 homicides and recorded the names of all the individuals who had been involved as victims, suspects or witnesses
 They then explored the files and recorded all the other crimes in which those same individuals appeared
 
  The snowball approach
 This snowball process was continued until they had data on 557 crime events
 Those 557 events involved 870 participants of which:
○ 569 appeared as victims
○ 682 appeared as suspects
○ 195 appeared as witnesses
○ 41 were dual (they were recorded both as victims and suspects in the same crime)
 
  You know you are a realist ...
 ... if you have the whole list only on the last day
 
  3. Event approach
 Including and linking nodes based on appearing at the same time and/or same place
 Example-- Co-appearance of Les Miserables characteristics in chapters of the book
 
  Les Mis characters ...
 Weighted network of co-appearances of characters in Les
Miserables
 Nodes represent characters
 Edges connect any pair of characters that appear in the same chapter of the book
 The edges have values indicating the number of times each pair of characters coappear
 
  Les Mis characters ...
 Altogether it looks like this
 This graph was made in Gelphi
  
  Les Mis characters ...
     
  3. Event approach
 What is the benefit of choosing nodes based on an event-based criteria?
 
  3. Event approach
 What is the benefit of choosing nodes based on an event-based criteria?
- This approach relies on actual actor behavior; they have to do something to enter the dataset -- attend an event
- Ties should represent some level of actual interaction
 
  3. Event approach
 What are the drawbacks of choosing nodes based on an event- based criteria?
 
  3. Event approach
 What are the drawbacks of choosing nodes based on an event- based criteria?
- This approach could be prone to bias and error due to the stochastic nature of event attendance, especially if only a few events are analyzed
- Event attendance may still not represent very strong ties between different people
 
  The basics: Ties
 Also known as edges=arcs(if directed)=links=lines
 What counts as a connection between nodes?
 
  The basics: Ties
 What counts as a connection between nodes?
1. Behavioral interactions: e.g., talking to each other; sending messages; sending money
2. Physical (geographic) connection: e.g., sitting together in the same office; living in the same neighborhood
3. Association or affiliation: e.g., taking the same courses; belonging to the same division; attending the same events
 
  The basics: Ties
 What counts as a connection between nodes?--continued
4. Emotional evaluation of one person by another: e.g., considering someone a friend or enemy; sponsoring someone
5. Formal relations: e.g., who is someone’s boss; who is someone’s parent
6. Other miscellaneous: ... Your ideas here!
 
  The basics: How to measure ties
 There are two main types of ties:
Undirected vs. directed ties
Valued vs. unvalued ties
 
  Directed ties
 Directed ties capture the direction of the relationship, with a “sender” and a “receiver”
 Can be done through observation, but usually through nominations
 Example-- High school. Oh, high school! Harris Udry (1994-5). Adolescent health networks from Longitudinal Survey of Adolescent Health.
 
  Directed ties - High school
 90,118 students representing 84 communities took this survey in 1994-95
 Each student was given a paper-and-pencil questionnaire and a copy of a roster listing every student in the school
 The name generator asked about five male and five female friends separately. The question was, "List your closest friends. List your best friend first, then your next best friend, and so on. You can list your girl- or boyfriends too.”
 
  Directed ties - High school
 For each friend named, the student was asked to check off whether he/she participated in each of five activities with the friend:
1. went to (his/her) house in the last seven days.
2. met (him/her) after school to hang out or go somewhere in the last seven days.
3. spent time with (him/her) last weekend.
4. talked with (him/her) about a problem in the last seven days. 5. talked with (him/her) on the telephone in the last seven days.
 
  Directed ties - High school
 On average, a kid will be nominated as a friend by 1.4% of the school
 But the maximum is someone named as a friend by over 58%(!) of all students (Joshua M. Hill. 2012. “The Effects of Social Networking Skills on Labor Market Outcomes.” Working paper.)
 Anywhere from 8% to 30% of students are isolates -- meaning they have no nominations at all
 
  Undirected ties
 It just notes that two nodes are linked (1=yes; 0=no), but does not have a direction associated with the tie
 Any directed network can be transformed into an undirected one, but not vice versa
 
  Valued ties
 Valued ties capture the strength of the relationship, ranging from weak connections to very intense ones
 Think again about the high school example-- Harris Udry (1994- 5). Adolescent health networks from Longitudinal Survey of Adolescent Health.
 
  Valued ties - High school
 Each student was asked to check off whether he/she participated in up to five activities with their friend
 So the strength of the tie could be how many of those 5 things the student said they did, ranging from 0 to 5
 The more of those things they did together, maybe the stronger their relationship is
 
  Valued ties - Other examples?
  Unvalued ties - High school
 In contrast, an unvalued tie just lists that a tie exists (yes=1, no=0), not how strong the tie is
 Again, from the high school example, this would mean just establishing a tie (directed or undirected) based on whether the student listed somebody as a friend, but not tied (no pun intended) to having done anything with them in the last week
 Unvalued ties are obviously coarser indicators of relationships
 
  The basics: Groups
 Nodes+ties=groups
1. The simplest groups is the dyad: one node connected to another node (--it can be directed or undirected)
2. Then the next smallest group is a triad: one node connected to two other nodes (who may or may not also be connected) ... we will have much more to say about triads-- my personal favorite for studying structural holes and brokerage
 
  The basics: Groups
 Nodes+lines=groups
3. A group is frequently larger than 2 or 3 nodes. It is defined by many overlapping relations among nodes.
They can be known as clusters, cliques, clubs, sub-groups, communities, modules, complexes, components.
 
  The basics: Groups
 The basic idea is that groups share lots of ties within themselves and not so many between other groups
 The trick is how many ties need to not exist between groups and how many ties do need to exist within groups
 There are many algorithms designed to figure this question out
  
  An easy one ...
 The network structure of political blogs prior to the 2004 U.S. Presidential election
 Here are 2 naturally well-separated
clusters
  
  Now, how many sub-groups here?
 Network of terrorists associated with September 11th attacks
  
  A couple of other points ...
  The social network perspective
Attributes vs. relations
 Attributes are things that are self-contained within the individual
 We do not need to refer to anyone else for those variables to have
meaning
 Typical of most social science (psychology and economics,
especially)
  
  The social network perspective
Attributes vs. relations
 Relations are inherently things that are shared among individuals
 This suggests that the value of an attribute can change depending
on its context
 Some relations are still analyzed vis-a-vis an individual as ego
 But other relations are more-or-less completely independent of
ego: instead, they refer to overall network properties or topography
  
  Graph theory
 Graph theory refers to the use of points and lines to illustrate relationships
 This is a formalized area of mathematics
 Mathematicians just call such thing graphs, while social scientists call their graphs “sociograms”
 
  Matrices
 Social networks can frequently be most easily represented as matrices
 Again, mathematicians just call them matrices, but social scientists call them “socio-matrices”
 They can be symmetric or not (i.e., directed or not), and valued or not
 
  BTW: Cognitive social network
 A mental map of who we think are related to each other
 E.g., Matthew Pittinsky (Co-Founder of Blackboard and Parchment)
 Dissertation: “Smart by (perceived) association: Cognitive social networks and teacher academic judgments” in 2010
 Measures teacher’s perceptions of friendship in her science classes, along with students’ own friendship patterns
 
  Cognitive social network (CSN)
 He finds that the teacher “balanced” her academic judgments among perceived friends later in the school year
 When the teacher perceived a student to be in a friendship group, her academic judgment of the perceived friendship group significantly influenced her judgment of the student, above and beyond the student's achieved and ascribed characteristics
 Our mental maps can matter too
 
  Social networks 0.0
  Social networks 0.0
 There is a fair bit of “social network” research that does not technically contain social network information (nodes, ties, groups)
 It is more like “proto” social network (specialized socializing) information - hence, my labeling them at the 0.0 level
 The thing is: A lot of this research is really good and super important for larger social network theorizing
 Exhibit A: Mark Granovetter’s Getting a Job (1974)
 
  What are social networks 0.0?
Narrow glimpses into some portion of the people someone knows and what they might do for them:
1. Size of total network: summation, “phone book” method
2. Size of sub-components: how many Xs do you know? Any?
3. For one moment/decision: e.g., getting a job; buying a car; finding
out about QMSS; how many people had sex with, etc.
4. One critical relationship: spouse, sibs, or kin
 
  #1. Size of the total network
 Summation method: Respondents are asked how many people they know in a list of specific relationship types: e.g., immediate family, neighborhood, coworkers
 These responses are then summed to yield an overall total estimate
 One problem is that these relationship types often overlap so degree estimates suffer from double-counting
 
  Size of the total network
 Phone book method: Respondent was provided randomly selected pages from the phone book
 Based on the proportion of pages which contained the family name of someone known to respondent, you could estimate the respondent's social network size
 Now, they just provide lists of last names instead of a phone book
 
  #2. Size of sub-components
 Aggregated relational data (ARD) approach: Aka, “How many Xs do you know?”-- Most often used to estimate the size of populations that are difficult to count directly.
 Scale-up method: If the subpopulation size is known (people named Nicole, for example) we can estimate someone’s total network size
 Suppose that I know 2 persons named Nicole, and that there are 358,000 Nicoles out of 280 million Americans
 
  Size of sub-components
 Thus my two Nicoles represent a fraction (2/358,000) of all the Nicoles
 Extrapolating to the entire country yields an estimate of (2/358,000) × (280 million) = 1,560 people known by me
 We can figure out the size of unknown subpopulations by solving an equation for the unknown subpopulation size, using my estimated total network size: e.g., number of injection drug users, homeless or those with HIV/AIDS
 
   Any issues with this approach?
  Size of sub-components
 Network structure (in particular, clustering and homophily) make it hard to simply aggregate up in this Nicole way
 Other approaches (involving over-dispersion parameters) have been used, taking these factors into account
 
  How many Xs ...
  This is a multidimensionally- scaled graph of how certain knowings go together
 You can see clear (and not super surprising) clustering happening
 
  Extra: How overdispersion helps us
 Under random mixing, the “How many X's do you know?” questions should follow a Poisson distribution with a rate parameter determined by the respondent’s total network size and the proportion of ties that involve individuals in the subpopulation
 We would therefore expect the number of Rose's known by a respondent with degree equal to 500 would be 500×(500,000/280 million) ≈ 1.
 But most questions in the data did not follow a Poisson distribution, but are overdispersed, with greater-than-expected variance.
 
  Extra: How overdispersion helps us
 The overdispersion means that the frequency of people who know exactly one person of type X decreases, as compared to the frequency of people who know none.
 As overdispersion increases from its null value of 1, it is less likely for a person to have an isolated acquaintance from that group.
 
  Extra: How overdispersion helps us
 For example, consider the responses to the question: “How many
males do you know incarcerated in state or federal prison?”
 The mean of the responses to this question was 1.0, but the variance was 8.0, indicating that some people are much more likely to know more than one individual in prison than others.
 To model this increased variance Zheng, Salganik, and Gelman (2006) allowed individuals to vary in their propensity to form ties to different groups.
 
  Extra: How overdispersion helps us
 In a multilevel model, this corresponds to assuming that these individual propensities to connect with different groups follow a gamma distribution with a shape parameter determined by the overdispersion.
 
  Extra: How overdispersion helps us
 The responses then can be modeled as a negative binomial distribution so that the expected number of alters known by a respondent in a given subpopulation is the total size of the respondent’s network times the network prevalence, as under the simple model.
 But now the expected number of alters from a given subpopulation is scaled by the overdispersion parameter to estimate the variation in individual propensities to form ties to people in different groups.
 
  This comes from ...
  McCormick, T. H., and Zheng, T. (2013) “Network-based methods for
 accessing hard-to-reach populations using standard surveys.” In Hard-to-
 Survey Populations. Editors K. Wolter and R. Tourangeau
  #3. Getting a job ...
    This is the question that started it all
  For one moment/decision: a job
 Granovetter starts out with a decision* (to switch jobs) and then works out from there to figure out the social network that allowed that decision to happen
 We can only infer what someone’s whole network might look like
 Sparked a revolution in networks (over 30,000 cites now)
* BTW, lots of times, there was no search at all, but people were just asked to take new jobs
 
  For one moment/decision: a job
 Randomly sampled 282 recent professional, technical, and managerial job changers living in a Boston suburb in 1972
 Granovetter asked those who found a new job through contacts how often they saw the contact around the time that they passed on job information to them
 Of those finding a job through contacts, 16.7% reported that they saw their contact often at the time, 55.6% said occasionally, and 27.8% rarely (N=54).
 
  For one moment/decision: a job
 The paradox is that we might think that that our strong ties will be much more motivated to help with a job search, but our weak ties are much more likely to move in circles different from our own and information different from that which we normally receive.
 Granovetter’s results show the skew is clearly to the weak end of the tie continuum, suggesting the primacy of structure over motivation
 
  Really weak ties ...
 The weak ties were often really weak: In many cases, the contact was someone only marginally included in the current network of contacts, such as an old college friend or a former workmate or employer, with whom only sporadic contact had been maintained
 Usually such ties had not even been very strong when first forged
 
  Really weak ties ...
 For work-related ties, respondents almost invariably said that they never saw the person in a non-work context. Chance meetings or mutual friends operated to reactivate such ties.
 Granovetter notes that it is remarkable that people receive crucial information from individuals whose very existence they have forgotten
 Maintenance of weak ties may well be the most important consequence of specialist meetings and conventions
 
  Following the leads back ...
 Granovetter also asked respondents where their contacts got the information they transmitted
 He expected long paths of information. But in 39.1% of the cases information came directly from the prospective employer; 45.3% said that there was one intermediary between himself and the employer; 12.5% reported two; and 3.1% more than two (N =64).
 Job information does not need six degrees to get around: Friends of friends is usually (more than) enough
 
  #4. Important few in my network
 Sometimes we know about a couple of important people in my social network: e.g., spouse, sibs, or kin of other kinds
 Nicholas Christakis started his career as a network analysis by looking at spouses, specifically the effects of spousal death on survival chances of the widow or widower
 We often have information on people’s immediate family or kin, and this can tell us a lot
 
   That Christakis ...

  Social Network Analysis
 Gregory M. Eirich QMSS
 Social network analysis - A sampling
 
 1. From where great (or at least good) ideas come
 
  Examining structural holes
Burt, Ronald S. "Structural holes and good ideas." American journal of sociology 110.2 (2004): 349-399.
  
  His question
Does a person’s network position independently (and additionally) predict how good their ideas are?
 
  How he answered the question
 Started working at Raytheon (a large electronics company and military contractor based in Waltham, Mass.), where he was hired to help integrate a group of recent acquisitions.
 
  How he answered the question
 He asked managers to write down their best ideas about how to improve business operations (particularly around supply-chain management) and then he had two executives at the company rate their quality.
 Additionally, he surveyed all the managers to ask if they discussed their ideas with anyone else at Raytheon; also more generally, who the managers talk to around the company (-he generated what are called “ego networks”)
 
  A fragile (and siloed) network
  
  How he answered the question
 He needed a measure of network position for each manager. He measured how many “structural holes” each manager had, which are - well, it is complex, but ..., in essence - non- redundant ties that connect disparate social clusters.
 He operationalized “structual holes” as network constraint - Someone’s network is more constrained if it is small, or if a manager’s discussion partners talked a lot to one another directly (dense network), or if they shared information indirectly via a central contact (hierarchical network).
 
  What he found
 The highest-ranked ideas came from managers who had low network constraint. That is, they had lots of contacts outside their immediate work group. Their contacts span the gaps between discrete groups of people.
 They could be “brokers” of ideas new to unlike people. The trick is, these managers managed to get an idea which might have been somewhat mundane and well-known in one place and get it in front of people in another place who can get some value out of it.
 
   What he found
The less constrained manager’s have higher-rated ideas.
  
  What (else) he found
 Some managers had discussion partners in other groups (suggesting a diverse network) and so were positioned to spread good ideas across business units. But the people they cited for idea discussion were just colleagues already close in their informal discussion network. So their ideas were not developed any further.
 These managers should have had discussions outside their typical contacts, particularly with “an informal boss,” a person with enough power to be an ally but not an actual supervisor.
 
  By the way ...
 In a separate study, Burt conducted a field experiment at Raytheon. Results in - Burt, Ronald S., and Don Ronchi. “Teaching executives to see social capital: Results from a field experiment.” Social Science Research 36.3 (2007): 1156-1183.
 Burt and other University of Chicago Business School faculty spent 7 days over 6 months training executives to see social structure (holes and closure in social networks) and to know how to exploit those structures.
 
  By the way ...
 Results were: Compared to a control group of untrained, but otherwise equally able peers ... Program graduates are ~40% more likely to receive top performance evaluations, ~55% more likely to be promoted, and ~55% more likely to be retained by the company.
 See! Learning about social networks can improve your career prospects :)
 
  Recurring themes
 Importance of being “in between” and of not being “structural equivalent” to anyone else
 Focus on competitive advantages within networks
 
  Helpful review of Burt ...
Michael Erard. May 22, 2004. “THINK TANK; Where to Get a Good Idea: Steal It Outside Your Group.” The New York Times.
  
  2. Not all ties are advantageous
  Exploring guilt by association
Pontikes, Elizabeth, Giacomo Negro, and Hayagreeva Rao. "Stained Red: A Study of Stigma by Association to Blacklisted Artists during the “Red Scare” in Hollywood, 1945 to 1960." American Sociological Review 75.3 (2010): 456-478.
    
  Their question
What happens to the employment prospects of an actor after they have worked with someone who is later accused of being a Communist?
 
  How they answered the question
 Built a database of all actors and films in America (Hollywood) from 1945 to 1960, including information on whether the actors were blacklisted for being Communists. A total of 38,000 cast members in the database - and only 267 were officially blacklisted between 1945 and 1960.
 Ran a survival analysis (or event-history analysis) on continued employment.
 
  What they found
Mere association with a stigmatized colleague reduces an artist’s chances of working again and that one exposure is enough to impair work prospects. And the more exposures, the worse.
 
  Effects of “mere” association
  
  What (else) they found
 Working on a film itself is enough to generate guilt by association, even if the Communist is a writer and you are an actor, or vice versa. The film itself becomes a site of “contamination.”
 Said another way, individuals are harmed even if there is heterophily in mere association – that is, they work with dissimilar affiliates.
 
  What (else) they found
 Even elite actors were not immune from guilt by association. The negative effects of association with stigmatized co-workers hold even when the focal artist has won an Oscar or worked in box-office hits.
 Even high-status individuals can be stigmatized by mere association and their salience creates a “broadcast effect” (or example) to discourage others from engaging in deviant associations.
 
 Other examples of guilt by
association
 See: Other clients of Arthur Andersen after Enron collapse
 See: Exposure to communicable diseases like the flu
  
  3. Simulating “The Influentials”
  Making the world ...
Watts, Duncan J., and Peter Sheridan Dodds. "Influentials, networks, and public opinion formation." Journal of consumer research 34.4 (2007): 441-458.
   
  Their question
Is it true (as marketers think) that The Influentials — supposedly a minority of individuals who influence an exceptional number of their peers — are super important to the formation of public opinion?
 
 The classic “two-step” model
of diffusion
It looks like this ...
   
  How they answer their question
 They developed a computer simulation to see the impact of changing various parameters behind interpersonal influence processes.
 
  How they answer their question
 They programmed a group of 10,000 people, all governed by a few simple interpersonal rules. Each was able to communicate with anyone nearby. With every contact, each had a small probability of "infecting" another.
 Each person also paid attention to what was happening around him: If lots of other people were adopting a trend, he would be more likely to join, and vice versa.
 
  How they answer their question
 The people in the virtual society had varying amounts of sociability - some were more connected than others. Watts designated the top 10% most-connected as Influentials; they could affect 4 times as many people as the average person.
 Watts set the test in motion by randomly picking one person as a trendsetter, then sat back to see if the trend would spread. He did this thousands of times in a row.
 
  How they answer their question
 To stack the deck in favor of Influentials even more, Watts changed the simulation, making them 10 times more connected. Now they could infect 40 times more people than the average citizen.
 
  What they found
 The experiment (with 4x more influential Influentials) did produce several hundred society-wide infections.
 But in the large majority of cases, the cascade began with an average citizen anyway.
 That said, in cases where an Influential touched off the trend, it spread much further.
 
  What they found
 The experiment (with 40x more influential Influentials) also produced hundreds of society-wide infections.
 The rank-and-file citizen was still far more likely to start a contagion
 Again, when an Influential set off the cascade, it was substantially larger, so that is supportive of the Influentials idea
 
  The world is really like this ...
Radical equality of influence:
  
  Their explanation
 Why didn't the Influentials wield more power? With 40 times the reach of a normal person, why couldn't they kick-start a trend every time?
 A trend's success depends not on the person who starts it, but on how susceptible the society is overall to the trend - not how persuasive the early adopter is, but whether everyone else is easily persuaded.
 
  Their explanation
 With minor tweaks to the model (where everyone’s odds of being infected are increased a bit), the number of trends skyrocketed.
 
  Their conclusion
 Trends are more like forest fires: There are thousands a year, but only a few become roaring monsters.
 That's because in those rare situations, the landscape was ripe: sparse rain, dry woods, badly equipped fire departments.
 If these conditions exist, any old match will do. And nobody will go around talking about the exceptional properties of the spark that started the fire. - There are just “accidental” Influencers
 
  By the way ...
 Watts created the idea of “Big Seed” marketing campaigns.
 For the Brady Campaign to ban assault weapons, he set up a regular mass-market ad buy, running banner ads on several prominent blogs and news sites.
 Like many ads, they added a button on the ad that allows people to forward the ad to a friend - a way of collecting eyeballs for free. Typically, people ignore this "share with your friends" pitch.
 
  By the way ...
 But Watts included technology called ForwardTrack (product of Microsoft now, I think), which displays the route the ad travels once you've forwarded it. This turned ad forwarding into a piece of social cartography. People would pass the ad specifically to those friends most likely to keep it moving.
 The pass-around effect doubled the number of people who saw the Brady Campaign's ad. They paid for 22,582 hits and received an additional 31,590 for free. Also worked for Oxygen Network and Procter & Gamble
 
  Recurring themes
 Social networks allow for “emergent” and truly unpredictable outcomes to happen - allowing us to link the micro to the macro
 Sometimes simulations are the best way to see the implications of network topography and agent decision-rules on our ultimate results
 
  Helpful review of Watts ...
THOMPSON, CLIVE. February 2008. “IS THE TIPPING POINT TOAST?” Fast Company.
 
 4. Using meta-data (via bipartite graphs) to find key players
 
  Who is this Paul Revere character?
  
  While this is a blog post ...
 Healy does this analysis “tongue-in-cheek” but formal analyses largely confirm this “back-of-the-envelope” calculations.
 See: Han, Shin-Kap. "The Other Ride of Paul Revere: The Brokerage Role in the Making of the American Revolution." Mobilization: An International Quarterly 14.2 (2009): 143-162.
 
  His question
  Can analysts use mere “meta-data” - which does not include any of
 the content of communications - to to find the most essential
 persons involved in the American Revolution?
 Come out, Paul Revere, wherever you are ...
  
  How he answered the question

   He uses the database collected by historian David Hackett
 Fischer on 254 men’s memberships in 7 different Boston
 organizations prior to the Revolutionary war.
   It looks like this (an adjacency 254x7 matrix):
 
  How he answered the question

 And so on ...
   John Adams was a member of North Caucus and the Long
 Room Club, for instance.
   
  How he answered the question

   Healy takes that original matrix and transposes it - and then
 multiplies the two matrices together, producing a 254x254
 “Person by Person” matrix
   It looks like this:
 
  How he answered the question

   We now have a tally of how many groups each pair of individuals
 shares in common.
 
  How he answered the question

   Nathaniel Appleton and John Adams are connected through both
 being members of 1 group in common, while John Adams and
 Samuel Adams shared memberships in 2 groups. Gilbert Ash,
 meanwhile, was not connected through organization membership to
 any of the first four men on our list. ... and so on ...
 
  Who is right in the middle?
 Now he graphs that 254x254 bipartite matrix:
        
  Formalizing Revere’s centrality 1

   He calculates betweenness centrality for all the men, meaning
 roughly the number of “shortest paths” between any two people in
 our network that pass through the person of interest. It is a way of
 asking “If I have to get from person a to person z, how likely is it that
 the quickest way is through person x?” Here are the top scores:
  
  Formalizing Revere’s centrality 2

   Then he calculates everyone’s eigenvector centrality, which is a
 measure of centrality weighted by one’s connection to other central
 people. Here are our top scorers on that measure
  
  Formalizing Revere’s centrality 3

   Lastly, he calculates everyone’s Bonacich power centrality score,
 another (even) more sophisticated measure. Here the lower score
 indicates a more central location:
  
  What he found
 By almost any measure, Paul Revere would be the Most Wanted Man for the British to watch, based just on membership data alone
 
  Oh, here is all the R code for this
 
  By the way ...
 Healy has a wicked sense of humor and this whole exercise is done as a commentary on the NSA spying program.
 I am in no way endorsing any particular stance on the NSA or Healy’s take on it - to be clear.
 I will say, it is very clever writing, however.
 
  Recurring themes
 These two-way (or affiliation or bipartite) graphs are incredibly valuable ways to examine “The Duality of Persons and Groups.” (Breiger 1974)
 Can apply to many kinds of “associations” or “affiliations”
   
  5. Does power=centrality?
  Finding the most powerful cities
Neal, Zachary. “Differentiating centrality and power in the world city network.” Urban Studies 48.13 (2011): 2733-2748
  
  His question
Is all that makes a city powerful is that it is very central to the other cities in the world network?
 
  How he answers the question
 He starts by calculating the standard (degree) measure of centrality for cities, based on the network of Internet backbone connections among cities—the physical infrastructure that digitally links cities to one another. It is the capacity for information flow between pairs of cities, measured as megabits per second (Mbps) of bandwidth between them.
 For example, in this network, the bandwidth connection between New York and London is 96,599 Mbps while the connection between Manila and Jakarta is only 10 Mbps.
 
 The world city network when the idea is that centrality=power
 Bigger lettering indicates more
central cities; position on the Wordle is (sadly) non-informative
 Notice the centrality of
Singapore, Tokyo and LA
   
  How he answers the question
 He wants to consider if power≠centrality.
 He defines maximum (recursive) centrality as being at the center of other very central cities. That is, the central city is also most connected to other cities who themselves were also really connected to lots of other cities.
  
  How he answers the question
 That does seem like a lot of power because that increases its opportunities for concentration of resources from many sources (pull from lots of other cities quickly and easily) or the diffusion of resources to many sources rapidly (put out messages, trends or innovations to many other cities).
 
  How he answers the question
 But the problem is that while the central city has direct and indirect access to resources from a number of sources, so too do the cities to which it is connected.
 Thus, the focal city lacks the ability to control resource exchanges with its exchange partners. These partners have alternatives and thus they can ignore the actions or demands of the focal city.
  That is why such a city is not super powerful. It is replaceable.
  What if power≠centrality?
 Now, for power. Say another city has access to resources from a more limited pool of contacts (i.e. it is not recursively central).
 But it may have significant bargaining and negotiating influence over its exchange partners because it may be one of (or the only) sources for capital, information and other valuable commodities. These partners have no alternatives and thus cannot ignore the focal city’s demands. That is (recursive) power!
  
  What he found ...
 
  What he found: The world cities
 Yay! New York (#1) and London (#2-whatever) are the only cities that are really, truly both super central and super powerful. That is, they are connected to other highly-connected cities, but they are also the only main connection for otherwise not-so- connected cities. Everybody needs to have a lot of bandwidth with NYC.
 NYC is connected with all the other major cities, but is still irreplaceable too.
 
  What he found: Hub cities
 A second group of cities — Paris, Amsterdam, Washington, Brussels and Chicago — occupy highly central positions in the network, but do not occupy positions that afford them significant amounts of power.
 These cities are likely to be resource rich, with structural opportunities to accumulate and diffuse the commodities that flow through the network (in this case, information).
   
  What he found: Hub cities
 They are not, however, likely to have much influence over the flow of those resources elsewhere in the system and thus little ability to control the activities in other cities.
 They are likely sites of innovation because they benefit from the high concentrations of capital and the ability to disseminate new information. They are often centers of national (e.g., Paris, Washington) and transnational (e.g., Brussels) government - and can (from their central positions) efficiently communicate policy and diplomatic messages to wide audiences
 
  What he found: Gateway cities
 A third group of cities — Miami, Stockholm, San Francisco, Los Angeles and Tokyo — are the mirror image of hubs, occupying positions of power but not of centrality.
 These cities are likely to be highly influential, with structural opportunities to function as gatekeepers that can mediate or broker (at least some) other cities’ access to the resources flowing through the network.
   
  What he found: Gateway cities
 They are not, however, likely to be sites of significant resource concentrations or particularly effective at diffusing resources through the network.
 Such places are likely to be sites of instrumental and coordinative activities (for example, banking, advertising and consulting) that facilitate the more primary activities found in hub world cities.
 
  What he found: Gateway cities
 Note, in our case: The Internet backbone network is constituted by physical infrastructure - and so, the most powerful cities are located at the geographical edges, serving as the principal entry points for their respective continents.
 
  By the way ...
This distinction generated a series of commentaries and replies. Very interesting stuff!
 Boyd, John P., Matthew C. Mahutga, and David A. Smith. "Measuring centrality and power recursively in the world city network: a reply to Neal." Urban Studies 50.8 (2013): 1641- 1647.
 Neal, Zachary. "Does World City Network Research Need Eigenvectors?." Urban Studies 50.8 (2013): 1648-1659.
 
  Recurring themes
 As Neal highlights, we need to map our network measures to our substantive concerns and concepts
 The question often will be: What constituents a link between nodes - and what travels over that link? Neal gets us thinking that way too.
 

 Social Network Analysis (Class 5)
  Gregory M. Eirich QMSS
  Agenda
1. Triads--
2. Measures of competition
3. Measures of brokerage
 
  1- Triads (Class #4 slides)
  2- Measures of competition
  Measures of competition
 Weak components
 Structural holes  Brokerage
 
  Weak components
 A weak component is the largest number of actors who are connected, disregarding the direction of the ties
 (A strong component pays attention to the direction of the ties for directed data.)
 Most egos in this law firm have 1 (maybe 2) weak components
 
  Weak components
 If ego was connected to A and B (who are connected to one another), and ego is connected to C and D (who are connected to one another), but A and B are not connected in any way to C and D (except by way of everyone being connected to ego) then there would be two "weak components" in ego's neighborhood
 Cases where ego is the only connection between otherwise disjoint sets of actors
 
  Visualizing weak components
 Ego #23 is connected to #7 but #7 is not connected to anyone else in #23’s ego network; so too with #45
 Ego #23 has 3 weak components (I can only see 2 of them)
  
  Normalized weak components
 Number of weak components divided by size. The likelihood that there would be more than one weak components in ego's neighborhood would be a function of neighborhood size if connections were random. So, to get a sense of whether ego's role in connecting components is "unexpected" given the size of their network, it is useful to normalize the count of components by size.
 For the Lazega data, the average proportion of weak components is around 10%
 
  Remember this?
Burt, Ronald S. "Structural holes and good ideas." American journal of sociology 110.2 (2004): 349-399.
  
  The UCINET output
Various measures of structural holes:
STRUCTURAL HOLES
-------------------------------------------------------------------------------------------------
  Input dataset:
Method:
Output dataset
Structural Hole Measures
lazega-net-advice (C:\Users\Greg\etc)
Ego Network -- connections 2 links beyond ego are ignored
lazega-net-advice-SH (C:\Users\Greg\etc)
123456789 Degree EffSize Efficienc Constrain Hierarchy Ego Betwe Ln(Constr Indirects Density --------- --------- --------- --------- --------- --------- --------- --------- --------- 1 13.000 8.167 0.628 0.296 0.107 10.843 -1.216 0.838 0.295 2 23.000 16.154 0.702 0.170 0.084 53.902 -1.771 0.856 0.243 3 12.000 7.429 0.619 0.294 0.046 27.783 -1.225 0.826 0.326 4 30.000 20.000 0.667 0.134 0.057 100.448 -2.012 0.913 0.255
                [omitted]
    71      3.000     3.000     1.000     0.333     0.000     0.000    -1.099     0.000     0.000
Structural hole measures saved as dataset lazega-net-advice-SH (C:\Users\Greg\Documents\Spring
2014\Networks\lazega-net-advice-SH)
  Structural holes 1
 Effective size. Burt's measure to account for redundancy in someone’s network, and a person's ego network has redundancy to the extent that her contacts are connected to each other as well
 Two ways to calculate it.
 
  Effective size
Person A is also connected to 3 of G’s (6 total) alters, so Person A’s real value to G is only half of a tie (half- redundant)
 The first way to calculate effective size: Calculating “redundancy” for each alter vis-a-vis ego
 The less redundancy, the better
   
  Structural holes 1
 Effective size-- Second (easier) way to calculate it: The number of alters minus the average degree of alters within the ego network, not counting ties to ego
 The within-network degree of each of G's 6 alters A-F is {3,2,0,1,1,1}, and the average of these numbers is 1.33, i.e., the redundancy score from earlier.
 Effective size = 6 - 1.33 = 4.67
 
  Structural holes 1
 Effective size-- continued
 So the formula for redundancy is:
Redundancy = 2t/n
... where t is the number of ties in the network (not including ties to ego) and n is the number of nodes (excluding ego).
 
  Helpful notes from ...
“Introduction to Ego Network Analysis.” Rich DeJordy & Dan Halgin. Boston College and the Winston Center for Leadership & Ethics. Academy of Management PDW (2008)
 
  Structural holes 2
 Efficiency. The effective size divided by the number of alters in ego's network.
 
  Efficiency
   How much of ego’s network is worth something unique to ego?
 The higher the better
  Structural holes 3
 Constraint. Burt's constraint measure (equation 2.4, pg. 55 of Burt, 1992). Essentially a measure of the extent to which ego is invested in people who are also invested in ego's alters
 Remember from Day 1: Someone’s network is more constrained if it is small, or if a manager’s discussion partners talked a lot to one another directly (dense network), or if they shared information indirectly via a central contact (hierarchical network).
 
  Structural holes 3
 Constraint (for ego vis-a-vis alter J) = the proportion of ego’s total ego network that alter J makes up minus the sum of the product of (the proportion of ego’s total ego network that alter Q makes up times [ego’s tie to alter Q / alter J’s strongest tie to anyone] N.B.)
 N.B. ~ So this ratio is always 1 if alter J has tie to alter Q, 0 otherwise
    
  Constraint
 An alter constrains ego to the extent that ego has invested in that alter, but that alter has has few structural holes
 So even if ego withdraws from that alter, everyone else in ego’s network is still invested with that alter
 For example, if ego's boyfriend bowls with her brother and father every Wednesday night, she may be constrained in terms of distancing herself from him, even if they break up
  The lower the constraint score, the better (-- often logged)
  Structural holes 4
 Hierarchy. Burt's adjustment of constraint (equation 2.9, pg 71), indicating the extent to which constraint on ego is concentrated with a single alter.
 The lower the hierarchy score, the better
 
  Structural holes in Lazega data
 
We will look at the Lazega advice network, where at first we consider any and all ties (in-coming or out-going) between ego and alters
. sum  ADegree AEffSize AEfficiency AConstraint AHierarchy
    Variable |       Obs        Mean    Std. Dev.       Min        Max
-------------+--------------------------------------------------------
     ADegree |
   AEffSize |
AEfficiency |
AConstraint |
 AHierarchy |
71    15.70423
71    11.07626
71    .7148484
71    .2788968
71    .0849944
8.386033
6.264325
.0987179
.1631878
.1592736
1 35
       1   26.83721
.5388889          1
.1155992          1
       0          1
   
What if we look at only in-coming or only out-going ties too?
Put aside statistical significance for right now-- just look at means
. tabstat  ADegree AiDegree AoDegree, by(STATUS)
Summary statistics: mean
  by categories of: STATUS
STATUS | ADegree AiDegree AoDegree (all) (in-coming)(out-going)
---------+------------------------------
       1 |  19.19444  12.94444  8.722222
       2 |  12.11429  4.171429  8.514286
---------+------------------------------
   Total |  15.70423  8.619718  8.619718
----------------------------------------
Structural holes in Lazega data
     
  Structural holes in Lazega data
 Partners (status=1) and associates (=2) both send out the same number of ties (~8.5), but partners get 12.9 back vs. only 4.2 for associates.--- How is this possible?
   . tabstat  ADegree AiDegree AoDegree, by(STATUS)
   Summary statistics: mean
     by categories of: STATUS
STATUS | ADegree AiDegree AoDegree (all) (in-coming)(out-going)
   ---------+------------------------------
          1 |  19.19444  12.94444  8.722222
          2 |  12.11429  4.171429  8.514286
   ---------+------------------------------
      Total |  15.70423  8.619718  8.619718
   ----------------------------------------
      
  Effective size in Lazega data
 Everyone’s effective network size shrinks, once redundancy is taken into account, and by similar magnitudes
   . tabstat  AEffSize  AiEffSize AoEffSize , by(STATUS)
   Summary statistics: mean
     by categories of: STATUS
     STATUS |  AEffSize  AiEffS~e  AoEffS~e
                (all)  (in-coming)(out-going)
   ---------+------------------------------
          1 |  13.34929  8.963715  5.852415
          2 |  8.738289  3.250146  5.950441
   ---------+------------------------------
      Total |  11.07626  6.147167  5.900737
   ----------------------------------------
  
  Efficiency in Lazega data
 Maybe surprisingly, associates have more efficient networks, on any measure of ties.-- Maybe why shouldn’t this be surprising?
   . tabstat   AEfficiency AiEfficiency AoEfficiency , by(STATUS)
   Summary statistics: mean
     by categories of: STATUS
     STATUS |  AEffic~y  AiEffi~y  AoEffi~y
                (all)  (in-coming)(out-going)
   ---------+------------------------------
          1 |  .6823357  .6842402  .6567239
          2 |    .74829  .8077998  .7099887
   ---------+------------------------------
      Total |  .7148484  .7348794  .6829466
   ----------------------------------------
  
  Constraint in Lazega data
 In the majority of instances, partners are less constrained that associates (except based on outgoing ties, where partners and associates are more equal in number, remember)
   . tabstat   AConstraint AiConstraint AoConstraint , by(STATUS)
   Summary statistics: mean
     by categories of: STATUS
     STATUS |  AConst~t  AiCons~t  AoCons~t
                (all)  (in-coming)(out-going)
   ---------+------------------------------
          1 |  .2274956  .3245303  .4822855
          2 |  .3317665  .5128076  .3831854
   ---------+------------------------------
      Total |  .2788968  .4016931  .4334978
   ----------------------------------------
  
  Constraint in Lazega data in R
  Constraint in R
 > ### calculate constraint in ego networks ###
 > con = data.frame( constraint=constraint(testmg) )
 >
 > ### do this to get density added into the file ###
 > dd <-data.frame(ID = V(testmg)$name)
 > cb3 <- cbind(dd, con)
 > aggdatanew4 <- merge(aggdatanew2, cb3, by=c("ID"))
 
  Look at constraint in R
 > con
    constraint
 1  0.13174849
 2  0.09785028
 3  0.14322393
 4  0.09009372
 5  0.15370140
 6  0.15311839
 7  0.18329700
 8  0.13843265
 9  0.09819664
 10 0.13189835
 11 0.09861697
 12 0.09179465
 13 0.07909755
 14 0.10839873
 15 0.14017165
 
  Is constraint just degree in another form?
 > summary(lm(constraint ~ V(testmg)$degree , aggdatanew4))
 Coefficients:
                   Estimate Std. Error t value Pr(>|t|)
 (Intercept)       0.210735   0.039742   5.303  1.3e-06 ***
 V(testmg)$degree -0.003524   0.002229  -1.581    0.119
 ---
 Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
 Residual standard error: 0.157 on 69 degrees of freedom
 Multiple R-squared:  0.03495, Adjusted R-squared:  0.02096
 F-statistic: 2.499 on 1 and 69 DF,  p-value: 0.1185
 
  Hierarchical constraint in Lazega
 These results mirror constraint in general: generally, partners are less constrained than associates (except based on outgoing ties)
   . tabstat  AHierarchy AiHierarchy AoHierarchy , by(STATUS)
   Summary statistics: mean
     by categories of: STATUS
     STATUS |  AHiera~y  AiHier~y  AoHier~y
                (all)  (in-coming)(out-going)
   ---------+------------------------------
          1 |  .0600486  .0743684  .1167271
          2 |  .1106529  .2026249  .0923193
   ---------+------------------------------
      Total |  .0849944  .1269325  .1047109
   ----------------------------------------
  
  Conclusions so far
 It potentially matters how ties are defined (in-coming, out-going, any, or reciprocated)
 A paradox-- Associates have more efficient advice networks, but partners have less constrained ones
 How to resolve this paradox?-- At least, I can sidestep it...
 
  Conclusions so far
 Structural holes are typically not going to show up as systematically separating one group from another, especially not partners vs. associates
 Quite the contrary. Structural holes should differentiate among people of the same group (remember this is competition to not be replaceable and to be connecting all sorts of disconnected people)
 Unfortunately, we don’t have the data (on revenue, sales, hours, promotions, exact titles) to see the fruits of competition among relatively equivalent positions and roles
 
  3- Measures of brokerage
  Brokerage
 Many of the arguments around structural holes stem from the idea of tertian gaudens -- “the third enjoys” by way of brokering
 We can get deeper insight into brokerage, as long as we have (1) a membership variable to separate one group from another and (2) directed ties so we know who comes to whom
 A typology of brokerage relationships was developed by: Fernandez, Roberto M., and Roger V. Gould. "A dilemma of state power: Brokerage and influence in the national health policy domain." American Journal of Sociology (1994): 1455-1491.
 
  Thanks to ...
 Robert A. Hanneman (Department of Sociology, University of California, Riverside) and --
 Mark Riddle (Department of Sociology, University of Northern Colorado)
 For many of the phrases and graphic below ...
 
  Node B as a “co-ordinator”
 Node B (as ego) is brokering, and both the source and destination nodes (A and C) are all members of the same group (all red).
 In this case, B is acting as a "coordinator" of actors within the same group as itself.
   Think of this as tertius jungens or “the one who unites”
  Node B as a “consultant”
 Node B (as ego) is brokering a relation between two members of the same group, but is not itself a member of that group (hence, blue).
 In this case, B is acting in a "consulting" role to others.
 Think of this also as tertius jungens or “the one who unites” too
  
  Node B as a “gatekeeper”
 Node B (as ego) is is acting as a gatekeeper. B is a member of a (blue) group who is at its boundary (in front of C), and controls access of outsiders (A) to the group
 In this case, B is acting in a "gatekeeping" role to others.
  
  Node B as a “representative”
 Node B (as ego) is in the same group as A, and acts as the contact point or representative of the red group to the blue via C.
 In this case, B is acting in a "representative" role to others.
  
  Node B as a “liaison”
 Node B (as ego) is is brokering a relation between two groups, and is not part of either, nor are they part of the same group (hence, red vs. black)
 Think of this as tertius gaudens or “the one who enjoys (being in the middle)”
  
  Brokerage in Lazega data
 We will look at the Lazega advice network, where we will consider any and all ties (in-coming or out-going) between ego and alters
 
  The UCINET output
First are the un-normalized number of times that each type of brokerage was observed for each lawyer
GOULD & FERNANDEZ BROKERAGE MEASURES
--------------------------------------------------------------------------------
  Old Code    New Code   Frequency
  ========    ========   =========
1=>1 36 2=>2 35
Number of classes: 2
Un-normalized Brokerage Scores
123456 Coordinat Gatekeepe Represent Consultan Liaison Total
        -------------------------------------------------------------
  1  1 |        11         3         0         0         0        14 |
  2  2 |        56        17         0         0         0        73 |
  3  3 |        24         4         0         0         0        28 |
  4  4 |        80        83         0         0         0       163 |
  [etc.]
  The UCINET output-- cont’d
 Then there are the relative number of times that each type of brokerage was observed for each lawyer.
 This relative number is obtained by dividing the observed number of brokerage by the expected number of time, given the number of groups and the size of each group (that is-- these are the the expected values under the assumption that brokerage is independent of the group status of nodes)
 
  The UCINET output-- cont’d
Then there are the relative number of times that each type of brokerage was observed for each lawyer.
GOULD & FERNANDEZ BROKERAGE MEASURES
--------------------------------------------------------------------------------
Relative Brokerage (raw scores divided by expected values given group sizes)
123456 Coordinat Gatekeepe Represent Consultan Liaison Total
        -------------------------------------------------------------
  1 1| 2 2| 3 3| 4 4| 5 5| [omitted...]
36 36 |0 ---------------------------------------------------------------
37 37 |
38 38 |
39 39 |
    0     1.315         0     2.630
0.256     0.208     2.249     1.246
0.278     0.131     3.221     0.329
[etc.]
0     1.000 |
0     1.000 |
0     1.000 |
3.282     0.845         0         0         0
3.204     0.919         0         0         0
3.580     0.563         0         0         0
2.050     2.009         0         0         0
2.702     1.392         0         0         0
1.000 |
1.000 |
1.000 |
1.000 |
1.000 |
2.630         0     1.315         0
1.000 |
  To consult or to coordinate?
 No one can be both a
coordinator among their group and a consultant for members of another group
   
  How did I do this?
graph twoway (scatter RBrCoordinator RBrConsultant if STATUS==1,
msymbol(Oh) mlabel(IDC) jitter(3)) ///
  (scatter RBrCoordinator RBrConsultant if STATUS==2, msymbol(S) mlabel
(IDC) jitter(20)), ///
  legend(label(1 partner) label(2 associate))
 
  To consult or to coordinate?- cont.
 Many lawyers coordinate much more than would be expected (2-4x more), given the size of their networks and the partitioning of the two groups
   
  To consult or to coordinate?- cont.
 Only 5 lawyers consult more often than would be expected, given the characteristics of ego and the network
 Most action is within groups
    
  Who brokers how?-- recodes
 
Let’s start by looking at who has a higher-than-expected chance of serving as a given kind of broker, where what is expected is based on ego’s degree and the size of the two groups. Recode like this:
. recode  RBrCoordinator 0/1=0 1.00001/10=1, gen(coord)
(48 differences between RBrCoordinator and coord)
. recode   RBrGatekeeper 0/1=0 1.00001/10=1, gen(gate)
(45 differences between RBrGatekeeper and gate)
. recode    RBrRepresentative 0/1=0 1.00001/10=1, gen(rep)
(32 differences between RBrRepresentative and rep)
. recode     RBrConsultant 0/1=0 1.00001/10=1, gen(cons)
(29 differences between RBrConsultant and cons)
 
  Who brokers how?
 . tabstat  coord cons gate rep , by(STATUS)
Summary statistics: mean
  by categories of: STATUS
  STATUS |     coord      cons      gate       rep
---------+----------------------------------------
       1 |  .8055556  .0277778  .7222222  .0277778
       2 |  .2571429  .1142857  .0571429  .5428571
---------+----------------------------------------
   Total |  .5352113  .0704225  .3943662  .2816901
--------------------------------------------------
  Who brokers how?
 Partners are almost all coordinators and gatekeepers
 They are almost never consultants among associates or a
representative to the associates from another partner
   . tabstat  coord cons gate rep , by(STATUS)
   Summary statistics: mean
     by categories of: STATUS
     STATUS |     coord      cons      gate       rep
   ---------+----------------------------------------
          1 |  .8055556  .0277778  .7222222  .0277778
          2 |  .2571429  .1142857  .0571429  .5428571
   ---------+----------------------------------------
      Total |  .5352113  .0704225  .3943662  .2816901
   --------------------------------------------------
  
  Who brokers how?
  

Some portion of associates (~25%) coordinate among other associates The main thing associates do is represent another associate to a partner More often than partners do for associates, they consult between two partners
 . tabstat  coord cons gate rep , by(STATUS)
Summary statistics: mean
  by categories of: STATUS
  STATUS |     coord      cons      gate       rep
---------+----------------------------------------
       1 |  .8055556  .0277778  .7222222  .0277778
       2 |  .2571429  .1142857  .0571429  .5428571
---------+----------------------------------------
   Total |  .5352113  .0704225  .3943662  .2816901
--------------------------------------------------
  See? To gate-keep or to represent?
 No one can be both a
gatekeeper for their group and a representative for their group
  
  BTW ...
For every additional alter in ego’s network, they have (on average) a 1.44 percentage point increase in being a coordinator more often than expected
  . reg   coord ADegree
      Source |       SS       df       MS
-------------+------------------------------
       Model |  1.03093137     1  1.03093137
    Residual |  16.6310405    69  .241029572
-------------+------------------------------
       Total |  17.6619718    70  .252313883
Number of obs =      71
F(  1,    69) =    4.28
Prob > F      =  0.0424
R-squared     =  0.0584
Adj R-squared =  0.0447
Root MSE      =  .49095
------------------------------------------------------------------------------
       coord |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
     ADegree |   .0144714   .0069973     2.07   0.042     .0005122    .0284306
       _cons |   .3079498   .1243781     2.48   0.016     .0598222    .5560774
------------------------------------------------------------------------------
  BTW ...
For every additional alter in ego’s network, they have (on average) a 1.73 percentage point increase in being a gatekeeper more often than expected
  . reg    gate ADegree
      Source |       SS       df       MS
-------------+------------------------------
       Model |  1.47740784     1  1.47740784
    Residual |  15.4803386    69  .224352734
-------------+------------------------------
       Total |  16.9577465    70  .242253521
Number of obs =      71
F(  1,    69) =    6.59
Prob > F      =  0.0125
R-squared     =  0.0871
Adj R-squared =  0.0739
Root MSE      =  .47366
------------------------------------------------------------------------------
        gate |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
     ADegree |   .0173239   .0067509     2.57   0.012     .0038562    .0307915
       _cons |   .1223084   .1199982     1.02   0.312    -.1170813    .3616982
------------------------------------------------------------------------------
  BTW ...
But there is no increase in the probability of being a consultant or representative, as ego’s degree grows
 . eststo: reg     cons ADegree
 . eststo: reg      rep ADegree
 . esttab, ar2 se
 --------------------------------------------
                       (1)             (2)
                      cons             rep
 --------------------------------------------
  ADegree         -0.000918
                (0.00370)
_cons              0.0848
                 (0.0657)
  0.00547
(0.00647)
    0.196
  (0.115)
--------------------------------------------
N                      71              71
adj. R-sq          -0.014          -0.004
--------------------------------------------
Standard errors in parentheses
* p<0.05, ** p<0.01, *** p<0.001
  How to do brokerage analysis in R
 We need to use statnet -- not igraph -- for this analysis
  ### see Step #1 and Step #2 for the files ###
  install.packages("statnet")
  library(statnet)
  nrelations<-network(testm,directed=TRUE)
  nrelations %v% "ID" <- testatt$ID
  nrelations %v% "status" <- testatt$status
  b=brokerage(nrelations, status)
  bz=cbind(testatt, b$z.nli)
  
  How to do brokerage analysis in R
 Here is the most important output from R
bz
 ID status gender office seniority age practice lawschool         w_I        w_O        b_IO        b_OI b_O           t
  1 1 0 1
2 1 0 1
3 1 0 2
4 1 0 1
5 1 0 2
6 1 0 2
7 1 0 2
8 1 0 1
9 1 0 1
10 1 0 1
11 1 0 1
12 1 0 1
13 1 0 1
14 1 0 2
15 1 0 3
16 1 0 1
17 1 0 1
18 1 0 2
19 1 0 1
31  64        1
32  62        2
13  67        1
31  59        2
31  59        1
29  55        1
29  63        2
28  53        1
25  53        2
25  53        2
23  50        1
24  52        2
22  57        1
156 2 21 48 2 20 46 2 23 50 2 18 45 1 19 46 2
1 -0.47972664 -2.0720430 -1.25707377 -1.25707377 NaN -1.82269128
1  5.70220761 -1.6973804  0.47346165  0.47346165 NaN  1.76640466
1  0.17593305 -2.1657087 -1.89463946 -1.89463946 NaN -2.08855024
3  8.69950907 -0.3860610  2.47723952  2.47723952 NaN  4.75731795
2 -0.76072366 -2.0720430 -1.84909905 -1.84909905 NaN -2.35440920
1  0.26959872 -2.1657087 -2.16788189 -2.16788189 NaN -2.25471209
3 -1.60371469 -2.1657087 -1.94017986 -1.94017986 NaN -2.75319764
3 -0.47972664 -2.1657087 -1.75801824 -1.75801824 NaN -2.22147972
1 -0.57339231 -0.2923953  0.29130003  0.29130003 NaN -0.09460805
3 -0.38606097 -2.0720430 -1.57585662 -1.57585662 NaN -2.02208550
1  2.51757481 -1.3227177  0.24575962  0.24575962 NaN  0.60327172
2  9.54250011 -1.8847117  0.20021922  0.20021922 NaN  2.86307287
2  2.89223750  3.9225599  4.89088103  4.89088103 NaN  5.98691563
1  1.11258976 -1.3227177 -0.07302322 -0.07302322 NaN -0.12784042
3  0.26959872 -2.1657087 -2.16788189 -2.16788189 NaN -2.25471209
1 13.47645827  0.8315927  7.03128011  7.03128011 NaN 10.20742660
1  9.82349712  1.0189241  5.34628509  5.34628509 NaN  7.74823123
2 -1.22905201 -2.0720430 -1.71247783 -1.71247783 NaN -2.42087394
1 -1.69738036 -2.1657087 -1.84909905 -1.84909905 NaN -2.71996527
0
1
2
3
4
5
6
7
8
9
0 20
1 0 1
19 49 1
1 -0.19872963 -1.6973804 -1.21153337 -1.21153337 NaN -1.55683232
  Brokerage roles in R
 w_I: Coordinator role; the broker mediates contact between two individuals from his or her own group. Two-path structure: A -> A -> A
 w_O: Itinerant broker role; the broker mediates contact between two individuals from a single group to which he or she does not belong. Two- path structure: A -> B -> A
 b_{IO}: Representative role; the broker mediates an incoming contact from an out-group member to an in-group member. Two-path structure: A -> B -> B
 
  Brokerage roles in R, cont’d
 b_{OI}: Gatekeeper role; the broker mediates an outgoing contact from an in-group member to an out-group member. Two-path structure: A -> A -> B
 b_O: Liaison role; the broker mediates contact between two individuals from different groups, neither of which is the group to which he or she belongs. Two-path structure: A -> B -> C
 t: Total (cumulative) brokerage role occupancy. (Any of the above two- paths.)
 
  How to do brokerage analysis in R
The only results we really care about are: z.nli, the matrix of standardized brokerage scores, by vertex, attached below to the attribute file
bz
 ID status gender office seniority age practice lawschool         w_I        w_O        b_IO        b_OI b_O           t
  1 1 0 1
2 1 0 1
3 1 0 2
4 1 0 1
5 1 0 2
6 1 0 2
7 1 0 2
8 1 0 1
9 1 0 1
10 1 0 1
11 1 0 1
12 1 0 1
13 1 0 1
14 1 0 2
15 1 0 3
16 1 0 1
17 1 0 1
18 1 0 2
19 1 0 1
31  64        1
32  62        2
13  67        1
31  59        2
31  59        1
29  55        1
29  63        2
28  53        1
25  53        2
25  53        2
23  50        1
24  52        2
22  57        1
156 2 21 48 2 20 46 2 23 50 2 18 45 1 19 46 2
1 -0.47972664 -2.0720430 -1.25707377 -1.25707377 NaN -1.82269128
1  5.70220761 -1.6973804  0.47346165  0.47346165 NaN  1.76640466
1  0.17593305 -2.1657087 -1.89463946 -1.89463946 NaN -2.08855024
3  8.69950907 -0.3860610  2.47723952  2.47723952 NaN  4.75731795
2 -0.76072366 -2.0720430 -1.84909905 -1.84909905 NaN -2.35440920
1  0.26959872 -2.1657087 -2.16788189 -2.16788189 NaN -2.25471209
3 -1.60371469 -2.1657087 -1.94017986 -1.94017986 NaN -2.75319764
3 -0.47972664 -2.1657087 -1.75801824 -1.75801824 NaN -2.22147972
1 -0.57339231 -0.2923953  0.29130003  0.29130003 NaN -0.09460805
3 -0.38606097 -2.0720430 -1.57585662 -1.57585662 NaN -2.02208550
1  2.51757481 -1.3227177  0.24575962  0.24575962 NaN  0.60327172
2  9.54250011 -1.8847117  0.20021922  0.20021922 NaN  2.86307287
2  2.89223750  3.9225599  4.89088103  4.89088103 NaN  5.98691563
1  1.11258976 -1.3227177 -0.07302322 -0.07302322 NaN -0.12784042
3  0.26959872 -2.1657087 -2.16788189 -2.16788189 NaN -2.25471209
1 13.47645827  0.8315927  7.03128011  7.03128011 NaN 10.20742660
1  9.82349712  1.0189241  5.34628509  5.34628509 NaN  7.74823123
2 -1.22905201 -2.0720430 -1.71247783 -1.71247783 NaN -2.42087394
1 -1.69738036 -2.1657087 -1.84909905 -1.84909905 NaN -2.71996527
0
1
2
3
4
5
6
7
8
9
0 20
1 0 1
19 49 1
1 -0.19872963 -1.6973804 -1.21153337 -1.21153337 NaN -1.55683232
  A word of caution ...
 There is probably a lot of random variation in this data, which does not reflect real differences or relationships
 There is obviously no statistical significance for any of this ... yet
 So interpret this output with caution; it is more of a starting off point
 

 Social Network Analysis (Class 8)
  Gregory M. Eirich QMSS
  Agenda
1. ERGMs-- Exponential Random Graph Models
2. From face-to-face networks to online ones
3. Finding “groups”
4. A number of of bottom-up approaches
5. A number of top-down approaches
 
  1. ERGMs-- Exponential Random Graph Models
  Another way to model relations
 Remember the problem:
○ We have deep dependence in our data (clustering)
○ We have structural properties about our network that might matter
 
  A really good source
 Cranmer, Skyler J., and Bruce A. Desmarais. "Inferential network analysis with exponential random graph models." Political Analysis 19.1 (2011): 66-86.
 
  How ERGMs work
 From Cranmer & Desmarais (p.71): The only assumptions we have to make about ERGMs are (1) that we observe the expected values of a
bunch of parameters that define a network, Γi , and (2) that we have identified the factors that influence the probability of observing any given graph (i.e., the model is correctly specified). ERGMs thus provide a method capable of estimating standard covariate effects as well as the effects of other network properties without having to make any assumptions about independence.
  
  An example
  It started here ...
 
  ... and went to here
 
   1. Ignore it
  The sexual network of Grey’s Anatomy
  Our question
 Are heterosexual or homosexual relationships more likely on this network?
 
  Setting up ...
Pulling in the files and making the sociomatrix
install.packages("RCurl"); install.packages("ergm")
library(RCurl); library(ergm)
#First, read in the sociomatrix
ga.mat<-getURL("https://docs.google.com/spreadsheet/pub?key=0Ai--
oOZQWBHSdDE3Ynp2cThMamg1b0VhbEs0al9zV0E&single=true&gid=0&output=txt",
               ssl.verifypeer = FALSE)
ga.mat<-as.matrix(read.table(textConnection(ga.mat), sep="\t",
                             header=T, row.names=1, quote="\""))
#Second, read in the network attributes
ga.atts<-getURL("https://docs.google.com/spreadsheet/pub?key=0Ai--
oOZQWBHSdDE3Ynp2cThMamg1b0VhbEs0al9zV0E&single=true&gid=1&output=txt",
                ssl.verifypeer = FALSE)
ga.atts<-read.table(textConnection(ga.atts), sep="\t", header=T, quote="\"",
                    stringsAsFactors=F, strip.white=T, as.is=T)
#Third, create a network object using the sociomatrix and its corresponding attributes
ga.net<-network(ga.mat, vertex.attr=ga.atts, vertex.attrnames=colnames(ga.atts),
  directed=F, hyper=F, loops=F, multiple=F, bipartite=F)
   1. Ignore it
  The sexual network of Grey’s Anatomy
  How’d they do that?
Here:
plot(ga.net, vertex.col=c("blue","pink")[1+(get.vertex.attribute(ga.net, "sex")=="F")], label=get.vertex.attribute(ga.net, "name"), label.         )
                                            cex=.
75
  Predicting ties based on same sex
The model includes how many edges are in the graph that do not match and then how many of the edges are same-sex (nodematch)
                 ga.base<-ergm(ga.net~edges+nodematch("sex")) #Estimate the model summary(ga.base) #Summarize the model
        
  Predicting ties based on same sex
The coefficient on “nodematch.sex” is -3.14***. This means that on this network, ties based on same sex are less likely that ties based on not-same sex. The logit of seeing a same sex pair is -3.14 lower than seeing a heterosexual pair.
ga.base<-ergm(ga.net~edges+nodematch("sex")) #Estimate the model summary(ga.base) #Summarize the model
                         Iterations: 20
Monte Carlo MLE Results:
              Estimate
edges         -2.3003
nodematch.sex -3.1399
Std. Error
0.1581
0.7260
MCMC % NA
NA
p-value
<1e-04 ***
<1e-04 ***
 —
Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
Null Deviance: 1311.43 on 946 degrees of freedom
Residual Deviance: 320.47 on 944 degrees of freedom
Deviance: 990.97 on 2 degrees of freedom ; AIC: 324.47 BIC: 334.17
  Predicting ties based on same sex
Ties based on same sex are less likely that ties based on not-same sex, net of the total number of ties in the network. Only two edges (torres-arizona and torres-hahn) are same-sex.
ga.base<-ergm(ga.net~edges+nodematch("sex")) #Estimate the model summary(ga.base) #Summarize the model
                         Iterations: 20
Monte Carlo MLE Results:
              Estimate
edges         -2.3003
nodematch.sex -3.1399
Std. Error
0.1581
0.7260
MCMC % NA
NA
p-value
<1e-04 ***
<1e-04 ***
 —
Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
Null Deviance: 1311.43 on 946 degrees of freedom
Residual Deviance: 320.47 on 944 degrees of freedom
Deviance: 990.97 on 2 degrees of freedom ; AIC: 324.47 BIC: 334.17
  What about the coeff. on edges?
The coefficient on “edges” is -2.30***. This means that on this network, ties based on opposite sex relationship are also not very likely ... they are just more likely than same sex pairings. The probability of a heterosexual tie forming on this network is e-2.30/(1+e-2.30) = 0.09 = 9 percent. ga.base<-ergm(ga.net~edges+nodematch("sex")) #Estimate the model
                         summary(ga.base) #Summarize the model
Iterations: 20
Monte Carlo MLE Results:
              Estimate
edges         -2.3003
nodematch.sex -3.1399
Std. Error
0.1581
0.7260
MCMC % NA
NA
p-value
<1e-04 ***
<1e-04 ***
 —
Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
Null Deviance: 1311.43 on 946 degrees of freedom
Residual Deviance: 320.47 on 944 degrees of freedom
Deviance: 990.97 on 2 degrees of freedom ; AIC: 324.47 BIC: 334.17
  Probability of a same sex tie
The logit of a homosexual tie forming on this network is -2.30 + -3.14 = -5.44. Therefore, the probability of a homosexual tie forming is e-5.44/(1+e-5.44) = 0.004 = 0.4 percent.
ga.base<-ergm(ga.net~edges+nodematch("sex")) #Estimate the model summary(ga.base) #Summarize the model
                         Iterations: 20
Monte Carlo MLE Results:
              Estimate
edges         -2.3003
nodematch.sex -3.1399
Std. Error
0.1581
0.7260
MCMC % NA
NA
p-value
<1e-04 ***
<1e-04 ***
 —
Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
Null Deviance: 1311.43 on 946 degrees of freedom
Residual Deviance: 320.47 on 944 degrees of freedom
Deviance: 990.97 on 2 degrees of freedom ; AIC: 324.47 BIC: 334.17
  Another example-- Lazega
  Remember this?
    Should we read this as good
news for these women? Bad news? Neither? Both?
  How important is gender to friendship?
Load in the Lazega friendship network, with directed ties and attributes
   library(ergm)
 #First, read in the sociomatrix
 ga.mat<-as.matrix(read.csv(file.choose() ,header=TRUE,row.names=NULL,check.names=FALSE))
 #Second, read in the network attributes
 ga.atts<-read.csv(file.choose() ,header=TRUE)
 #Third, create a network object using the sociomatrix and its corresponding attributes
 ga.net<-network(ga.mat, vertex.attr=ga.atts, vertex.attrnames=colnames(ga.atts),
 directed=T, hyper=F, loops=F, multiple=F, bipartite=F)
  First, baseline tie formation
The log-odds of forming a tie on this network are -1.57*** (i.e., much less than 50%)
   > ga.base.d0<-ergm(ga.net~edges,
 +                  control=control.ergm(MCMC.burnin=50000, MCMC.interval=5000))
 > summary(ga.base.d0)
 Iterations:  20
 Monte Carlo MLE Results:
 Estimate Std. Error MCMC % p-value
 edges  -1.5727     0.0376     NA  <1e-04 ***
 ---
 Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
 Null Deviance: 6890  on 4970  degrees of freedom
 Residual Deviance: 4560  on 4969  degrees of freedom
 AIC: 4562    BIC: 4569    (Smaller is better.)
  Next, what about gender, net of ties?
The log-odds of forming a tie based on shared gender is 0.237*** higher than forming an opposite gender one
   > ga.base.d1<-ergm(ga.net~edges+nodematch("gender"),
 +                  control=control.ergm(MCMC.burnin=50000, MCMC.interval=5000))
 > summary(ga.base.d1)
 Iterations:  20
 Monte Carlo MLE Results:
 Estimate Std. Error MCMC % p-value
 edges            -1.72314    0.06386     NA < 1e-04 ***
 nodematch.gender  0.23712    0.07905     NA 0.00272 **
 ---
 Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
 Null Deviance: 6890  on 4970  degrees of freedom
 Residual Deviance: 4551  on 4968  degrees of freedom
 AIC: 4555    BIC: 4568    (Smaller is better.)
  What about other similarities?
The log-odds of forming a tie based on shared litigation vs. corporate practice (1.16***) are 6 times higher than forming a tie on gender or partner vs. associate status (~0.2)
   >ga.base.d2<-ergm(ga.net~edges+nodematch("gender")+nodematch("status")+nodematch("practice")+nodematch
 ("lawschool"), control=control.ergm(MCMC.burnin=50000, MCMC.interval=5000))
 > summary(ga.base.d2)
 Monte Carlo MLE Results:
 Estimate Std. Error MCMC % p-value
 edges               -2.53447    0.09914     NA < 1e-04 ***
 nodematch.gender     0.22988    0.08126     NA 0.00469 **
 nodematch.status     0.21959    0.07762     NA 0.00469 **
 nodematch.practice   1.16738    0.08333     NA < 1e-04 ***
 nodematch.lawschool  0.01248    0.08094     NA 0.87744
 ---
 AIC: 4337    BIC: 4370    (Smaller is better.)
  One last example--
  Climate change elites
 Lorien Jasny, Joseph Waggle, and Dana R. Fisher. 2015. “An Empirical Examination of Echo Chambers in US Climate Policy Networks.” Nature Climate Change 5:782-786.
    
  Who is Dana Fisher?
 
  Their question
 Where do climate change elites get their information about climate change issues?
 
  Their method
 Got 64 out of the top 100 climate change elites to provide an ego network of where they get their information on climate change from, along with their opinions on climate change issues
 This results, once all merged together, in a directed graph of information sharing, with affiliations tied to climate change support or denial
 
  Their concern
 Do elites within this network exist in “echo chambers”?
 Echo chambers are made up of two parts:
○ Echos, which are shared beliefs about climate change with other
actors
○ Chambers, the specific structures about how information comes
to ego within the network
 
  They find
 Both the echo and chamber are present in the climate change information network
 
  Agreement abounds
 The Nature Conservancy
shares lots of ties with groups and people who believe in climate change, while Alabama scientists share lots of ties with those who do not
  
   The chamber
 Echo chambers get louder the more transitive triads are present
 A transitive triad is where one individual is the source of information and transmits information to a second person both directly and indirectly through the third person. ... From the perspective of the person receiving the information, this information appears to be coming from multiple sources, though, in fact, it is coming from a single source.
 
  The ERGM
  If adding an edge adds one more to the count of transitive triads in which all actors responded with the same level of agreement to the question “There should be an international binding commitment on all nations to reduce GHG emissions,” the likelihood of that tie occurring increases significantly by 0.274 in log-odds or a probability of 57%.
  How ERGMs work again (from Fisher)
   Read the supplement to the Fisher article -- it is very helpful
  2. From face-to-face networks to online networks
  A few concepts
 From Internet 1.0 to 2.0 to 3.0
 Performativity of social networks
 Local vs. global scale  Others?
 
  3. Finding “groups”
  Remember?-- The basics: Groups
 The basic idea is that groups share lots of ties within themselves
and not so many between other groups
 The trick is how many ties need to not exist between groups and
how many ties do need to exist within groups
 There are many algorithms designed to figure this question out
  
  An easy one ...
 The network structure of political blogs prior to the 2004 U.S. Presidential election
 Here are 2 naturally well-separated
clusters
  
  Now, how many sub-groups here?
 Network of terrorists associated with September 11th attacks
  
  How do we find groups?
 How small is a group?
 How many groups should one network have?
 
  Why do we want to find groups?
  Why do we want to find groups? -1
 Find the difference between “explicit” (attribute-based) group membership vs. “implicit” (tie-based) group membership
 E.g., If it looks like a duck, and it quacks like a duck, but it relates like a swan, then it’s not a duck
 Someone who is in the located in HR, but all of their ties are to Accounting
 
  Why do we want to find groups? -2
 Find who is a “real” member of a group vs. not really real member of a group
 How to find out if someone is a terrorist or just unlucky? Or in a gang? Really one of the “cool kids” or not?
 
  Why do we want to find groups? -3
 Find out who will stick together if there is a rupture in the group
 
  Why do we want to find groups? -4
 Find out who will form new ties once groups are established
 
  #1. The Zachary karate club
 
  #2. Correlates of War data (1993-2001)
 Has positive (alliances) and negative (aggressive acts) ties
Traag, V. A., & Bruggeman, J. (2009). Community detection in networks with positive and negative links. Physical Review E, 80(3), 036115.
    
  Why do we want to find groups?
 If group-membership will influence nodes above and beyond their tie alone
 
  Why do we want to find groups?
 Other thoughts?
 
  3. Lots of bottom-up methods
  “Bottom-up” approaches
 We work out from the smallest units within the network and see how far they go before the groups cannot be stretched any further
 We start with pairs and triads and keep seeing if we can add more people without the group having only loosely-connected people in it
 
  Back to our Lazega friend network
 To make it easy on us, I have taken the friendship network and only kept ties that are reciprocated, thus creating a symmetric, binary socio-matrix
 That makes a relatively sparse network, which should make it easier to view the network
 
  The friendship network ...
 The friendship network looks like this:
 258 total reciprocated ties for 71 lawyers
 Blue are men and pink are women
 Circles are partners and squares are associates
 Size of the label is age
 Color of label is practice (red=1 and green=2)
 Density is about 5%
 
   The friendship network ...
  1. Cliques
  Cliques
 Originally proposed by Luce and Perry (1949), it is a subgraph in which every pair of vertices is directly connected to every other.
 Very stringent criterion of complete community, tends to produce very small groups
 
  Cliques
 This starts with the most stringent requirement of direct ties among all members of the group and the smallest size group (>1)
 
  What do we find?
 69 cliques of size 2 or greater were found:
  69 cliques found.
   1: 13 39 55
2: 13 54 56
3: 13 24 31
4: 13 39 52
5: 13 64
6: 13 67
7: 13 65 68
8: 13 71
9: 4 41
56 57 65
18:  6 58
19:  7 64
20:  11 54
21:  11 39 56
22:  11 43
23:  12 24 26
24:  12 42
25:  12 62
26:  1 41
27:  17 45
28:  19 28
29:  19 28 29
30:  19 28 45
31:  19 22
32:  19 42
33:  19 35
34:  20 21
35: 21 26
36: 21 26
37: 21 24
38: 22 31
39: 25 28
40: 26 30
41: 26 29
42: 28 70
43: 28 30
44: 24 28
45: 28 63
46: 29 34
47: 30 31
48: 30 31
49: 30 59
50: 32 63
51: 38 40
27 40
40 41
26 41
32
30
31 35 31
32 35 33
41
52:  24 38 41
53:  39 40 41
54:  40 41 43
55:  39 41 52
56:  39 41 57
57:  24 41 43
58:  41 49 52
59:  39 42
60:  43 55
61:  39 48
62:  51 58
63:  53 64
64:  54 58
65:  60 61
66:  57 62
67:  62 65
68:  66 67 69
69:  69 71
10: 5 28 31
11: 5 28 50
12: 5 31 32
13: 5 32 50
14: 5 51 59
15: 5 54
16: 6 30
17: 6 50
35 35
35 46
46 60 24 26
56 65
  What do we see about Partner 13?
 69 cliques found.
    1: 13 39 55
2: 13 54 56
3: 13 24 31
4: 13 39 52
5: 13 64
6: 13 67
7: 13 65 68
8: 13 71
9: 4 41
56 57 65
18:  6 58
19:  7 64
20:  11 54
21:  11 39 56
22:  11 43
23:  12 24 26
24:  12 42
25:  12 62
26:  1 41
27:  17 45
28:  19 28
29:  19 28 29
30:  19 28 45
31:  19 22
32:  19 42
33:  19 35
34:  20 21
35: 21 26
36: 21 26
37: 21 24
38: 22 31
39: 25 28
40: 26 30
41: 26 29
42: 28 70
43: 28 30
44: 24 28
45: 28 63
46: 29 34
47: 30 31
48: 30 31
49: 30 59
50: 32 63
51: 38 40
27 40
40 41
26 41
32
30
31 35 31
32 35 33
41
52:  24 38 41
53:  39 40 41
54:  40 41 43
55:  39 41 52
56:  39 41 57
57:  24 41 43
58:  41 49 52
59:  39 42
60:  43 55
61:  39 48
62:  51 58
63:  53 64
64:  54 58
65:  60 61
66:  57 62
67:  62 65
68:  66 67 69
69:  69 71
10: 5 28 31
11: 5 28 50
12: 5 31 32
13: 5 32 50
14: 5 51 59
15: 5 54
16: 6 30
17: 6 50
35 35
35 46
46 60 24 26
56 65
  What do we see about Partner 13?
 Has many groups of close-knit friends, but usually with associates
  69 cliques found.
    1: 13 39 55
2: 13 54 56
3: 13 24 31
4: 13 39 52
5: 13 64
6: 13 67
7: 13 65 68
8: 13 71
9: 4 41
56 57 65
18:  6 58
19:  7 64
20:  11 54
21:  11 39 56
22:  11 43
23:  12 24 26
24:  12 42
25:  12 62
26:  1 41
27:  17 45
28:  19 28
29:  19 28 29
30:  19 28 45
31:  19 22
32:  19 42
33:  19 35
34:  20 21
35: 21 26
36: 21 26
37: 21 24
38: 22 31
39: 25 28
40: 26 30
41: 26 29
42: 28 70
43: 28 30
44: 24 28
45: 28 63
46: 29 34
47: 30 31
48: 30 31
49: 30 59
50: 32 63
51: 38 40
27 40
40 41
26 41
32
30
31 35 31
32 35 33
41
52:  24 38 41
53:  39 40 41
54:  40 41 43
55:  39 41 52
56:  39 41 57
57:  24 41 43
58:  41 49 52
59:  39 42
60:  43 55
61:  39 48
62:  51 58
63:  53 64
64:  54 58
65:  60 61
66:  57 62
67:  62 65
68:  66 67 69
69:  69 71
10: 5 28 31
11: 5 28 50
12: 5 31 32
13: 5 32 50
14: 5 51 59
15: 5 54
16: 6 30
17: 6 50
35 35
35 46
46 60 24 26
56 65
  What do we see about Associate 41?
 69 cliques found.
     1: 13 39 55
2: 13 54 56
3: 13 24 31
4: 13 39 52
5: 13 64
6: 13 67
7: 13 65 68
8: 13 71
9: 4 41
56 57 65
18:  6 58
19:  7 64
20:  11 54
21:  11 39 56
22:  11 43
23:  12 24 26
24:  12 42
25:  12 62
26:  1 41
27:  17 45
28:  19 28
29:  19 28 29
30:  19 28 45
31:  19 22
32:  19 42
33:  19 35
34:  20 21
35: 21 26
36: 21 26
37: 21 24
38: 22 31
39: 25 28
40: 26 30
41: 26 29
42: 28 70
43: 28 30
44: 24 28
45: 28 63
46: 29 34
47: 30 31
48: 30 31
49: 30 59
50: 32 63
51: 38 40
27 40
40 41
26 41
32
30
31 35 31
32 35 33
41
52:  24 38 41
53:  39 40 41
54:  40 41 43
55:  39 41 52
56:  39 41 57
57:  24 41 43
58:  41 49 52
59:  39 42
60:  43 55
61:  39 48
62:  51 58
63:  53 64
64:  54 58
65:  60 61
66:  57 62
67:  62 65
68:  66 67 69
69:  69 71
56 65
   10: 5 28 31
11: 5 28 50
12: 5 31 32
13: 5 32 50
14: 5 51 59
15: 5 54
16: 6 30
17: 6 50
35 35
35 46
46 60 24 26
 
  What do we see about Associate 41?
 Has lot of complete triads, especially with pretty senior associates
and has dyadic relations with super senior partners 1 and 4
  69 cliques found.
     1: 13 39 55
2: 13 54 56
3: 13 24 31
4: 13 39 52
5: 13 64
6: 13 67
7: 13 65 68
8: 13 71
9: 4 41
56 57 65
18:  6 58
19:  7 64
20:  11 54
21:  11 39 56
22:  11 43
23:  12 24 26
24:  12 42
25:  12 62
26:  1 41
27:  17 45
28:  19 28
29:  19 28 29
30:  19 28 45
31:  19 22
32:  19 42
33:  19 35
34:  20 21
35: 21 26
36: 21 26
37: 21 24
38: 22 31
39: 25 28
40: 26 30
41: 26 29
42: 28 70
43: 28 30
44: 24 28
45: 28 63
46: 29 34
47: 30 31
48: 30 31
49: 30 59
50: 32 63
51: 38 40
27 40
40 41
26 41
32
30
31 35 31
32 35 33
41
52: 24 38 41
53: 39 40 41
54: 40 41 43
55: 39 41 52
56: 39 41 57
57: 24 41 43
58: 41 49 52
59: 39 42
60: 43 55
61: 39 48
62: 51 58
63: 53 64
64: 54 58
65: 60 61
66: 57 62
67: 62 65
68: 66 67 69
69: 69 71
56 65
   10: 5 28 31
11: 5 28 50
12: 5 31 32
13: 5 32 50
14: 5 51 59
15: 5 54
16: 6 30
17: 6 50
35 35
35 46
46 60 24 26
 
  Clique analysis for group size>=2
 Lots of “groups,” almost all of which are quite small
 Lots of overlap in groups for some nodes
 Not a lot of overall group structure ... so let’s make it have to be larger groups, like size>=3
 
  What do we find?
 36 cliques of size 3 or greater were found:
   36 1-cliques found.
   1:  13 39 55 56 57
2: 13 54 56 65
   3:  13 24 31
   4:  13 39 52
5: 13 65 68
6: 5 28 31 35
7: 5 28 50
8: 5 31 32 35
9: 5 32 50
  10:  5 51 59
  11:  11 54 56 65
  12:  11 39 56
  13:  12 24 26
  14:  19 28 35 46
  15:  19 28 29
  16:  19 28 45
  17:  19 35 46 60
18:  20 21 24 26
19:  21 26 27 40
20:  21 26 40 41
21:  21 24 26 41
22:  22 31 32
23:  25 28 30
24:  28 30 31 35
25:  24 28 31
26:  30 31 32 35
27:  30 31 33
28:  38 40 41
29:  24 38 41
30:  39 40 41
31:  40 41 43
32:  39 41 52
33:  39 41 57
34:  24 41 43
35:  41 49 52
36:  66 67 69
  What do we find?
 Same as before, but just no pairs left, so only 36 “groups”
 Big winners are 13, 24, 28, and 41
   36 1-cliques found.
   1:  13 39 55 56 57
2: 13 54 56 65
   3:  13 24 31
   4:  13 39 52
5: 13 65 68
6: 5 28 31 35
7: 5 28 50
8: 5 31 32 35
9: 5 32 50
  10:  5 51 59
  11:  11 54 56 65
  12:  11 39 56
  13:  12 24 26
  14:  19 28 35 46
  15:  19 28 29
  16:  19 28 45
  17:  19 35 46 60
18:  20 21 24 26
19:  21 26 27 40
20:  21 26 40 41
21:  21 24 26 41
22:  22 31 32
23:  25 28 30
24:  28 30 31 35
25:  24 28 31
26:  30 31 32 35
27:  30 31 33
28:  38 40 41
29:  24 38 41
30:  39 40 41
31:  40 41 43
32:  39 41 52
33:  39 41 57
34:  24 41 43
35:  41 49 52
36:  66 67 69
  What if we did size>=4?
 We would have 13 “groups” then
71
13 cliques found.
   1:  13 39 55 56 57
2: 13 54 56 65
3: 5 28 31 35
4: 5 31 32 35
5: 11 54 56 65
6: 19 28 35 46
7: 19 35 46 60
8: 20 21 24 26
9: 21 26 27 40
  10:  21 26 40 41
  11:  21 24 26 41
  12:  28 30 31 35
  13:  30 31 32 35
  
  Summary on cliques, size>2
 We now have many fewer groups, but we have a really stringent requirement that everyone be friends with everyone else completely
 What if we relaxed that assumption? We let people be in groups if they were within 2 steps on a path to each other (i.e., “friend of a friend”) level. What becomes of the group structure, then?
 
  A digression on clustering ...
  The distance matrix of US cities
 It looks like this:
> cm
      Atl  Chi  Den Hous   LA  Mia  NYC   SF  Sea   DC
Atl     0  587 1212  701 1936  604  748 2139 2182  543
Chi   587    0  920  940 1745 1188  713 1858 1737  597
Den  1212  920    0  879  831 1726 1631  949 1021 1494
Hous  701  940  879    0 1374  968 1420 1645 1891 1220
LA   1936 1745  831 1374    0 2339 2451  347  959 2300
Mia   604 1188 1726  968 2339    0 1092 2594 2734  923
NYC   748  713 1631 1420 2451 1092    0 2571 2408  205
SF   2139 1858  949 1645  347 2594 2571    0  678 2442
Sea  2182 1737 1021 1891  959 2734 2408  678    0 2329
DC    543  597 1494 1220 2300  923  205 2442 2329    0
  
  Multidimensional Scaling of Cities
 
  Multidimensional Scaling of Cities
 
  Multidimensional Scaling of Cities -- Not bad drawing ....
  
  How did I do this?
 Like such:
fit <- cmdscale(cm, eig = TRUE, k = 2)
x <- fit$points[, 1]
y <- fit$points[, 2]
x <- 0 - x
y <- 0 - y
plot(x, y, pch = 19, xlim = range(x) + c(0, 600))
text(x, y, pos = 4, labels = city.names)
  
  The distance matrix again
 It looks like this:
> cm
      Atl  Chi  Den Hous   LA  Mia  NYC   SF  Sea   DC
Atl     0  587 1212  701 1936  604  748 2139 2182  543
Chi   587    0  920  940 1745 1188  713 1858 1737  597
Den  1212  920    0  879  831 1726 1631  949 1021 1494
Hous  701  940  879    0 1374  968 1420 1645 1891 1220
LA   1936 1745  831 1374    0 2339 2451  347  959 2300
Mia   604 1188 1726  968 2339    0 1092 2594 2734  923
NYC   748  713 1631 1420 2451 1092    0 2571 2408  205
SF   2139 1858  949 1645  347 2594 2571    0  678 2442
Sea  2182 1737 1021 1891  959 2734 2408  678    0 2329
DC    543  597 1494 1220 2300  923  205 2442 2329    0
  
  Hierarchical Clustering of City Distances
 
  How did I do this?
 Like such:
c=read.csv(file.choose(),header=TRUE,check.names=FALSE, row.names=1) # Cities.csv #
cm=as.matrix(c)
plot(hclust(dist(cm)))
  
  Hierarchical clustering of lawyers
  The problem of clique overlap
 As we can see, sometimes it is difficult to make out the larger group structure with so many small, super-cohesive groups
 The proposed solution to this problem is to perform hierarchical clustering on the co-occurence matrix of clique overlaps
 
  What is a hierarchical clustering?
 Puts things that are “closer together” on some dimension together, but puts things that are far apart, far away from each other
 In this case, nodes are “close together” if they are in many of the same cliques -- and are far apart, if they do not share any cliques in common
 
  Remember? -- Clique analysis 69 cliques found.
    1: 13 39 55
2: 13 54 56
3: 13 24 31
4: 13 39 52
5: 13 64
6: 13 67
7: 13 65 68
8: 13 71
9: 4 41
56 57 65
18:  6 58
19:  7 64
20:  11 54
21:  11 39 56
22:  11 43
23:  12 24 26
24:  12 42
25:  12 62
26:  1 41
27:  17 45
28:  19 28
29:  19 28 29
30:  19 28 45
31:  19 22
32:  19 42
33:  19 35
34:  20 21
35: 21 26
36: 21 26
37: 21 24
38: 22 31
39: 25 28
40: 26 30
41: 26 29
42: 28 70
43: 28 30
44: 24 28
45: 28 63
46: 29 34
47: 30 31
48: 30 31
49: 30 59
50: 32 63
51: 38 40
27 40
40 41
26 41
32
30
31 35 31
32 35 33
41
52: 24 38 41
53: 39 40 41
54: 40 41 43
55: 39 41 52
56: 39 41 57
57: 24 41 43
58: 41 49 52
59: 39 42
60: 43 55
61: 39 48
62: 51 58
63: 53 64
64: 54 58
65: 60 61
66: 57 62
67: 62 65
68: 66 67 69
69: 69 71
10: 5 28 31
11: 5 28 50
12: 5 31 32
13: 5 32 50
14: 5 51 59
15: 5 54
16: 6 30
17: 6 50
35 35
35 46
46 60 24 26
56 65
Clique overlaps
   
  Hierarchical cluster analysis
  kkkk
69 cliques found.
   1: 13 39 55
2: 13 54 56
3: 13 24 31
4: 13 39 52
5: 13 64
6: 13 67
7: 13 65 68
8: 13 71
9: 4 41
56 57 65
18:  6 58
19:  7 64
20:  11 54
21:  11 39 56
22:  11 43
23:  12 24 26
24:  12 42
25:  12 62
26:  1 41
27:  17 45
28:  19 28
29:  19 28 29
30:  19 28 45
31:  19 22
32:  19 42
33:  19 35
34:  20 21
35:  21 26 27 40
36:  21 26 40 41
37:  21 24 26 41
38:  22 31 32
39:  25 28 30
40:  26 30
41:  26 29
42:  28 70
43:  28 30 31 35
44:  24 28 31
45:  28 63
46:  29 34
47:  30 31 32 35
48:  30 31 33
49:  30 59
50:  32 63
51:  38 40 41
10: 5 28 31
11: 5 28 50
12: 5 31 32
13: 5 32 50
14: 5 51 59
15: 5 54
16: 6 30
17: 6 50
35 35
35 46
46 60 24 26
56 65
  Big divides at the bottom
 There is a divide into two big cliques here:
                              18:  6 58
                              19:  7 64
                              20:  11 54 56 65
                              21:  11 39 56
                              22:  11 43
                              23:  12 24 26
                              24:  12 42
                              25:  12 62
                              26:  1 41
                              27:  17 45
                              28:  19 28 35 46
                              29:  19 28 29
                              30:  19 28 45
                              31:  19 22
                              32:  19 42
                              33:  19 35 46 60
                              34:  20 21 24 26
35:  21 26 27 40
36:  21 26 40 41
37:  21 24 26 41
38:  22 31 32
39:  25 28 30
40:  26 30
41:  26 29
42:  28 70
43:  28 30 31 35
44:  24 28 31
45:  28 63
46:  29 34
47:  30 31 32 35
48:  30 31 33
49:  30 59
50:  32 63
51:  38 40 41
     
  Further sub-divides at the top
Partner 13 is mostly part of this group of 54, 11, 56, and 65
    18:  6 58
19:  7 64
20:  11 54 56 65
21:  11 39 56
22:  11 43
23:  12 24 26
24:  12 42
25:  12 62
26:  1 41
27:  17 45
28:  19 28 35 46
29:  19 28 29
30:  19 28 45
31:  19 22
32:  19 42
33:  19 35 46 60
34:  20 21 24 26
35:  21 26 27 40
36:  21 26 40 41
37:  21 24 26 41
38:  22 31 32
39:  25 28 30
40:  26 30
41:  26 29
42:  28 70
43:  28 30 31 35
44:  24 28 31
45:  28 63
46:  29 34
47:  30 31 32 35
48:  30 31 33
49:  30 59
50:  32 63
51:  38 40 41
 
  2. N-cliques
  N-cliques
 As with cliques in general, an n-clique with an path length of n=1 is simply the original clique formula
 But if we choose an n>1, then this allows us to include people who do not directly know each other, but include them in the same group, because they are connected by some degrees of separation
 
  72 n-cliques of n=2 and size 3+
  1:  13 24 31 39 52 54 55 56
2:  13 24 31 39 43 52 54 55
3:  13 24 31 39 41 43 52 55
4:  13 21 24 26 31 38 39 41
5:  12 13 21 24 26 31 38 39
6:  12 13 24 31 39 43 57 65
57 64 65
56 57 65
56 57
43 52 57
41 43 57
67 68 71
31:  11 13 24 39 41 42 55 56 57 62
32:  5 11 13 24 54 56 65
33:  1 4 21 24 26 38 39 40 41 43 49 52 57
7:  5 13 22 24 28 30 31
8:  5 13 24 28 31 32 35
9:  5 13 24 31 54 56 65
32 33 35 54
40 41 43
30 40 41
40 41 43
41 43 49
40 41 43
40 41 43
40 41
52 57
42 57
52 57 57
10:  12 13 20 21 24 26
11:  12 13 20 21 24 26
12:  13 24 26 28 30 31
13:  13 24 28 31 43 54
14:  5 19 24 25 28 29 30 31 35 45 46 50 63 70
15:  5 19 22 24 28 29 30 31 35 45 46 50 63
16:  19 24 25 26 28 29 30 31 35
17:  12 19 24 26 28 29 30 31
18:  5 19 24 25 28 30 31 32 35 46 50 63
19:  5 19 22 24 28 30 31 32 35 46 50 63
28 31 38
28 30 31
32 33 35
41 43 41
34:  12 20 21 24 26 27 38
35:  12 20 21 24 26 27 29
36:  12 21 24 26 27 38 39
37:  13 21 24 26 38 39 40
38:  12 13 21 24 26 38 39
39:  12 13 20 21 24 26 38
40:  12 13 20 21 24 26 30
41:  13 24 26 39 40 41 42
42:  12 13 24 26 39 40 41
43:  12 24 26 29 40 41 42
44:  12 13 24 26 39 41 42
45:  12 13 24 26 28 41 42
46:  13 22 24 28 35 42
47:  13 24 26 28 35 42
48:  19 22 24 28 29 35 42
49:  19 24 26 28 29 35 42
50:  12 19 24 26 28 29 42
51:  12 24 26 28 29 41 42
52:  12 19 24 26 39 42
53:  12 13 24 39 57 62 65
54:  6 25 26 28 30 31 32 33 35 59
57 62
45 46
61: 7 13 53 64
62: 17 19 28 45
63: 19 26 28 29
64: 11 13 39 40
65:  5 11 13 54 56 58 65
66: 5 13 30 58
67:  5 19 22 28 29 30 31 35 45 46 60
68:  5 19 22 28 30 31 32 35 46 60
69:  19 22 28 29 35 42 45 46 60
70:  19 35 46 60 61
71:  13 66 67 69 71
 20:  19 24 25 26 28 30
21:  12 19 24 26 31 39
22:  24 25 26 28 30 31
23:  5 24 25 28 30 31 32 33 35
24:  12 20 21 24 26 28 29 30 31
25:  5 24 28 31 32 35 50 54
26:  11 13 24 39 43 52 54 55 56
27:  11 13 24 39 40 41 43 52 55
28:  11 13 24 39 40 41 42 52 55
29:  11 13 24 39 52 54 55 56 57
30:  11 13 24 39 54 55 56 57 62
31 32 35
32 33 35
34
41 42 48 52 55 56 57
41
57 65
56 57
56 57
65 68
65 68
55:  5 6 25 28 30 31 32
56:  5 6 25 28 30 31 32
57:  5 6 28 30 31 32 35
58:  5 6 28 31 32 35 50
59:  5 6 50 51 54 58 59
60:  5 6 30 50 51 58 59
33 35 59
35 50 59
50 51 59
51 54 59
  Summary on this 2n-clique, size 3+
 At the n=2 level, some nodes are everywhere. Partner 24 was in 53 of these 71 groups, and was in the same groups with Partner 13 31 times, and with many others 20+ times
 Partners from 19 to 35 have a lot of reciprocal ties together, especially at the n=2 level
 Another group of high overlap is Associates 39 through 44
 A few other pockets of high overlap remain too
 
  What about 2n-cliques, size>9?
 Same as before, but *only* 34 sized 10 or larger cliques
 Many nodes overlap and are in 20+ of those 34 possible cliques
 
  N-cliques-- overlaps?
 These n-cliques will still often be small
 One way to see cliques in a bigger context is by doing an analysis of the overlapping structure of the n-cliques. We gain information on the number of times each pair of actors are in the same n-clique and see an hierarchical clustering based upon this information.
 Look at the 2n-cliques of size 10 and greater ...
 
  N-cliques-- overlaps?
   Partners 19 and
28 are in 3 cliques together for instance
  N-cliques-- overlaps?
    Part ners
19 and 28 are in 3 cliqu es
toget
   We can see how one “group” is nested within another
 
   Partners 19, 28, 31 and 35 are nested within the larger group, which also includes Partners 5, 30 and 32 and Associates 46 and 60, etc.
  
  3. K-cores
 Each node within a K-core is connected to at least K other nodes in the group
 For instance, a 3-core subgraph consists of nodes connected to at least 3 other nodes in the group
 As K increases, the remaining relations will appear increasingly dense, as less connected nodes drop out of the analysis or graph
 
  K-Core partitioning
 K-cores up to 4 are found
    On the next slide, the darker, the higher the K
  K-Cores
 
  K-Cores
 
  4. K-plexes
 How many ties does the group need not share?
 We can specify that nodes need not be connected to up to K other nodes in at least an N-sized group
  
  How many K-plexes do we find?
 We find 17 k-plexes when for 5 or larger groups, they cannot be connected to up to 2 of the nodes
17 k-plexes found.
   1:  5 28 30 31 32 35
2: 5 28 31 32 50
3: 5 28 32 35 50
   4:  11 13 39 54 56
   5:  11 13 39 56 65
   6:  11 13 54 56 65
   7:  13 39 41 52 57
   8:  13 39 55 56 57
   9:  19 28 35 46 60
  10:  20 21 24 26 41
  11:  21 24 26 40 41
  12:  21 24 38 40 41
  13:  21 24 40 41 43
  14:  21 26 27 40 41
  15:  24 26 38 40 41
  16:  24 26 40 41 43
  17:  24 38 40 41 43
  
  K-plexes do we find?
 We find 1 k-plex when for 6 or larger groups, they may not be connected to up to 2 of the nodes
K-PLEX
--------------------------------------------------------------------------------
  Value of K:
Minimum Set Size =
Input dataset:
2014\Networks\SNA\lazega-net-friendship-Sym)
1 k-plexes found.
   1:  5 28 30 31 32 35
2 (each member of a K-plex of size N has N-K ties to other members)
6
lazega-net-friendship-Sym (C:\Users\Greg\Documents\Spring
  In conclusion (for now)
 Did we find the groups we were looking for by proceeding “bottom up”?
 Were the groups too small? Did we need more or less number of groups?
 Did we demand too much cohesion of them? Or not enough?
 
  How to do some of this in R
   New data
  It looks like this:
   As a matrix
  It looks like this:
     It looks like this:
As an ego- network graph
  The socio-matrix
 Let’s remove Citibank, since it has a connection to everyone (so we can ask: who is connected to each other without the need of Citibank?)
c=read.csv(file.choose(),header=TRUE,check.names=FALSE, row.names=1)
cm=as.matrix(c) # coerces the data set as a matrix
cmg=graph.adjacency(cm,mode="undirected",weighted=NULL)
plot(cmg)
  
   As a graph
  It looks like this:
  The k-cliques
 Find all of the cliques that are 3 and bigger
 > Mcmgcliques3=maximal.cliques(cmg, min=3)
 > Mcmgcliques3
 [[1]]
 [1] 13 18 10
 [[2]]
 [1] 13  4  6
 [[3]]
 [1]  8 19 20
 [[4]]
 [1] 21 10 18
 [[5]]
 [1]  3  1 10  7
 [[6]]
 [1]  2 15 18 16
  
  The k-cliques
 Turn the k-cliques into a dataframe ...
   > require(devtools)
> source_gist(4676064)
> cliques2 = as.data.frame
(cmgcliques2)
> cliques2
   Col1 Col2 Col3 Col4
1 151618NA 2 101821NA 3 101318NA 4 81920NA 5 4 6 13 NA 6 3 7 10 NA 7 21618NA 8 21518NA 9 21516NA 10 1 710NA 11 1 310NA 12 1 3 7 NA 13 21 25 NA NA 14 21 24 NA NA [omitted]
50 1 3 7 10 51 2151618
  Another approach: Clustering on correlations
 Which nodes go together because they have the most ties to similar other alters
friend_cors <- cor(cm)
  
  Correlations among companies
 Which ones have similar linkages ...
friend_cors <- cor(cm)
  
  Correlations among companies
 Find all of the cliques that are 2 and bigger
  > head(friend_cors)
Aetna                 1.00000000  0.1071429
Alcoa                 0.10714286  1.0000000
American Airlines     0.40476190 -0.1904762
AT&T                 -0.12869789 -0.1286979
Automatic Data Proc. -0.08908708  0.4677072
Calpine
Aetna
Alcoa
American Airlines
AT&T
Automatic Data Proc.
Calpine
 0.40476190 -0.12869789
-0.19047619 -0.12869789
 1.00000000 -0.12869789
-0.12869789  1.00000000
-0.08908708 -0.06019293
-0.12869789  0.45652174
-0.08908708 -0.12869789  0.40476190
 0.46770717 -0.12869789 -0.19047619
-0.08908708 -0.12869789  0.40476190
-0.06019293  0.45652174 -0.12869789
 1.00000000 -0.06019293 -0.08908708
-0.06019293  1.00000000 -0.12869789
Aetna      Alcoa American Airlines        AT&T Automatic Data Proc.     Calpine     Comcast Cummins Engine      DuPont
-0.12869789 -0.1286979
Electronic Data Sys. Estée Lauder Ford Motors Halliburton
HCA Johnson & Johnson     Lucent
 0.26569371  -0.12869789 -0.08908708  0.05455447  0.27348302
 0.01021899  -0.12869789 -0.08908708  0.05455447  0.27348302
 0.26569371   0.27348302 -0.08908708  0.05455447  0.27348302
 0.17951966  -0.08695652 -0.06019293  0.22116293 -0.08695652
-0.11470787  -0.06019293 -0.04166667 -0.10206207 -0.06019293
 0.17951966  -0.08695652 -0.06019293  0.22116293 -0.08695652
Raytheon Schlumberger      Target Time Warner United Technologies
-0.16116459  -0.16116459  0.10714286  0.51035454
-0.16116459  -0.16116459  0.10714286  0.17459498
-0.16116459  -0.16116459  0.10714286 -0.16116459
-0.10889310  -0.10889310 -0.12869789 -0.10889310
Aetna
Alcoa
American Airlines
AT&T
Automatic Data Proc. -0.07537784  -0.07537784 -0.08908708 -0.07537784
Calpine              -0.10889310  -0.10889310 -0.12869789 -0.10889310
                                            -0.12869789 -0.12869789
                                            -0.12869789 -0.12869789
                                            -0.12869789 -0.12869789
                                            -0.08695652 -0.08695652
                                            -0.06019293 -0.06019293
                                            -0.08695652 -0.08695652
                                             Lyondell    PepsiCo
                    0.10714286 -0.2182179 -0.12869789 0.26569371
                    0.40476190  0.3273268 -0.12869789 0.26569371
                   -0.19047619  0.3273268 -0.12869789 0.01021899
                   -0.12869789 -0.1474420  0.45652174 0.17951966
                   -0.08908708  0.4082483 -0.06019293 0.36324158
                   -0.12869789 -0.1474420  0.45652174 0.17951966
                  Xerox Yum! Brands
-0.08908708 -0.08908708 -0.08908708
-0.08908708 -0.08908708 -0.08908708
-0.08908708 -0.08908708 -0.08908708
-0.06019293 -0.06019293 -0.06019293
-0.04166667 -0.04166667 -0.04166667
-0.06019293 -0.06019293 -0.06019293
   The k-cliques
 Find all of the cliques that are 2 and bigger
 
  How did I do that?
 The code:
install.packages("lattice")
library(lattice)
rgb.palette <- colorRampPalette(c("blue", "yellow"), space = "rgb")
levelplot(friend_cors, main="correlation matrix", xlab="", ylab="",
col.regions=rgb.palette(120), cuts=100, at=seq(0,1,0.01))
  
  Hierarchically cluster them ...
 The code:
friend_dist <- as.dist(1-friend_cors)
install.packages("cluster")
library("cluster")
# now cluster the correlations
friend_hclust <- hclust(friend_dist)
plot(friend_hclust)
  
   The k-cliques
 Find all of the cliques that are 2 and bigger
 
  Hierarchically cluster raw distance
 The code:
plot(hclust(dist(cm)))
  
   The k-cliques
 Find all of the cliques that are 2 and bigger
 
  Hierarchically cluster raw distance
 The code:
heatmap(cm,
#        distfun = function(x) {as.dist(1-cor(x))},
#       (comment out prev line to get euclidean distance clustering)
        col = grey(0:1)[c(2,1)],
        main="Adjacency Matrix")
  
   The k-cliques
 Find all of the cliques that are 2 and bigger
 
  Hierarchically cluster Jaccard coeff.
 The code:
install.packages("vegan")
library(vegan)
dist.mat<-vegdist(cm,method="jaccard")
plot(hclust(dist.mat))
  
   The k-cliques
 Find all of the cliques that are 2 and bigger
 
  Actor-by-actor clique co-occurrence
 Actor-by-Actor Clique Co-Membership Matrix (FROM UCINET)
                                               1 1 1 1 1
1 1 1 11 2222 22 5 6 7 89 0123 45 J L L PR STTU XY - - - -- ---- -- 0 0 0 00 0000 00 1 1 0 10 0000 00 0 0 0 00 0000 00 0 0 0 00 0000 00 0 0 0 00 0000 00 0 0 0 00 0000 00 0 0 0 00 0000 00 0 0 0 01 1000 00 0 0 0 00 0000 00 0 0 0 20 0100 00 0 0 0 00 0000 00 0 0 0 00 0000 00 0 0 0 10 0000 00 0 0 0 00 0000 00 1 1 0 10 0000 00 1 1 0 10 0000 00 0 0 0 00 0000 00 1 1 0 30 0100 00 0 0 0 01 1000 00 0 0 0 01 1000 00
1 2 3 4 5 6 7 8 9
10
11
12
13
14
15
16
17
18
19
20
Aetna
               Alcoa
   American Airlines
                AT&T
Automatic Data Proc.
             Calpine
             Comcast
      Cummins Engine
              DuPont
Electronic Data Sys.
        Estee Lauder
         Ford Motors
         Halliburton
                 HCA
   Johnson & Johnson
              Lucent
            Lyondell
             PepsiCo
            Raytheon
        Schlumberger
1 2 3 4 5 6 7 8 9 A A A A A C C C D - - - - - - - - - 1 0 1 0 0 0 10 0 0 1 0 0 0 0 00 0 1 0 1 0 0 0 10 0 0 0 0 1 0 1 00 0 0 0 0 0 0 0 00 0 0 0 0 1 0 1 00 0 1 0 1 0 0 0 10 0 0 0 0 0 0 0 01 0 0 0 0 0 0 0 00 0 1 0 1 0 0 0 10 0 0 0 0 0 0 0 00 0 0 0 0 0 0 0 00 0 0 0 0 1 0 1 00 0 0 0 0 0 0 0 00 0 0 1 0 0 0 0 00 0 0 1 0 0 0 0 00 0 0 0 0 0 0 0 00 0 0 1 0 0 0 0 00 0 0 0 0 0 0 0 01 0 0 0 0 0 0 0 01 0
0 1 2 3 4 E E F H H - - - - - 1 00 0 0 0 00 0 0 1 00 0 0 0 00 1 0 0 00 0 0 0 00 1 0 1 00 0 0 0 00 0 0 0 00 0 0 3 00 1 0 0 00 0 0 0 00 0 0 1 00 2 0 0 00 0 0 0 00 0 0 0 00 0 0 0 00 0 0 2 00 1 0 0 00 0 0 0 00 0 0
21                Target  0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0
  Hierarchically cluster clique co-
occurrences
 The code:
u=read.csv(file.choose(),header=TRUE,check.names=FALSE, row.names=1)
um=as.matrix(u) # coerces the data set as a matrix
plot(hclust(dist(um)))
  
   The k-cliques
 Find all of the cliques that are 2 and bigger
 
  5. A few top-down methods
  “Top down” approaches
 We work from the whole network and try to break it apart into components
 
  The friendship network ...
 The friendship network looks like this:
 258 total reciprocated ties for 71 lawyers
 Blue are men and pink are women
 Circles are partners and squares are associates
 Size of the label is age
 Color of label is practice (red=1 and green=2)
 Density is about 5%
 
   The friendship network ...
  1. Components
  Components
 There is just 1 giant completed connected component
 And then the singletons ...
 
  2. Girvan-Newman algorithm
  Girvan-Newman algorithm
 We want to find the tightly-knit regions of a graph, with sparse connections between them
 Looking for instances where edges between the groups occur at lower “density” than edges within the groups
 Known as graph partitioning or community detection
 
  Girvan-Newman algorithm
 Divisive technique that looks to find the edges with the highest betweenness
 Edge betweenness is super similar to node betweenness: the most “traffic” over the shortest path
 
  Girvan-Newman algorithm
 The idea is that if we remove the key edges that carry the most traffic this should (start to) split different regions made up of more dense clusters
 Then, having removed the edges with highest betweenness, we recalculate the edge betweenness, and then remove those new edges with highest betweenness -- and break up new clusters
 And so on ...
 
  Girvan-Newman algorithm
 Measure of fit is Q, modularity
 Modularity compares the number of internal links found to how many
would be found if links were distributed at random
 Modularity has turned into a huge thing in the last few years
 
  The friendship network ...
 The friendship network looks like this:
 258 total reciprocated ties for 71 lawyers
 Colors correspond with Girvan-Newman communities (pre-set to 20)
 Circles are partners and squares are associates
 Size of the node is degree centrality
 Size of label is betweenness centrality
 Color of label is practice (red=litigation and green=corporate)
 Color of the rims of the nodes is gender (blue=mean, pink=women)
 
   The friendship network ...
  Girvan-Newman on the Citibank data
 The code:
gn = edge.betweenness.community (cmg, directed = TRUE, edge.betweenness
= TRUE, merges = TRUE,
    bridges = TRUE, modularity = TRUE, membership = TRUE)
head(gn)
plot(gn, cmg)
memb = data.frame(gn$membership)
memb
  
   The k-cliques
 Find all of the cliques that are 2 and bigger
 
  3. Factions algorithm
  Factions algorithm
 Pre-determine a certain number of n “groups”
 Try to place nodes into groups such that density within the groups
approaches 1, while density outside of those groups approaches 0
 Therefore, the closer the sum of all of the densities from within each group is equal to n number of groups, the better the fit
 
  More on factions
FACTIONS (isolates removed)
--------------------------------------------------------------------------------
Measure of fit:                         Hamming
Initial proportion correct: 0.843
Final proportion correct: 0.920
   
  Factions algorithm
Fit based on:
 Initial percent correct: The algorithm starts by randomly sorting nodes into groups, then ...
 Final percent correct: The algorithm improves on that initial random assignment via the principle of maximized density within groups; calculated as the sum of the number of 0s within factions (where - ideally - there should be none) plus the number of 1s on the off- diagonals (where - ideally - there should be none), divided by the total number of network ties present
 
  What counts as a faction?
 
  Density among factions
FACTIONS (isolates removed)
--------------------------------------------------------------------------------
Measure of fit:                         Hamming
Initial proportion correct: 0.843
Final proportion correct: 0.920
Density Table
           1    2    3    4    5    6    7    8    9   10
        ---- ---- ---- ---- ---- ---- ---- ---- ---- ----
    1   0.58 0.03 0.11 0.04 0.03 0.04 0.00 0.00 0.04 0.03
    2   0.03 0.57 0.00 0.09 0.00 0.06 0.03 0.07 0.19 0.00
    3   0.11 0.00 0.80 0.07 0.04 0.07 0.07 0.00 0.03 0.29
    4   0.04 0.09 0.07 0.30 0.00 0.00 0.00 0.00 0.00 0.05
    5   0.03 0.00 0.04 0.00 0.33 0.00 0.00 0.00 0.00 0.00
    6   0.04 0.06 0.07 0.00 0.00 0.00 0.00 0.00 0.00 0.00
    7   0.00 0.03 0.07 0.00 0.00 0.00 0.40 0.00 0.00 0.00
    8   0.00 0.07 0.00 0.00 0.00 0.00 0.00 0.47 0.14 0.08
    9   0.04 0.19 0.03 0.00 0.00 0.00 0.00 0.14 0.53 0.00
   10   0.03 0.00 0.29 0.05 0.00 0.00 0.00 0.08 0.00 0.67
 
  The friendship network ...
 The friendship network looks like this:
 258 total reciprocated ties for 71 lawyers
 Colors correspond with Factions algorithm (pre-set 10, singletons
excluded)
 Circles are partners and squares are associates
 Size of the node is degree centrality
 Size of label is betweenness centrality
 Color of label is practice (red=litigation and green=corporate)
 Color of the rims of the nodes is gender (blue=mean, pink=women)
 
   The friendship network ...
  4. Markov clustering algorithm
  Markov clustering algorithm
 Algorithm that seeks to find the right number of groups based on two iterative steps:
1. Expand: where the stochastic (random walk) matrix, M is squared
2. Inflate: where each element in M is raised to an inflation parameter, r, usually 2 (if set higher, fewer clusters will be found)
 Eventually, all the nodes within a cluster will start to flow toward one attractor node, and so any nodes who flow in the same way can be seen as part of the same cluster
 
  What is a random walk?
 Memoryless process
 Someone has equal probability of going in any direction
 In the limit, the probability of the person ending back up at their origin is 1
 
  The friendship network ...
 The friendship network looks like this:
 258 total reciprocated ties for 71 lawyers
 Colors correspond with Markov clustering algorithm
 Circles are partners and squares are associates
 Size of the node is degree centrality
 Size of label is betweenness centrality
 Color of label is practice (red=litigation and green=corporate)
 Color of the rims of the nodes is gender (blue=mean, pink=women)
 
   The friendship network ...
  Walk trap on Citibank data
 The code:
friend_comm_wt <- walktrap.community(cmg, steps=200,modularity=TRUE) # , labels=TRUE)
friend_comm_wt
plot(friend_comm_wt, cmg)
  
   The k-cliques
 Find all of the cliques that are 2 and bigger
 
  Comparing G-N and Walk Trap
 The code:
girvan = data.frame(gn$membership)
str(girvan)
blocks = gBlocks$blocks
str(blocks)
rw = friend_comm_wt$membership
str(rw)
cb <- cbind(girvan, rw)
  
  Comparing G-N and Walk Trap
  The code:
> cb
   gn.membership rw
113 223 313 435 523 635 713 841 953 10 12 11 64 12 64 13 35 14 53 15 23 16 23 17 46
18 22 19 47 20 41 21 72 22 13 23 41 24 72 25 72
  > cor(cb)
gn.membership
rw
gn.membership          rw
   1.00000000 -0.05315497
  -0.05315497  1.00000000
18 22
  5. Cohesive blocking
  Cohesive blocking
 Allows for multiple group memberships at the same time
 
  Cohesive blocking ...
 The code:
gBlocks = cohesive.blocks(cmg, labels = TRUE)
#plotHierarchy(gBlocks$blocks, layout=layout.kamada.kawai)
if (interactive()) {
  plot(gBlocks, cmg)
}
  
   The k-cliques
 Find all of the cliques that are 2 and bigger
 
  6. Many other ideas here ...



 Social Network Analysis (Class 3)
  Gregory M. Eirich QMSS
  Ego networks
 A way to visualize or measure the people closest to me
 This is how I experience my social world; it is hard to see the whole global social network from my own little perspective
 My “local” neighborhood of connections
 Everyone here is directly known to me
 
  My ego network: Level 1
 This is a sociogram
 This is a star graph
 No connections measured to each other
 “Me” is the only connection to the others
  
  My ego network: Level 1.5
 Not just my relationship to them
 But their relationships to each other too
 These are undirected, unvalued ties
  
  My ego network: Level 1.5
 These are undirected, but valued ties
 You can see the lack of ties or strong ties between my mom and my brother with Keira’s parents
 This was made in Gephi
  
  As a one-mode matrix
   This is a symmetric matrix-- the values are the same on either side of the diagonal (because the ties are undirected)
  As an edge-list
   All the pairs of relationships
 By custom, if ties are directed, the sender is listed first and then the receiver
 Attributes can be added to the list
 Very efficient way to store network information
  Why study ego networks?
 We usually are interested in one of the following things about people’s immediate social networks:
- How big are people’s social circles (size, or degree)?
- How closely-knit together is someone’s social circle (density)? - How strong are the connections within someone’s social circle (intensity, or valued density)?
- What kinds of people compose a person’s social circle (composition)?
 
  Question 1a
Do people from different parts of the country have larger or smaller ego networks?
 
  Numgiven-
From time to time, most people discuss important matters with other people. Looking back over the last six months, who are the people with whom you discussed matters important to you? Name up to a maximum of 6 people:
. tab numgiven
  number of |
    persons |
  mentioned |      Freq.     Percent        Cum.
------------+-----------------------------------
 0| 590 12.40
1| 796 16.73
2| 848 17.83
3| 1,402 29.47
4| 473 9.94
5| 443 9.31
6| 205 4.31
12.40
29.14
46.96
76.43
86.38
95.69
                                          100.00
------------+-----------------------------------
Total |      4,757      100.00
  Numgiven-
In R:
> d=read.csv(file.choose())
> library(gmodels)
> CrossTable(d$numgiven, , prop.r=F, prop.c=T, prop.t=F, prop.chisq=F, format="SPSS")
Total Observations in Table:  6029
|0|1|2|3|4| |-----------|-----------|-----------|-----------|-----------| | 759 | 1062 | 1129 | 1651 | 599 | | 12.589% | 17.615% | 18.726% | 27.384% | 9.935% | |-----------|-----------|-----------|-----------|-----------| |5|6|
          |-----------|-----------|
          |      544  |      285  |
          |    9.023% |    4.727% |
          |-----------|-----------|
  Number of Missing Observations: 5037 (45.5178%)
  Ego network size
 Calculated simply as the total number of alters connected to ego
 Also known as “degree”
 
  Ego network size, by geography
 The West is the most social region-- Who knew?
 The South is the least social
  
  Ego network size, by geography
 In R
  
  How did I do that graph?
IN STATA:
ssc install ciplot
recode region (1/2=1 "northeast") (3/4=2 "midwest") (5/7=3 "south") (8/9=4 "west"), gen
(bigreg)
ciplot numgiven, by(bigreg)
IN R:
d$reg[d$region==1 | d$region==2] <- "north"
d$reg[d$region==3 | d$region==4] <- "midwest"
d$reg[d$region==5 | d$region==6 | d$region==7] <- "south"
d$reg[d$region==8 | d$region==9] <- "west"
install.packages("gplots")
library(gplots)
 plotmeans(d$numgiven ~ d$reg, connect=F)
  Question 1b
Do immigrants have smaller ego networks than native-born US citizens?
 
  Ego network size, by nativity
 Immigrants have smaller ego
networks than native-born US citizens
 (Why that really big confidence
interval around immigrants?)
  
  Ego network size, by nativity
 In R
  
  How did I do that graph?
IN STATA:
ciplot numgiven, by(born)
IN R:
d$native=ifelse(d$born==1, "US", "Foreign")
plotmeans(d$numgiven ~ d$native, connect=F)
 
  Question 1c
Are people’s ego networks shrinking over time?
 
  Ego network size, over time
 Looks like a steady decline in the average
number of people others have as confidants
 More on this later ...
  
  Ego network size, over time
 In R
  
  How did I do that graph?
IN STATA:
ciplot numgiven, by(year)
IN R:
plotmeans(d$numgiven ~ d$year, connect=T)
 
  But ...
Are any of these bivariate relationships still visible, after controlling for a variety of factors?
 
  Multivariate analyses ...
. reg numgiven b4.bigreg i.born i.year age educ sex realinc i.race attend
       Source |       SS       df       MS
-------------+------------------------------
       Model |  1794.12116    13   138.00932
    Residual |   9312.0418  4306  2.16257357
-------------+------------------------------
       Total |   11106.163  4319   2.5714663
Number of obs =    4320
F( 13,  4306) =   63.82
Prob > F      =  0.0000
R-squared     =  0.1615
Adj R-squared =  0.1590
Root MSE      =  1.4706
------------------------------------------------------------------------------
    numgiven |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
      bigreg |
          1  |  -.2828005   .0745902    -3.79   0.000    -.4290357   -.1365653
          2  |  -.2956444   .0685798    -4.31   0.000    -.4300962   -.1611927
          3  |  -.3578036   .0659563    -5.42   0.000     -.487112   -.2284952
             |
      2.born |  -.0771545   .0929653    -0.83   0.407    -.2594144    .1051053
| year |
       1987  |  -.3798872   .0546681    -6.95   0.000    -.4870648   -.2727096
       2004  |  -1.057772   .0585842   -18.06   0.000    -1.172627   -.9429171 ....
  Multivariate analyses ...
. reg numgiven b4.bigreg i.born i.year age educ sex realinc i.race attend
(continued)
          ....
             |
         age |  -.0064057   .0013978    -4.58   0.000     -.009146   -.0036654
    educ |
    sex |
realinc |
        |
   race |
 .102674
.1970995
4.71e-06
.0081926
.0456904
8.40e-07
12.53   0.000
 4.31   0.000
 5.60   0.000
.0866123
.1075227
3.06e-06
.1187357
.2866762
6.35e-06
          2  |  -.4501348   .0621511    -7.24   0.000     -.571983   -.3282866
          3  |  -.4087625   .1225808    -3.33   0.001     -.649084   -.1684409
             |
      attend |   .0351995   .0088282     3.99   0.000     .0178916    .0525074
       _cons |   1.796441   .1634287    10.99   0.000     1.476037    2.116846
------------------------------------------------------------------------------
  Multivariate analyses in R
> d$realinc10k=d$realinc/10000
> lm1 = lm(numgiven ~ reg + native + as.factor(year) + age + educ + sex + realinc10k + as.
factor(race) + attend, data=d)
> summary(lm1)
                     Estimate Std. Error t value Pr(>|t|)
(Intercept)          1.192764   0.163610   7.290 3.54e-13 ***
 regnorth
regsouth
regwest
nativeUS
as.factor(year)1987 -0.379037   0.055636  -6.813 1.06e-11 ***
as.factor(year)2004 -1.050907   0.059511 -17.659  < 2e-16 ***
as.factor(year)2010 -0.646945   0.061853 -10.459  < 2e-16 ***
age                 -0.004085   0.001272  -3.211  0.00133 **
educ                 0.101023   0.007464  13.534  < 2e-16 ***
sex                  0.214598   0.041597   5.159 2.57e-07 ***
...
---
Residual standard error: 1.503 on 5438 degrees of freedom
  (5613 observations deleted due to missingness)
Multiple R-squared:  0.1412,    Adjusted R-squared:  0.139
-0.009894   0.063654  -0.155  0.87649
-0.062762   0.052480  -1.196  0.23177
0.267911   0.061967   4.323 1.56e-05 ***
0.206508   0.082693   2.497  0.01254 *
  Multivariate analyses ...
The West is still much more gregarious (about a third of a person more, on average), even net of many things
. reg numgiven b4.bigreg i.born i.year age educ sex realinc i.race attend
        Source |       SS       df       MS
-------------+------------------------------
       Model |  1794.12116    13   138.00932
    Residual |   9312.0418  4306  2.16257357
-------------+------------------------------
       Total |   11106.163  4319   2.5714663
Number of obs =    4320
F( 13,  4306) =   63.82
Prob > F      =  0.0000
R-squared     =  0.1615
Adj R-squared =  0.1590
Root MSE      =  1.4706
------------------------------------------------------------------------------
    numgiven |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
      bigreg |
          1  |  -.2828005   .0745902    -3.79   0.000    -.4290357   -.1365653
          2  |  -.2956444   .0685798    -4.31   0.000    -.4300962   -.1611927
          3  |  -.3578036   .0659563    -5.42   0.000     -.487112   -.2284952
|....
  Multivariate analyses ...
Immigrants are no more isolated than native-born US citizens, once other things correlated with immigrant status are taken into account
. reg numgiven b4.bigreg i.born i.year age educ sex realinc i.race attend
        Source |       SS       df       MS
-------------+------------------------------
       Model |  1794.12116    13   138.00932
    Residual |   9312.0418  4306  2.16257357
-------------+------------------------------
       Total |   11106.163  4319   2.5714663
Number of obs =    4320
F( 13,  4306) =   63.82
Prob > F      =  0.0000
R-squared     =  0.1615
Adj R-squared =  0.1590
Root MSE      =  1.4706
------------------------------------------------------------------------------
    numgiven |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
...
       |
2.born |  -.0771545   .0929653    -0.83   0.407    -.2594144    .1051053
  Multivariate analyses ...
People in 2004 named (on average) 1 whole person less in their ego
networks, compared to 1985, net of many other factors
. reg numgiven b4.bigreg i.born i.year age educ sex realinc i.race attend
        Source |       SS       df       MS
-------------+------------------------------
       Model |  1794.12116    13   138.00932
    Residual |   9312.0418  4306  2.16257357
-------------+------------------------------
       Total |   11106.163  4319   2.5714663
Number of obs =    4320
F( 13,  4306) =   63.82
Prob > F      =  0.0000
R-squared     =  0.1615
Adj R-squared =  0.1590
Root MSE      =  1.4706
------------------------------------------------------------------------------
    numgiven |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
...
year |
       1987  |  -.3798872   .0546681    -6.95   0.000    -.4870648   -.2727096
       2004  |  -1.057772   .0585842   -18.06   0.000    -1.172627   -.9429171 ....
  But ...
Is OLS regression the appropriate way to model this relationship?
 
  What if ...
 Our dependent variable is a count? - and -
 The mean of our dependent variable approximately equals its
variance?
  . sum numgiven, detail
                   number of persons mentioned
  -------------------------------------------------------------
        Percentiles      Smallest
   1%            0              0
   5%            0              0
  10%            0              0       Obs                4757
  25% 1 0
Sum of Wgt.
4757
2.529956
1.613454
2.603234
.2182256
2.392341
 50% 3
              Mean
Largest       Std. Dev.
75% 3 6
90%            5              6
95%            5              6
99%            6              6
Variance
Skewness
Kurtosis
 
  Consider ...
 Poisson regression may be a more appropriate way to model this relationship
 The model is:
Log(μ) = α + βx1 ... + βxi
 Where μ is the expected count of Y
 
  Multivariate Poisson analyses ...
. poisson numgiven b4.bigreg i.born i.year age educ sex realinc i.race attend
 Poisson regression                                Number of obs   =
                                                  LR chi2(13)     =
                                                  Prob > chi2     =
Log likelihood = -7758.9466                       Pseudo R2       =
  4320
700.97
0.0000
0.0432
------------------------------------------------------------------------------
    numgiven |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
      bigreg |
          1  |  -.0988917   .0302702    -3.27   0.001    -.1582202   -.0395633
          2  |  -.1015727   .0278721    -3.64   0.000     -.156201   -.0469445
          3  |  -.1299054   .0268689    -4.83   0.000    -.1825675   -.0772432
             |
      2.born |   -.030382   .0404881    -0.75   0.453    -.1097372    .0489731
| year |
       1987  |  -.1316584   .0221124    -5.95   0.000    -.1749978    -.088319
       2004  |  -.4100074   .0252135   -16.26   0.000    -.4594249   -.3605899
| ...
  Multivariate Poisson analyses ...
. poisson numgiven b4.bigreg i.born i.year age educ sex realinc i.race attend
...
             |
         age |  -.0026504   .0006008    -4.41   0.000    -.0038281   -.0014728
    educ |
    sex |
realinc |
        |
   race |
.0413665
.0815887
1.69e-06
.0035134
 .019306
3.38e-07
11.77   0.000
 4.23   0.000
 5.00   0.000
.0344804
.0437496
1.03e-06
.0482526
.1194277
2.35e-06
          2  |  -.1963646   .0284044    -6.91   0.000    -.2520362   -.1406931
          3  |  -.1713282   .0558694    -3.07   0.002    -.2808301   -.0618262
             |
      attend |   .0135002   .0037098     3.64   0.000     .0062291    .0207713
       _cons |   .5863527   .0695716     8.43   0.000     .4499949    .7227105
------------------------------------------------------------------------------
  Multivariate Poisson analyses ...
The Northeast has a log of an expected count that is 0.099 lower than the West, net of other factors
. poisson numgiven b4.bigreg i.born i.year age educ sex realinc i.race attend
  Poisson regression                                Number of obs   =
                                                  LR chi2(13)     =
                                                  Prob > chi2     =
Log likelihood = -7758.9466                       Pseudo R2       =
  4320
700.97
0.0000
0.0432
------------------------------------------------------------------------------
    numgiven |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
      bigreg |
          1  |  -.0988917   .0302702    -3.27   0.001    -.1582202   -.0395633
          2  |  -.1015727   .0278721    -3.64   0.000     -.156201   -.0469445
          3  |  -.1299054   .0268689    -4.83   0.000    -.1825675   -.0772432
  Multivariate Poisson analyses in R
> glm1 = glm(numgiven ~ reg + native + as.factor(year) + age + educ + sex + realinc10k +
as.factor(race) + attend, family="poisson", data=d)
> summary(glm1)
  Estimate Std. Error z value Pr(>|z|)
0.3556801  0.0699431   5.085 3.67e-07 ***
(Intercept)
regnorth
regsouth
regwest
nativeUS
as.factor(year)1987 -0.1311336  0.0220224  -5.955 2.61e-09 ***
as.factor(year)2004 -0.4080769  0.0250655 -16.280  < 2e-16 ***
as.factor(year)2010 -0.2337395  0.0249876  -9.354  < 2e-16 ***
age                 -0.0016953  0.0005347  -3.171 0.001521 **
educ                 0.0408217  0.0031434  12.986  < 2e-16 ***
....
---
(Dispersion parameter for poisson family taken to be 1)
    Null deviance: 6728.2  on 5452  degrees of freedom
Residual deviance: 5935.7  on 5438  degrees of freedom
  (5613 observations deleted due to missingness)
AIC: 19757
-0.0062018  0.0263014  -0.236 0.813591
-0.0283905  0.0220270  -1.289 0.197435
0.0942896  0.0248126   3.800 0.000145 ***
0.0877773  0.0361812   2.426 0.015264 *
  And so on, for Poisson ...
 The statistical significance is actually quite similar between the OLS and the Poisson; this is comforting
 Look at that pitiful Pseudo-R2 though
 If we exponentiate all of the Poisson coefficients along with specific values for each X in the model, we can get a predicted count (or rate)
 
  To recap ...
 So that is what we can use ego network size measures for
 
  Question 2a
Are the ego networks of religious people more closely-knit (i.e., dense) than those of less religious people?
 
  Density in ego networks
 Density: The number of reported ties in the ego network divided by the total number of possible pairs.
 Ranges from 0 to 1.
 Answers the question: What percentage of all possible ties in each ego network are actually present?
 
  Density in ego networks
 Formula for non-directed, non-valued ties is:
where L is the actual number of reported ties and where N=number of nodes
    
  Note, however
 In our GSS case, the ties actually come to us valued.
 Respondents are asked: Please think about the relations between the people you just mentioned. Some of them may be total strangers in the sense that they wouldn't recognize each other if they bumped into each other on the street. Others may be especially close, as close or closer to each other as they are to you. Are [PERSON 1] and [PERSON 2] total strangers? Are they especially close? As close or closer to each other as they are to you?
 
  Measuring closeness in ties
 How close are Person 1 and Person 2?
 That is done for all ties in the ego network
. tab rclose12
   how close are |
persons number 1 |
          and 2? |      Freq.     Percent        Cum.
-----------------+-----------------------------------
  total strangers |
247       12.69
754       38.75
945       48.56
12.69
 know each other |
especially close |
-----------------+-----------------------------------
Total |      1,946      100.00
51.44 100.00
  To start ...
 I am going to dichotomize these ties to show some things ...
 First, I will dichotomize the ties so that we capture ties where the two people know each other “at all.”
 This produces ties for any two people who are not complete strangers from each other
 
  Ego net density, by religiosity
 Religious people report that a
greater percentage of their alters know each other at all
  
  Ego net density, by religiosity
 In R
  
  How did I do that graph?
In STATA:
foreach var of varlist close12-close45 {
  recode `var' 1/2=1 3=0, gen( tie`var' )
}
replace  tierclose1=. if  sex1>=.
replace  tierclose2=. if  sex2>=.
replace  tierclose3=. if  sex3>=.
replace  tierclose4=. if  sex4>=.
replace  tierclose5=. if  sex5>=.
egen rdensity = rmean( tieclose12- tieclose45)
ssc install ciplot
recode attend (0/2=0 "infrequent") (3/5=1 "moderate") (6/8=2 "a lot"),
gen(nattend)
 ciplot numgiven, by(nattend)
  How did I do that graph in R?
d$any12=ifelse(d$close12<3,1,0)
d$any13=ifelse(d$close13<3,1,0)
d$any14=ifelse(d$close14<3,1,0)
d$any15=ifelse(d$close15<3,1,0)
d$any23=ifelse(d$close23<3,1,0)
d$any24=ifelse(d$close24<3,1,0)
d$any25=ifelse(d$close25<3,1,0)
d$any34=ifelse(d$close34<3,1,0)
d$any35=ifelse(d$close35<3,1,0)
d$any45=ifelse(d$close45<3,1,0)
anys = c("any12", "any13", "any14", "any15", "any23", "any24", "any25", "any34",
"any35", "any45")
d$anydensity <- rowMeans(d[, anys ], na.rm=TRUE)
d$attend.cat = cut(d$attend, breaks = c(-1, 2, 5, 8), label=c("weak","moderate","
strong")) ## create a number of categories ##
plotmeans(d$anydensity~ d$attend.cat, connect=F)
 
  I could also do this as a function in R
      > names(d)  ### check on position of variables in columns ###
# Let’s make the variables close12 through close45 the first 10 # variables in d.
> d <- d[c(889:899,1:888,900:1212)] ### rearrange the variable columns ###
     # function to do the mapping from <3 to 1 and >=3 to 0
under3 <- function(x) ifelse(x < 3, 1, 0)
# make a matrix of the new variables you want
d_new <- apply(d[, 1:10], 2, under3)
# name the new variables replacing "close" with "any"
colnames(d_new) <- sub("close", "any", colnames(d[,1:10]))
     # add the new variables to the original data.frame
d <- data.frame(d, d_new)
 
  Or like this loop
     > names(d)  ### check on position of variables in columns ###
# Let’s make the variables close12 through close45 the first 10 # variables in d.
> d <- d[c(889:899,1:888,900:1212)] ### rearrange the variable columns ###
    # Get the names of the variables in d you want to use
names <- colnames(d)[1:10]
# Make new names replacing "close" with "any"
new_names <- sub("close", "any", names)
# Loop using 'within' function (not 'with') so d itself is modified for (i in seq_along(names)) {
d <- within(d, assign(new_names[i], # new_names[i] will be the name of the new variable
ifelse(get(names[i]) < 3, 1, 0))) # get(names[i]) finds the corresponding variable in d
 }
  Question 2b
Are the ego networks of religious people more really, really closely- knit (i.e., dense) than those of less religious people?
 
  To continue ...
 I am going to dichotomize these ties again ...
 Now, I will dichotomize the ties so that we capture ties where the two people must know each other “very well.”
 This produces ties for any two people only if they know each other very well
 This is a stronger tie than earlier
 
  I need a strong density variable
foreach var of varlist close12-close45 {
  recode `var' 1=1 2/3=0, gen( strong`var' )
}
// this captures people knowing each other very well //
replace  tierclose1=. if  sex1>=.
replace  tierclose2=. if  sex2>=.
replace  tierclose3=. if  sex3>=.
replace  tierclose4=. if  sex4>=.
replace  tierclose5=. if  sex5>=.
egen strongrdensity = rmean(strongclose12- strongclose45)
 
  How did I do that graph in R?
      d$strong12=ifelse(d$close12<2,1,0)
      d$strong13=ifelse(d$close13<2,1,0)
      d$strong14=ifelse(d$close14<2,1,0)
      d$strong15=ifelse(d$close15<2,1,0)
      d$strong23=ifelse(d$close23<2,1,0)
      d$strong24=ifelse(d$close24<2,1,0)
      d$strong25=ifelse(d$close25<2,1,0)
      d$strong34=ifelse(d$close34<2,1,0)
      d$strong35=ifelse(d$close35<2,1,0)
      d$strong45=ifelse(d$close45<2,1,0)
      strongs = c("strong12", "strong13", "strong14", "strong15", "strong23", "strong24",
      "strong25", "strong34", "strong35", "strong45")
      d$strongdensity <- rowMeans(d[, strongs ], na.rm=TRUE)
      d$attend.cat = cut(d$attend, breaks = c(-1, 2, 5, 8), label=c("weak","moderate","
      strong")) ## create a number of categories ##
      plotmeans(d$strongdensity~ d$attend.cat, connect=F)
 
  Comparing “knowing at all” density vs. “knowing well” density
 The correlation between these two measures is 0.45 (not shown)
  . sum  rdensity strongrdensity
    Variable |       Obs        Mean    Std. Dev.       Min        Max
-------------+--------------------------------------------------------
    rdensity |      1949    .8190505    .2822616          0          1
strongrden~y |      1949    .4302668    .3893735          0          1
  Ego net strong density, by religion
 Religious people report that even a greater percentage of their alters know each other really well
  
  Multivariate analyses ...
The effect of religious attendance is correlated ~3 times more (0.0134 /0.0047=2.85) with “knowing well” density vs. “knowing at all” density, net of other factors, including ego network size
----------------------------------------------------------------------------
                      (1)             (2)             (3)             (4)
                 rdensity    strongrden~y        rdensity    strongrden~y
----------------------------------------------------------------------------
  attend            0.00631**
                (0.00239)
numgiven
   0.0156***
(0.00328)
0.00477
(0.00249)
  -0.0252***
(0.00525)
0.0134***
(0.00339)
  -0.0162*
(0.00715)
[omitted]
----------------------------------------------------------------------------
N                    1944            1944            1813            1813
adj. R-sq           0.003           0.011           0.052           0.068
----------------------------------------------------------------------------
Standard errors in parentheses ... * p<0.05, ** p<0.01, *** p<0.001
  How did I make this table?
ssc install estout, replace
eststo: reg rdensity attend
eststo: reg strongrdensity attend
eststo: reg rdensity attend numgiven i.born i.year age educ sex realinc
i.race i.marital
eststo: reg strongrdensity attend numgiven i.born i.year age educ sex
realinc i.race i.marital
esttab, se ar2
eststo clear
 
  Multivariate analyses ...
For each category increase in attendance, someone’s ego network strong density increases (on average) by 1.34 percentage points, net of other factors
----------------------------------------------------------------------------
                      (1)             (2)             (3)             (4)
                 rdensity    strongrden~y        rdensity    strongrden~y
----------------------------------------------------------------------------
  attend            0.00631**
                (0.00239)
numgiven
   0.0156***
(0.00328)
0.00477
(0.00249)
  -0.0252***
(0.00525)
0.0134***
(0.00339)
  -0.0162*
(0.00715)
[omitted]
----------------------------------------------------------------------------
N                    1944            1944            1813            1813
adj. R-sq           0.003           0.011           0.052           0.068
----------------------------------------------------------------------------
Standard errors in parentheses ... * p<0.05, ** p<0.01, *** p<0.001
  But ...
Is OLS regression the appropriate way to model this relationship?
 
  What if ...
 Our dependent variable is bounded between 0 and 1?
 We can discretize our 0-100% range into (say) 10 groups of equal range, and run an ordinal logistic regression on that new discretized ordinal variable with 10 categories
 
  How did I do this?
recode rdensity 0/.09999999999999=0 .1/.199999999999=1 .2/.
29999999999=2 .3/.39999999999=3 .4/.49999999999=4 .5/.5999999999=5 .6/.
6999999999=6 .7/.79999999999=7 .8/.89999999999=8 .9/.99999999999=9, gen
(rdensitycut)
recode strongrdensity 0/.09999999999999=0 .1/.199999999999=1 .2/.
29999999999=2 .3/.39999999999=3 .4/.49999999999=4 .5/.5999999999=5 .6/.
6999999999=6 .7/.79999999999=7 .8/.89999999999=8 .9/.99999999999=9, gen
(strongrdensitycut)
 
  Comparing these two measures
  . tab1 rdensitycut strongrdensitycut
-> tabulation of rdensitycut
  RECODE of |
   rdensity |      Freq.     Percent
-> tabulation of strongrdensitycut
  RECODE of |
strongrdens |
        ity |      Freq.     Percent        Cum.
------------+-----------------------------------
                                            Cum.
------------+-----------------------------------
0| 103 5.28 1| 10 0.51 2| 19 0.97 3| 113 5.80 4| 66 3.39 5| 57 2.92 6| 214 10.98 7| 60 3.08 8| 133 6.82 9| 1,174 60.24
 5.28
 5.80
 6.77
12.57
15.96
18.88
29.86
32.94
39.76
0| 611 31.35 1| 186 9.54 2| 70 3.59 3| 286 14.67 4| 104 5.34 5| 51 2.62 6| 115 5.90 7| 17 0.87 8| 31 1.59 9| 478 24.53
31.35
40.89
44.48
59.16
64.49
67.11
73.01
73.88
75.47
                                          100.00
------------+-----------------------------------
                                          100.00
------------+-----------------------------------
Total |      1,949      100.00
Total |      1,949      100.00
 .
  Multivariate ologit analyses ...
The effect of religious attendance is correlated 2+ times more (0.0637 /0.0268=2.38) with “knowing well” density vs. “knowing at all” density, net of other factors including ego network size
----------------------------------------------------------------------------
                      (1)             (2)             (3)             (4)
              rdensitycut    strongrden~t     rdensitycut    strongrden~t
----------------------------------------------------------------------------
  attend             0.0359*
                 (0.0166)
numgiven
  0.0742***
(0.0151)
0.0268
(0.0183)
  -0.484***
(0.0400)
0.0637*** (0.0163)
 -0.0305
(0.0358)
[omitted]
----------------------------------------------------------------------------
N                    1944            1944            1813            1813
pseudo R-sq         0.001           0.003           0.047           0.018
----------------------------------------------------------------------------
Standard errors in parentheses ... * p<0.05, ** p<0.01, *** p<0.001
  How did I make this table?
ssc install estout, replace
eststo: ologit rdensitycut attend
eststo: ologit strongrdensitycut attend
eststo: ologit rdensitycut attend numgiven i.born i.year age educ sex
realinc i.race i.marital
eststo: ologit strongrdensitycut attend numgiven i.born i.year age educ
sex realinc i.race i.marital
esttab, se pr2
eststo clear
 
  Multivariate ologit analyses ...
For each category increase in attendance, someone’s log-odds of being in a higher percentage category of ego network strong density increase by 0.0637, net of other factors
----------------------------------------------------------------------------
                      (1)             (2)             (3)             (4)
              rdensitycut    strongrden~t     rdensitycut    strongrden~t
----------------------------------------------------------------------------
  attend             0.0359*
                 (0.0166)
numgiven
  0.0742***
(0.0151)
  0.0268
(0.0183)
  -0.484***
(0.0400)
0.0637*** (0.0163)
 -0.0305
(0.0358)
[omitted]
----------------------------------------------------------------------------
N                    1944            1944            1813            1813
pseudo R-sq         0.001           0.003           0.047           0.018
----------------------------------------------------------------------------
Standard errors in parentheses ... * p<0.05, ** p<0.01, *** p<0.001
 Other options when you have a percentage as an outcome
1. Generalized linear model, with a log link and binomial errors
2. Fractional response regression models (very similar to #1 above)
  
  To recap ...
 It may be quite important to know about how people’s 1.5 neighborhoods can possibly relate to their actions and beliefs
 
  Question 3a
Are the ego networks of strongly political people more intense than those of less political people?
 
  Network intensity, by “politicity”
 The extremes of the political
party spectrum have the highest levels of ego network intensity
  
  How did I do this?
ssc install ciplot
ciplot intensity , by(partyid), if partyid<7, xla(, ang(45))
 
  How did I do this?
foreach var of varlist close12-close45 {
  vreverse `var', gen( r`var' )
}
egen intensity = rmean( rclose12- rclose45)
  
  Intensity = Density (for valued, non- directed ties) in ego nets
 Density: For a valued, non-directed network, density is defined as the sum of the ties divided by the number of possible ties
 It is the ratio of all tie strength that is actually present to the number of possible ties. It is just the average tie strength for the ego network
 Answers the question: How strong is the average connection within ego’s network?
  
  Density in valued ego networks
 Formula for non-directed, valued ties is:
where the numerator is the sum of all the weights of all reported ties, while the denominator is the total number of possible ties among N actors
   
  Multivariate analyses ...
Note the curvilinear pattern on partyid here. In Model 3, the slope
starts negative (-0.056), but then, at some point, it becomes positive
(0.009), net of other factors
------------------------------------------------------------
                      (1)             (2)             (3)
                intensity       intensity       intensity
------------------------------------------------------------
  partyid
partyid_sq
numgiven
 -0.00358
(0.00612)
  -0.0586***
 (0.0102)
  -0.0722**
 (0.0240)
   0.0115**
(0.00390)
  -0.0592***
 (0.0102)
  -0.0565*
 (0.0240)
  0.00902*
(0.00389)
  -0.0446***
 (0.0102)
[omitted]
------------------------------------------------------------
N                    1923            1923            1920
adj. R-sq           0.016           0.020           0.062
------------------------------------------------------------
  How did I do this?
ssc install estout, replace
eststo: reg intensity partyid numgiven if partyid<7
eststo: reg intensity c.partyid##c.partyid numgiven  if partyid<7
eststo: reg intensity c.partyid##c.partyid numgiven age educ i.marital
sex if partyid<7
esttab, se ar2
eststo clear
 
  Network intensity, by extremity
 The extremes of the political party spectrum have the highest levels of ego network intensity or (valued) density
  
  How did I do this?
reg intensity c.partyid##c.partyid numgiven age educ i.marital sex if
partyid<7
predict ybar if e(sample)
twoway (qfitci ybar partyid) if partyid<7
 
  To recap ...
 People who have less intense feelings about politics have friends who have less intense relationships to each other
 
  Idle question--
 This is all self-reported. But what if we had “objective” measures of how many confidantes someone had? Would we see that people who are more “extreme” in their opinions/attitudes/actions, have more friends (and family)?
 
  Let’s try this with Add Health
 Do people’s political orientations when they are aged 25 have a curvilinear relationship with their school friendship density when they are in 10th-grade?
  
  Add Health answers this ...
Ego’s (receiver) network density in high school, measured “objectively,” is not related (curvilinear or otherwise) to their political positions years in the future
    > summary(d$ERDEN)
       Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's
     0.0800  0.2700  0.3900  0.4264  0.5000  1.0000    2484
    > lmad = lm(ERDEN ~ as.factor(H3CC13) , total, subset = H3CC13<95)
    > summary(lmad)
                        Estimate Std. Error t value Pr(>|t|)
    (Intercept)         0.423151   0.024616  17.190   <2e-16 ***
    as.factor(H3CC13)2 -0.001921   0.026190  -0.073    0.942
    as.factor(H3CC13)3  0.004243   0.025172   0.169    0.866
    as.factor(H3CC13)4  0.003318   0.026233   0.126    0.899
    as.factor(H3CC13)5  0.007022   0.036994   0.190    0.849
    ---
    Residual standard error: 0.2103 on 2813 degrees of freedom
      (1573 observations deleted due to missingness)
Multiple R-squared: 0.0001398, Adjusted R-squared: -0.001282 F-statistic: 0.09833 on 4 and 2813 DF, p-value: 0.983
  
  Lastly ...
  Lastly, remember this?
   Looks like a steady decline in the average
number of people others have as confidants
  About that finding ...
 Paik, Anthony, and Kenneth Sanchagrin. "Social Isolation in America: An Artifact." American Sociological Review 78.3 (2013): 339-360.
 Estimates of network size found in the 2004 General Social Surveys (GSS) were affected by significant interviewer effects
 They find interviewer effects reduced reported network size
 In the 2004 GSS, some interviewers obtained highly improbable levels of social isolation, due to training and fatigue effects
 
  Remember this?
Numgiven-- From time to time, most people discuss important
matters with other people. Looking back over the last six months, who
are the people with whom you discussed matters important to you?
Name up to a maximum of 6 people:
. tab numgiven
  number of |
    persons |
  mentioned |      Freq.     Percent        Cum.
------------+-----------------------------------
 0| 590 12.40
1| 796 16.73
2| 848 17.83
3| 1,402 29.47
4| 473 9.94
5| 443 9.31
6| 205 4.31
12.40
29.14
46.96
76.43
86.38
95.69
                                          100.00
------------+-----------------------------------
Total |      4,757      100.00
  About that finding ...
 Bearman, Peter, and Paolo Parigi. "Cloning headless frogs and other important matters: Conversation topics and network structure." Social Forces 83.2 (2004): 535-557.
 They show that half the people who report not talking about anything have nothing to talk about, whereas the others have no one to talk to.
 Secondly, they show that people tend to talk about things that many would regard as unimportant, for example, cloning of headless frogs, eating less red meat, and so on
 
  What makes a confidante?
 Who is a friend? A close contact? Someone important instrumentally? Etc.
 This is a basic problem when people are asked to nominate the people closest to them
 
  Finally - How to make ego networks out of whole networks in R
  #1 - Find network data here
 
  #2- Pick this dataset
   BACKGROUND In 1991 and 1992 Cinthia Webster collected data on both work ties and social ties from 24 members of a small accounting firm. Six respondents were partners in the firm, three were managers, nine were staff accounts and the other six were support staff.
First, ad libitum sampling was used to observe social interactions in a wide range of settings. This produced the OBSERVED_SOCIAL matrix. Work assignment sheets were used to determine who had worked with whom and they produced the OBSERVED_WORK data. Then each individual was asked to report others with whom he or she had socialized and those with whom they had worked. REPORTED_SOCIAL and REPORTED_WORK coded responses to these questions.
  Like this
 
  It looks like this:
  Like this
  #3- Read your network into R
> x<- read.table("http://moreno.ss.uci.edu/acct.dat", skip=10, nrows=24) >x
V1 V2 V3 V4 V5 V6 V7 V8 V9 V10 V11 V12 V13 V14 V15 V16 V17 V18 V19 V20 V21 V22 V23 V24 1101000000000000010000000 2000000000000000000000000 3102000100010000010000000 4000322221022121202210000 5 0 0 0 2 10 5 9 5 2 0 5 5 4 5 4 4 0 4 5 0 1 0 0 0 6000258721022122202200000 7 0 0 1 2 9 7 13 5 2 0 6 4 3 4 3 3 0 4 5 0 1 0 0 0 8000252574144343504501000 9000121249642222602200000 10 0 0 0 0 0 0 0 1 6 7 2 0 0 0 0 4 0 0 0 0 0 0 0 0 11 0 0 1 2 5 2 6 4 4 2 11 6 5 5 4 4 0 3 4 2 0 0 0 0 12 0 0 0 2 5 2 4 4 2 0 6 6 5 5 4 4 0 3 4 1 0 0 0 0 13 0 0 0 1 4 1 3 3 2 0 5 5 6 5 4 3 0 2 3 1 0 0 0 0 14 0 0 0 2 5 2 4 4 2 0 5 5 5 6 4 4 0 3 4 0 0 0 0 0 15 0 0 0 1 4 2 3 3 2 0 4 4 4 4 8 6 0 2 3 0 0 1 0 0 16 0 0 0 2 4 2 3 5 6 4 4 4 3 4 6 13 0 3 4 0 0 1 0 0 17 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 1 1 1 1 1 0 18 0 0 0 2 4 2 4 4 2 0 3 3 2 3 2 3 0 11 11 0 1 0 1 0 19 0 0 0 2 5 2 5 5 2 0 4 4 3 4 3 4 1 11 14 1 2 1 2 0 20 0 0 0 1 0 0 0 0 0 0 2 1 1 0 0 0 1 0 1 4 1 1 1 0 21 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 1 2 1 2 1 1 0 22 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 2 1 0 23 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 2 1 1 1 3 1 24 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 
  #4- Get an attribute file too
> y = read.table("http://moreno.ss.uci.edu/acc_att.dat", skip=8) > library(plyr)
> y = rename(y, c("V1"="sex")) > y = rename(y, c("V2"="job")) >y
sex job 111 211 311 423 523 612 712 823 913 10 1 3 11 1 1 12 1 1 13 1 1 14 2 2 15 1 3 16 1 3
 17 1 3
  #5- Get some network measure
Do this:
 library(igraph)
 xmg=graph.adjacency(as.matrix(xm),mode="undirected",weighted=NULL)
 y$degree = degree(xmg) ## this is the same thing as NUMGIVEN in the GSS ##
  
  #6- View your ultimate dataset
>y
sex job degree
1114 2110 3118 4 2 3 30 5 2 3 80 6 1 2 48 7 1 2 85 8 2 3 66 9 1 3 56 10 1 3 27 11 1 1 81 12 1 1 63 13 1 1 54 14 2 2 61 15 1 3 59 16 1 3 81 17 1 3 11 18 2 3 69 19 2 4 89 20 2 4 18
 
  #7- Run a model on degree
> lm1 = lm(degree ~ as.factor(sex) + as.factor(job), y)
> summary(lm1)
Residuals:
    Min      1Q  Median      3Q     Max
-37.846 -21.837  -8.532  19.577  64.167
Coefficients:
 Neither sex or position predicts the number of people someone will interact with
  Estimate Std. Error t value Pr(>|t|)
  35.000     12.074   2.899   0.0092 **
(Intercept)
as.factor(sex)2    9.846     17.400   0.566   0.5781
as.factor(job)2   26.385     21.702   1.216   0.2390
as.factor(job)3   13.846     17.400   0.796   0.4360
as.factor(job)4  -20.013     24.379  -0.821   0.4219
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
Residual standard error: 29.58 on 19 degrees of freedom
Multiple R-squared:  0.231,   Adjusted R-squared:  0.06914
F-statistic: 1.427 on 4 and 19 DF,  p-value: 0.2634
  #8- Run a model on ln(degree)
   Degree is right-skewed, so let’s log it and see ...
> hist(y$degree)
> y$ln.degree = log(y$degree)
> is.na(y) <- sapply(y, is.infinite) ## because we want to
remove the infinite value when degree=0 ##
> lm3 = lm(ln.degree ~ as.factor(sex) + as.factor(job), y)
> summary(lm3)
Coefficients:
                Estimate Std. Error t value    Pr(>|t|)
(Intercept)       3.1985     0.4322   7.401    0.00729 ***
as.factor(sex)2   0.3075     0.5685   0.541    0.595
as.factor(job)2   0.8406     0.7307   1.150    0.265
as.factor(job)3   0.4869     0.5953   0.818    0.424
as.factor(job)4  -0.8137     0.8159  -0.997    0.332
---
Residual standard error: 0.9663 on 18 degrees of freedom
  (1 observation deleted due to missingness)
Multiple R-squared: 0.2853, Adjusted R-squared: 0.1264 F-statistic: 1.796 on 4 and 18 DF, p-value: 0.1737
 
  There is more you can do to generate other measures for ego networks, based on whole networks ... but that will come next week



 Social Network Analysis (Class 6.5)
  Gregory M. Eirich QMSS
  Do beautiful people have more people who want to be their friend?
  How many friends can one person have?
This is in-degree here
> table(d$IDGX2)
0 1 2 3 4 5 6 7 8 910111213141516171819 377 527 571 567 531 418 362 273 191 140 123 91 56 43 32 31 18 11 14 7
20 21 22 23 24 27 30 5122121
  
   Average degree
  Attractiveness ranking (1-5)
  Attractiveness -> Friends
Each category more attractive a teenage is, 0.6 more friends on average they have
> summary(lm(IDGX2 ~ H1IR1, d, subset=H1IR1<6))
Coefficients:
            Estimate Std. Error t value Pr(>|t|)
(Intercept)  2.34143    0.23555   9.940   <2e-16 ***
H1IR1        0.61324    0.06359   9.644   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
Residual standard error: 3.655 on 4389 degrees of freedom
  (2104 observations deleted due to missingness)
Multiple R-squared:  0.02075,   Adjusted R-squared:  0.02053
F-statistic: 93.01 on 1 and 4389 DF,  p-value: < 2.2e-16
  
    Attractiveness of personality
  Physical Attractiveness -> Friends
Each category more attractive a teenage is, 0.5 more friends on average they have, net of how attractive their personality is
> summary(lm(IDGX2 ~ H1IR1 + H1IR2, d, subset=H1IR1<6))
Coefficients:
            Estimate Std. Error t value Pr(>|t|)
(Intercept)  2.02250    0.26678   7.581 4.15e-14 ***
H1IR1        0.49822    0.07802   6.386 1.88e-10 ***
H1IR2        0.20264    0.07975   2.541   0.0111 *
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
Residual standard error: 3.653 on 4388 degrees of freedom
  (2104 observations deleted due to missingness)
Multiple R-squared:  0.02219,   Adjusted R-squared:  0.02175
F-statistic: 49.79 on 2 and 4388 DF,  p-value: < 2.2e-16
  
  Grooming -> Friends ?
Each category more attractive a teenage is, 0.4 more friends on average they have, net of how attractive their personality is and how groomed they are
 > summary(lm(IDGX2 ~ H1IR1 + H1IR2 + H1IR3, d, subset=H1IR1<6))
 Coefficients:
             Estimate Std. Error t value Pr(>|t|)
 (Intercept)  1.65799    0.29610   5.599 2.28e-08 ***
 H1IR1        0.41803    0.08296   5.039 4.87e-07 ***
 H1IR2        0.14934    0.08189   1.824  0.06827 .
 H1IR3        0.23521    0.08318   2.828  0.00471 **
 ---
 Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
 Residual standard error: 3.65 on 4387 degrees of freedom
   (2104 observations deleted due to missingness)
 Multiple R-squared:  0.02397,   Adjusted R-squared:  0.0233
 F-statistic: 35.91 on 3 and 4387 DF,  p-value: < 2.2e-16
  
  For girls
Each category more attractive a girl is, 0.3 more friends on average they have, net of how attractive their personality is and their grooming level
> summary(lm(IDGX2 ~ H1IR1 + H1IR2 + H1IR3, d, subset=(H1IR1<6 & S2==2)))
Coefficients:
            Estimate Std. Error t value Pr(>|t|)
(Intercept)  1.87093    0.39108   4.784 1.83e-06 ***
  H1IR1        0.32972
H1IR2        0.08109
H1IR3        0.36301
---
0.10610   3.108 0.001908 **
0.10643   0.762 0.446209
0.10832   3.351 0.000817 ***
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
Residual standard error: 3.517 on 2289 degrees of freedom
  (1970 observations deleted due to missingness)
Multiple R-squared:  0.02528,   Adjusted R-squared:  0.024
F-statistic: 19.79 on 3 and 2289 DF,  p-value: 1.155e-12
  For boys
Each category more attractive a boy is, 0.5 more friends on average they
have, net of how attractive their personality is and how groomed he is
 > summary(lm(IDGX2 ~ H1IR1 + H1IR2 + H1IR3, d, subset=(H1IR1<6 & S2==1)))
 Coefficients:
             Estimate Std. Error t value Pr(>|t|)
 (Intercept)  1.67266    0.46654   3.585 0.000345 ***
  H1IR1        0.51810
H1IR2        0.20314
H1IR3        0.04467
---
0.13253   3.909 9.55e-05 ***
0.12836   1.583 0.113674
0.13017   0.343 0.731515
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
Residual standard error: 3.788 on 2062 degrees of freedom
  (1947 observations deleted due to missingness)
Multiple R-squared:  0.01987,   Adjusted R-squared:  0.01845
F-statistic: 13.94 on 3 and 2062 DF,  p-value: 5.37e-09



 Social Network Analysis (Class 6)
  Gregory M. Eirich QMSS
  Agenda
1. Average degree and dispersion of degree (low-tech centralization)
2. Network density
3. Centrality measures
 
  1. Average degree and dispersion of degree (low-tech centralization)
  Average degree
 We just take the degree values for each ego network and take the average of them
 
  Average degree
  Blue=recipricated ties; red=any direction ties
 
  Average degree, with dispersion
 Based on any and all ties
  
  Dispersion of degree
Measures of the degree of centralization in the network. CV= coefficient of variation = st. dev. / mean. It is highest for the coworker network (0.543)
. sum ADegree CDegree FDegree
    Variable |       Obs        Mean    Std. Dev.       Min        Max
-------------+--------------------------------------------------------
  ADegree |
CDegree |
FDegree |
71    15.70423
71    10.64789
71    20.43662
8.386033
5.784458
8.067098
1 35 0 28 6 45
. tabstat ADegree CDegree FDegree, statistics(cv skewness kurtosis)
   stats |   ADegree   CDegree   FDegree
---------+------------------------------
      cv |  .5339985  .5432494  .3947374
skewness |  .4080647  .9802015  .2983879
kurtosis |  2.363688  3.822013  3.066483
----------------------------------------
  Dispersion of degree
For all, skewness is higher than 0, indicating right (positive) skew. Again, the coworker network is much more skewed (0.98) than the others.
. sum ADegree CDegree FDegree
    Variable |       Obs        Mean    Std. Dev.       Min        Max
-------------+--------------------------------------------------------
  ADegree |
CDegree |
FDegree |
71    15.70423
71    10.64789
71    20.43662
8.386033
5.784458
8.067098
1 35 0 28 6 45
. tabstat ADegree CDegree FDegree, statistics(cv skewness kurtosis)
   stats |   ADegree   CDegree   FDegree
---------+------------------------------
      cv |  .5339985  .5432494  .3947374
skewness |  .4080647  .9802015  .2983879
kurtosis |  2.363688  3.822013  3.066483
----------------------------------------
  Dispersion of degree
For all, kurtosis is higher than 2, indicating thicker tails than normal. But again, the coworker network has the fattest tails (3.82)
. sum ADegree CDegree FDegree
    Variable |       Obs        Mean    Std. Dev.       Min        Max
-------------+--------------------------------------------------------
  ADegree |
CDegree |
FDegree |
71    15.70423
71    10.64789
71    20.43662
8.386033
5.784458
8.067098
1 35 0 28 6 45
. tabstat ADegree CDegree FDegree, statistics(cv skewness kurtosis)
   stats |   ADegree   CDegree   FDegree
---------+------------------------------
      cv |  .5339985  .5432494  .3947374
skewness |  .4080647  .9802015  .2983879
kurtosis |  2.363688  3.822013  3.066483
----------------------------------------
  2. Network density
  Overall network density
 We have already seen this measure for ego
 Now, it couldn’t be simpler, since we don’t need to worry about ego anymore, so it’s just the same formulas as with ego networks, just not having to remove ego from the calculations.
 For unvalued, undirected ties, it’s just the proportion of all possible ties that are actually present
  
  Overall network density
 For a valued network, density is defined as the sum of the ties divided by the number of possible ties
 It is the ratio of all tie strength that is actually present to the number of possible ties
 
  Density in the Lazega data
 What if we look only at reciprocated (mutual) ties?
123 Density No. of Avg Deg Ties ree ------- ------- -------
  1 lazega-net-advice   0.123
2 lazega-net-co-work  0.152
3 lazega-net-frien~p  0.172
609   8.577
756  10.648
854  12.028
                    Avg Va Std De Avg Wt
                       lue      v d Degr
                                      ee
                    ------ ------ ------
1 lazega-net-valued  0.446  0.719 31.254
  Density in the Lazega data
 I.e.-- for the advice network, 12.3% of all possible ties are present
123 Density No. of Avg Deg Ties ree ------- ------- -------
  1 lazega-net-advice   0.123
2 lazega-net-co-work  0.152
3 lazega-net-frien~p  0.172
609   8.577
756  10.648
854  12.028
                    Avg Va Std De Avg Wt
                       lue      v d Degr
                                      ee
                    ------ ------ ------
1 lazega-net-valued  0.446  0.719 31.254
  Density in the Lazega data
 I.e.-- for the advice network, the average tie strength is 0.446 (aka, half of
 one tie)
 1 lazega-net-advice
 2 lazega-net-co-work  0.152
 3 lazega-net-frien~p  0.172
 123 Density No. of Avg Deg Ties ree ------- ------- -------
                    Avg Va Std De Avg Wt
                       lue      v d Degr
                                      ee
                    ------ ------ ------
1 lazega-net-valued  0.446  0.719 31.254
0.123
609   8.577
756  10.648
854  12.028
  Cohesion in the Lazega advice net
 The density of the advice network is doubled when ties need not be reciprocated
     ADVICE
     ------
     Density=0.123 -> Density=0.224
    (recipricical)   (any directed tie)
  
  Cohesion in the Lazega work net
 The density of the work network doesn’t change when ties need not be reciprocated
     CO-WORK
     ------
     Density=0.152 -> Density=0.152
    (reciprocal)   (any directed tie)
  
  Cohesion in the Lazega friend net
 The density of the friend network increases when ties need not be reciprocated
     FRIEND
     ------
     Density=0.172 -> Density=0.292
    (reciprocal)   (any directed tie)
  
  Cohesion in the Lazega valued net
 Almost half (45.6% of all ties) of the lawyers at connected at least on a one-way basis along one dimension of connection
     VALUED (but turned BINARY)
     ------
     Density=0.325 -> Density=0.456
    (reciprocal)   (any directed tie)
  
  Does the preceding make sense?
 The advice network is the most sparse
 The friendship network is the most dense
 Networks where ties do not need to be reciprocated are more dense than ones where mutual agreement must be present
 
  Network density, by subgroup
  Densities in the Lazega friend net
 Partners have more and denser relations among each other than associates do with each other
     FRIENDship network (any and all ties)
     ------
     Density=0.352 vs. Density=0.267
 Ave. Degree=12.33 vs. Ave. Degree=9.09
   (Partners, n=36)   (Associates, n=35)
  
  3. Centrality measures
  Remember the hunt for Paul Revere?
  
  (In- and out-) Degree centrality
  Degree centrality
 Answers the question-- How many people can this person reach directly?
 The more ties a node has, the more power it has to get what it wants and to influence many
 In a network of music collaborations, answers-- How many people has this person collaborated with?
 
  Degree centrality
 For undirected, unvalued ties, degree centrality is calculated simply as the sum of all ties to alters (just as with ego networks: remember numgiven?)
 Nodes in larger networks could have larger degree centrality simply because they are in larger overall networks
 To deal with this problem of CD -> gN (aka, gN is network size), we can normalize degree centrality by dividing through by the size of the whole network; now, centrality would be expressed as a proportion of total possible ties are actual
 
  In-degree and out-degree
 For directed, unvalued ties, two different degree centrality measures can be calculated.
1. In-degree centrality = the sum of all ties directed in toward ego from alters (often thought of as a measure of popularity or prestige)
2. Out-degree centrality = the sum of all ties directed out from ego to alters (often thought of as a measure of influence or social activity)
  
  In-degree and out-degree
 In-degree and out-degree can be normalized to allow for comparisons across social networks in the same way as with degree centrality-- i.e., by dividing by the total network size
 The ratio of in-degree to out-degree centrality can also tell us something about the relative balance between independence (if it is >1, alters need you, but you don’t need them) and “trying too hard” (if it is <1, ego is usually in a weaker, plaintiff position)
 
  Advice network
 609 directed ties represented
 Node shape: circle=men; squares=women
 Node color: pink=partners; blue=associates
 Node size: in-degree centrality
 Label size: out-degree centrality
 Label color: red=litigation practice; black=corporate practice
 Layout: Fruchterman-Rheingold graph layout
 
   Does the preceding make sense?
Etc.
 
  Advice network conclusions
 Results are based on directed ties
 The most prestigious Node is 26 (high in-degree, low out-degree-- male corporate partner) ... Node 21 is not far behind
 Nodes 45, 49, 30 and 61 (all male associates, some corporate, some litigation) are all trying way too hard-- soliciting lots of advice and receiving very little requests for it
 There are many nodes who have large in-degrees and out- degrees in equal measure (Nodes 13, 16, and 17)
 Lots of peripheral nodes who have relatively big out-degrees
 
   Etc.
  The code in R is this:
library(igraph)
### import your data ###
test=read.csv(file.choose(),header=TRUE,row.names=NULL,check.names=FALSE)
### turn your dataframe into a matrix ###
testm=as.matrix(test) # coerces the data set as a matrix ##
### makes your data into a sociomatrix ###
testmg=graph.adjacency(testm,mode="directed",weighted=NULL)
### import your attribute data ###
testatt=read.csv(file.choose(), header=TRUE) # see “Lazega-atts.csv” on Courseworks
 
  The code in R is this:
### attach the attributes to the Vertices of the igraph ###
V(testmg)$name
V(testmg)$status=testatt$status[match(V(testmg)$name,testatt$ID)]
V(testmg)$gender=testatt$gender[match(V(testmg)$name,testatt$ID)]
V(testmg)$office=testatt$office[match(V(testmg)$name,testatt$ID)]
V(testmg)$seniority=testatt$seniority[match(V(testmg)$name,testatt$ID)]
V(testmg)$age=testatt$age[match(V(testmg)$name,testatt$ID)]
V(testmg)$practice=testatt$practice[match(V(testmg)$name,testatt$ID)]
V(testmg)$lawschool=testatt$lawschool[match(V(testmg)$name,testatt$ID)]
 
  The code in R is this:
## start the graph ##
set.seed(12)
l <- layout.kamada.kawai(testmg)
# Plot undecorated first.
par(mfrow=c(1,1))
oldMargins<-par("mar")
par(mar=c(1,1,1,1))
### par(mar=oldMargins) ### to return to default ...
# Differentiate two gender by shape
V(testmg)[V(testmg)$gender== 1]$shape <- "circle"
V(testmg)[V(testmg)$gender== 2]$shape <- "rectangle"
 
  The code in R is this:
# Differentiate two status by color.
V(testmg)[V(testmg)$status== 1]$color <- "pink"
V(testmg)[V(testmg)$status== 2]$color <- "dodgerblue"
# Differentiate two practices by label color.
V(testmg)[V(testmg)$practice== 1]$label.color <- "red"
V(testmg)[V(testmg)$practice== 2]$label.color <- "black"
# Size node by in-degree.
V(testmg)$size <- 4*sqrt(degree(testmg, mode="in"))
V(testmg)$size2 <- V(testmg)$size * .5
# Size of node label by out-degree.
V(testmg)$label.cex <- 2.5 * degree(testmg, mode="out") / max(degree(testmg, mode="out"))
plot(testmg, layout=l)
## to suppress the edges, add edge.color=”white” ##
## plot(testmg, layout=l, edge.color=”white”)
 
  Friendship network
 854 directed ties represented
 Node shape: circle=men; squares=women
 Node color: pink=partners; blue=associates
 Node size: in-degree centrality
 Label size: out-degree centrality
 Label color: red=litigation practice; black=corporate practice
 Layout: Fruchterman-Rheingold graph layout
 
   Does the preceding make sense?
Etc.
 
  Friendship network conclusions
 Results are based on directed ties
 The most prestigious Node is 13 (high in-degree, low out-degree-- male litigation partner) ... Node 64 (female corporate associate) is not far behind
 Nodes 66, 42, and 19 (all males, but 19 is a partner) are all trying way too hard-- sending out many friendship requests and not receiving that many back
 There are many nodes who have large in-degrees and out- degrees in equal measure (Nodes 12, 24, and 26)
    Most nodes seem pretty proportionate in their in- and out-degree
  Degree centrality
 As of yet, there has been very little work available to create degree centrality measures on valued ties
 Though this may change things in that regard: Opsahl, T., Agneessens, F., Skvoretz, J., 2010. “Node centrality in weighted networks: Generalizing degree and shortest paths.” Social Networks 32 (3), 245-251
 
  Nice blog post about it too (in R)
 In-degree and out-degree can be normalized to allow for comparisons across social networks in the same way as with degree centrality-- i.e., by dividing by the total network size
 The ratio of in-degree to out-degree centrality can also tell us something about the relative balance between independence (if it is >1, alters need you, but you don’t need them) and “trying too hard” (if it is <1, ego is usually in a weaker, plaintiff position)
  
  Betweenness centrality
  Revere’s betweennness centrality

   He calculates betweenness centrality for all the men, meaning
 roughly the number of “shortest paths” between any two people in
 our network that pass through the person of interest. It is a way of
 asking “If I have to get from person a to person z, how likely is it that
 the quickest way is through person x?” Here are the top scores:
  
  Betweenness centrality
 Answers the question-- How likely is this person to be the most direct route between two people in a network?
 In network of spies, it answers-- Who is the spy through whom most of the confidential information is likely to flow?
 Need to know how to measure distance in social networks ...
 
  Measuring distance in networks
 Lots of ways of measuring distance in networks: Walks ~ trails ~ paths ~ closed walks ~ cycles ~ semi-cycles (most of these can be directed or undirected)
 The shortest path between two nodes is called geodesic, and the length of this path, in number of intermediate connections, is called geodesic distance.
 We can see how many connections and how many nodes are intermediaries in a relationship between two actors of a network.
  
  Betweenness centrality
 The number of times that a node falls "between" the geodesic paths of other actors
 The idea is that the more people have to go through me to make connections with other people, the more power I have
 We can norm this measure by expressing it as a percentage of the maximum possible times that an actor could have been between all dyads in the network (assuming that each pair has only 1 geodesic)
 
  Betweenness centrality
etc
    
  Betweenness centrality
 We can find the individuals who are necessary conduits for information that must traverse disparate parts of the network.
 High betweenness individuals often do not have the shortest average path to everyone else, but they have the greatest number of shortest paths that necessarily have to go through them.
 In a social network, high betweenness individuals are often found at the intersections of more densely connected network communities and can serve as brokers
 
  Betweenness centrality
 A valued betweenness centrality is also possible (see the Opsahl et al 2010 paper for this too)
 A betweennness centrality measure based on directed data is also possible (though rarely used) from this: White, D. R., & Borgatti, S. P. (1994). “Betweenness centrality measures for directed graphs.” Social Networks, 16(4), 335-346.
 
  Advice network
 609 undirected ties represented
 Node shape: circle=men; squares=women
 Node color: pink=partners; blue=associates
 Node size: degree centrality
 Label size: betweenness centrality
 Label color: red=litigation practice; black=corporate practice
 Layout: Fruchterman-Rheingold graph layout
 
   Does the preceding make sense?
Etc.
 
  Advice network conclusions
 Results are based on undirected ties
 Nodes 35 and 16 (male partners in litigation) have the most connections (degree centrality) and are the most in-between
 Node 60 is also very connected and very in-between, but she is a female associate, also in litigation
 In general, degree centrality and betweenness centrality appear to be pretty correlated (more on that later)
 
  Friendship network
 854 directed ties represented
 Node shape: circle=men; squares=women
 Node color: pink=partners; blue=associates
 Node size: degreecentrality
 Label size: betweenness centrality
 Label color: red=litigation practice; black=corporate practice
 Layout: Fruchterman-Rheingold graph layout
 
   Does the preceding make sense?
Etc.
 
  Friendship network conclusions
 Results are based on undirected ties
 Node 26! Definitely most degree-central and most between (male, corporate partner).
 As for associates, Node 41 is most central (if not most between, for an associate)
 How does this compare to the advice undirected network?
 
  Closeness centrality
  Closeness centrality
 Answers the question-- How fast can this person reach everyone in the network?
 Focuses on the distance of a node to all others in the network via the fewest number of indirect ties
 For example, in network of sexual relations-- How fast will an STD spread from this person to the rest of the network?
 
  Closeness centrality
 Closeness(i) =
    where i is ego, j is an alter and dij is the shortest distance between i and j
  
  Closeness centrality
 If we divide 1 by the sum of all the shortest path lengths from an individual to all other individuals in the network, then we have calculated their closeness centrality
 Individuals who connect to most others through many intermediaries get closeness scores that are increasingly nearer to zero.
 The closeness score for someone completely directly connected to everyone in the network will be closer to 1 than someone who is connected to others through longer paths, but it will not be 1, since the denominator for a completely directly connected person is g-1, where g is the number of nodes in the person's ego network. (That is why it is often helpful to normalize closeness centrality measures.)
 
  Closeness centrality
 High closeness centrality individuals might to be important influencers within their local network community. They may often not be public figures to the entire network of a corporation or profession, but they are often respected locally and they occupy short paths for information spread within their network community.
 Closeness centrality tends to give high scores to individuals who are near the center of local clusters (aka network communities) in an overall larger network ... always in the mix
 
  Closeness centrality
 Closeness scores cannot be calculated on networks where at least one node is unreachable by the others (because they produce infinitely large results)
 Often closeness is just calculated on the largest component of a network
 Opsahl provides another work-around ...
  
  Opsahl’s work-around
 
    Eigenvector centrality
  
   Centrality in the CCP
Franziska Barbara Keller
“Networks of Power. Using Social Network
Analysis to understand who will rule and who is really in charge in the Chinese Communist Party.” Presented at APSA 2014.
 
   For example
  The question
 Can we look at Chinese elites who score high on different measures of network centrality, and use that information to predict their importance (within the Inner Circle) for the Chinese Communist Party many years in the future?
 
  Closeness centrality
    Closeness centrality predicts ascension to the Politburo up to 10 years ahead. It captures a candidate’s popularity among peers and leaders, and their ability to help foster coalitions.
 Betweenness centrality
 Betweenness centrality reflects a leader’s ability to maintain control over their coalition, and therefore indicates someone who is a patron.
      
  Eigenvector centrality
  Revere’s eigenvector centrality

   Then he calculates everyone’s eigenvector centrality, which is a
 measure of centrality weighted by one’s connection to other central
 people. Here are our top scorers on that measure
  
  Eigenvector centrality
 Eigenvector centrality answers the question-- How well is this person connected to other well-connected people?
 For example, in a network of paper citations, we can ask-- Who is the author that is most cited by other well-cited authors?
 This looks to find a big fish connected with other big fish in a big pond
 
  An eigenvector example ...
 What is an eigenvector? Eigenvector, x, satisfies Ax = λx:
  
  Eigenvector centrality
Some of these examples are from:
 Who is central to a social network? It depends on your centrality measure. Luke Matthews and Paul Richard. 10 July 2012. www.activatenetworks.net/.../who-is-central-to-a-social-network-it-depen...
       Social Network Analysis. Giorgos Cheliotis, Researcher,
 educator and consultant at NUS. Feb 25, 2010.
 http://www.slideshare.
 net/gcheliotis/social-network-analysis-3273045
 
  Eigenvector centrality
 Eigenvector centrality weights ego’s centrality by the degree centrality values of its alters, thus taking the whole network into account
 We are searching for the largest eigenvectors, e, that satisfy the equation of Ae = λe, where A is the sociomatrix and λ is an array of eigenvalues
 Higher values of e for nodes indicate greater eigenvector centrality
 
  Eigenvector centrality
 Eigenvector centrality only works on symmetric data
 It can handle valued ties
 It can also be normalized to go from 0 to 1
 
  Eigenvector centrality
 Very similar to PageRank in Google algorithm
 
  Bonacich/power centrality
  Revere’s Bonacich centrality

   Lastly, he calculates everyone’s Bonacich power centrality score,
 another (even) more sophisticated measure. Here the lower score
 indicates a more central location:
  
  Remember the powerful cities?
Neal, Zachary. “Differentiating centrality and power in the world city network.” Urban Studies 48.13 (2011): 2733-2748
  
  How he answers the question
 He wants to consider if power≠centrality.
 He defines maximum (recursive) centrality as being at the center of other very central cities. That is, the central city is also most connected to other cities who themselves were also really connected to lots of other cities.
  
  How he answers the question
 That does seem like a lot of power because that increases its opportunities for concentration of resources from many sources (pull from lots of other cities quickly and easily) or the diffusion of resources to many sources rapidly (put out messages, trends or innovations to many other cities).
 
  How he answers the question
 But the problem is that while the central city has direct and indirect access to resources from a number of sources, so too do the cities to which it is connected.
 Thus, the focal city lacks the ability to control resource exchanges with its exchange partners. These partners have alternatives and thus they can ignore the actions or demands of the focal city.
  That is why such a city is not super powerful. It is replaceable.
  What if power≠centrality?
 Now, for power. Say another city has access to resources from a more limited pool of contacts (i.e. it is not recursively central).
 But it may have significant bargaining and negotiating influence over its exchange partners because it may be one of (or the only) sources for capital, information and other valuable commodities. These partners have no alternatives and thus cannot ignore the focal city’s demands. That is (recursive) power!
  
  What he found ...
 
  Bonacich (beta) centrality
 The Bonacich (Beta) power measure tries to offer split centrality into separate measures of power and dependence, based on the sign of an attenuation parameter
 The power of a node is recursively defined by the sum of the power of its alters.
 
  Bonacich (beta) centrality
 The nature of the recursion involved is then controlled by the power exponent:
■ Positive values imply that vertices become more powerful as their alters become more powerful (as occurs in cooperative relations)
■ Negative values imply that vertices become more powerful only as their alters become weaker (as occurs in competitive or antagonistic relations)
 
  Bonacich (beta) centrality
 The magnitude of the exponent indicates the tendency of the effect to decay across long walks, or how much ego’s local network is valued compared to their further-away neighbors
 Higher magnitudes imply slower decay, or that further-away neighbors are more important to ego
 The network must be symmetric, but can be either binary or valued
 
  Bonacich (beta) centrality
 Calculated as follows:
Cβ(i) = ∑Ai,j(α + βCβ(j))
where α is a scaling parameter; β is a value selected to determine how much of i’s centrality is tied to the centrality of others; and Ai,j is a sociomatrix
  
  Advice network
 609 undirected ties represented
 Node shape: circle=men; squares=women
 Node color: pink=partners; blue=associates
 Node size: eigenvector centrality
 Label size: Beta/Boniach cetrality
 Label color: red=litigation practice; black=corporate practice
 Layout: Fruchterman-Rheingold graph layout
 
   Does the preceding make sense?
Etc.
 
  Advice network conclusions
 Results are based on undirected ties
 Nodes 35 and 16 (male partners in litigation) have the most connections (degree centrality) and are the most in-between
 Node 60 is also very connected and very in-between, but she is a female associate, also in litigation
 In general, degree centrality and betweenness centrality appear to be pretty correlated
 
  Friendship network
 609 undirected ties represented
 Node shape: circle=men; squares=women
 Node color: pink=partners; blue=associates
 Node size: eigenvector centrality
 Label size: Beta/Boniach cetrality
 Label color: red=litigation practice; black=corporate practice
 Layout: Fruchterman-Rheingold graph layout
 
   Does the preceding make sense?
Etc.
 
  Friendship network conclusions
 Results are based on undirected ties
 Node 26! Definitely most degree-central and most between (male, corporate partner), followed closely by 12, 13, 24, and 27 (last one is a female litigation partner)
 As for associates, Node 41 is most central on both measures
 How does this compare to the advice undirected network?
 
  Calculating “centrality” in R
  Starting in R ...
   d=read.csv(file.choose(),header=TRUE,row.names=NULL,check.names=FALSE) # need first column as
   IDs - use “Lazega-Advice-Net.csv” ##
   dm=as.matrix(d) # coerces the data set as a matrix
   dmg=graph.adjacency(dm,mode="directed",weighted=NULL)
   V(dmg)$name
   V(dmg)$status=traits$status[match(V(dmg)$name,traits$ID)]
   V(dmg)$gender=traits$gender[match(V(dmg)$name,traits$ID)]
   V(dmg)$office=traits$office[match(V(dmg)$name,traits$ID)]
   V(dmg)$seniority=traits$seniority[match(V(dmg)$name,traits$ID)]
   V(dmg)$age=traits$age[match(V(dmg)$name,traits$ID)]
   V(dmg)$practice=traits$practice[match(V(dmg)$name,traits$ID)]
   V(dmg)$lawschool=traits$lawschool[match(V(dmg)$name,traits$ID)]
  
  Calculating centralities
  d.in <- degree(dmg, mode = c("in"), loops = TRUE, normalized = FALSE)
  d.out <- degree(dmg, mode = c("out"), loops = TRUE, normalized = FALSE)
  degree <- degree(dmg, loops=T, normalized=F)
  btwn <- betweenness(dmg,  directed = F)
  close <- closeness(dmg, mode = c("all"))
  eigen <- evcent(dmg)
  bon <- bonpow(dmg)
 
  Combining vars to other vars.
 dd <-data.frame(name = V(dmg)$name)
cb1 <- cbind(dd, con, d.in, d.out, close, btwn, eigen, bon, V(dmg)$status, V(dmg)$gender, V
(dmg)$office, V(dmg)$seniority, V(dmg)$age, V(dmg)$practice, V(dmg)$lawschool)
### to send this file for another program, do this ###
write.csv(cb1, "/Users/gregoryeirich/Desktop/Social Networks/conA.csv", row.names=F)
  This data-frame looks like this ...
cb4 = cb1[,c(1:7, 29:36)]
head(cb4)
  name d.in d.out degree       close      btwn    vector           bon V(dmg)$status V(dmg)$gender V(dmg)$office V(dmg)$seniority V(dmg)$age
1 1 12 3
2 2 19 7
3 3 7 7
4 4 17 17
5 5 6 4
6    6   10     0     10 0.006993007  7.556483 0.1783018  4.354686e-16
1             1             1
1             1             1
1             1             2
1             1             1
1             1             2
1             1             2
31         64
32         62
13         67
31         59
31         59
29         55
15 0.007518797 11.809535 0.3392158 -1.841539e-01
26 0.008333333 53.277764 0.5372024 -1.297315e-01
14 0.006944444  8.600505 0.2766227 -5.552606e-01
34 0.008771930 55.105151 0.7293782 -6.795701e-01
10 0.007142857  9.009522 0.1319111 -8.075959e-01
  Correlating these measures ...
 > cb2 <- cbind(d.in, d.out, degree, close, btwn, eigen$vector, bon)
> cor(cb2)
d.in d.out degree close btwn bon d.in 1.0000000 0.097808701 0.7645499 0.7130026 0.4402720 0.7860029 -0.173010359 d.out 0.0978087 1.000000000 0.7162537 0.6462358 0.7193632 0.6351603 -0.006547728 degree 0.7645499 0.716253660 1.0000000 0.9185064 0.7746296 0.9625212 -0.125555998 close 0.7130026 0.646235805 0.9185064 1.0000000 0.6962402 0.8689339 -0.107003358 btwn 0.4402720 0.719363194 0.7746296 0.6962402 1.0000000 0.6323692 -0.155449945
        0.7860029  0.635160302  0.9625212  0.8689339  0.6323692  1.0000000 -0.140437173
bon    -0.1730104 -0.006547728 -0.1255560 -0.1070034 -0.1554499 -0.1404372  1.000000000




 Social Network Analysis (Class 7)
  Gregory M. Eirich QMSS
  Agenda
1. The issue of statistical inference with networks
2. A QAP correlation example
3. A node regression example
4. Statistical significance in R
5. From face-to-face networks to online networks
 
  1. The issue of statistical inference with networks
  A statistical problem?
 How does the data structure of social network data differ from typical data we work with?
 We usually work with (sort of) representative samples
 We usually work with case-attribute data
 
  How does network differ?
 Non-independence of observations
 Sample? Population?
 Interested in predicting relations, not attributes
 
  The inference problem
 On the bright side: The non-independence of observations only affects the standard errors, not the coefficients (or means, or whatever) from models
 What options do we have?
 
  1. Ignore it
  Remember this?
Burt, Ronald S. "Structural holes and good ideas." American journal of sociology 110.2 (2004): 349-399.
  
  1. Ignore it
 This seems to be Burt’s solution
 Just run a regular regression, as if some of the measures were not based on interrelated individuals
 Why make this case?
 
  2a. Adjust standard errors
 We could at least just bootstrap or jack-knife the errors
 Bootstrap-- Resampling observations (with replacement) from the
data in memory some number of times. This is a nonparametric
technique
 Jackknife-- Reruns our analyses many times, but each time excludes
one observation from the dataset and then recalculates all of the
statistics
 In these cases, we use our own data as its own sample
 
  2b. Adjust standard errors
 We could try to cluster our standard errors by whatever “group” we find in the network data
 
  2c. Adjust standard errors
 We could permute the rows and columns, while maintaining the underlying relationship
 This is known as QAP, quadratic assignment procedure, where permutations are carried out on our matrices. We therefore calculate sampling distributions of statistics directly from the observed networks by using random sampling across hundreds or thousands of trials under the assumption that null hypotheses are true
 
  2. A QAP correlation example
  Our question
 How much does being connected in the friend network predict being connected in the advice network?
 In other words-- How strongly are the advice network and the friendship network correlated?
 
  Correlating advice and friendship
 Many measures available
Hubert's gamma: 134.000
Bivariate Statistics
1234567 Value Signif Avg SD P(Large) P(Small) NPerm --------- --------- --------- --------- --------- --------- ---------
    1
    2
    3
    4  Goodman-Kruskal Gamma:
    5       Hamming Distance:   1195.000     0.006  1252.692    33.118     0.994     0.006  2500.000
  Pearson Correlation:
    Simple Matching:
Jaccard Coefficient:
0.048     0.006     0.000
0.760     0.006     0.748
0.101     0.006     0.077
0.176     0.006    -0.001
0.018     0.006
0.016     0.006
0.009     0.006
0.071     0.006
0.994  2500.000
0.994  2500.000
0.994  2500.000
0.994  2500.000
  Correlating advice and friendship
  
The Pearson correlation is most appropriate when both matrixes are measured at the interval level
2,500 random permutations of the data were run, and only 0.6% (aka, 0.006) of the time did we get a correlation as large as 0.048 by chance
1234567 Value Signif Avg SD P(Large) P(Small) NPerm --------- --------- --------- --------- --------- --------- --------- Pearson Correlation: 0.048 0.006 0.000 0.018 0.006 0.994 2500.000
 1
  Correlating advice and friendship
  
Simple matching is most appropriate when both relations are binary 2,500 random permutations of the data were run, and only 0.6% (aka, 0.006) of the time did we get as many as 76% matches (1 for advice relation and 1 for friendship, or 0s instead) by chance
 2
1234567 Value Signif Avg SD P(Large) P(Small) NPerm --------- --------- --------- --------- --------- --------- --------- Simple Matching: 0.760 0.006 0.748 0.016 0.006 0.994 2500.000
  Correlating advice and friendship
 
On average--just based on the network’s density and average degree, 74.8% of the ties would be matched if we just randomly assigned the 1s and 0s
 2
1234567 Value Signif Avg SD P(Large) P(Small) NPerm --------- --------- --------- --------- --------- --------- --------- Simple Matching: 0.760 0.006 0.748 0.016 0.006 0.994 2500.000
  Correlating advice and friendship
 Gamma if the relations were measured on an ordinal scale
 The Jaccard coefficient is for binary relations (when at least one of
the elements is a 1)
 The Hamming distance is a measure of dissimilarity or distance
between the scores in one matrix and the scores in the other (it is the number of values that differ, element-wise, from one matrix to the
other).
  1234567 Value Signif Avg SD P(Large) P(Small) NPerm --------- --------- --------- --------- --------- --------- --------- 0.101 0.006 0.077 0.009 0.006 0.994 2500.000 0.176 0.006 -0.001 0.071 0.006 0.994 2500.000 5 Hamming Distance: 1195.000 0.006 1252.692 33.118 0.994 0.006 2500.000
3    Jaccard Coefficient:
4  Goodman-Kruskal Gamma:
  Beyond QAP correlation
 There is QAP regression, where we are predicting one sociomatrix with another sociomatrix
 And there is MR-QAP regression, where multiple sociomatrices are used to predict some dependent sociomatrix
 
  3. A regression example
  Our question
 What factors predict someone’s in-degree (centrality) in the advice network?
 
  Predicting (advice)
. reg  AiDegree  STATUS GENDER SENIORITY i.LAW_SCHOOL
      Source |       SS       df       MS
-------------+------------------------------
       Model |  1613.48981     5  322.697963
    Residual |  1859.24258    65   28.603732
-------------+------------------------------
       Total |  3472.73239    70  49.6104628
in-degree
Number of obs =      71
F(  5,    65) =   11.28
Prob > F      =  0.0000
R-squared     =  0.4646
Adj R-squared =  0.4234
Root MSE      =  5.3482
 ------------------------------------------------------------------------------
    AiDegree |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
      STATUS |  -7.662197   1.978772    -3.87   0.000    -11.61408   -3.710317
      GENDER |    1.51673   1.641727     0.92   0.359    -1.762025    4.795484
   SENIORITY |   .0842354   .1070736     0.79   0.434    -.1296052    .2980761
             |
  LAW_SCHOOL |
          2  |  -.9304084   1.839803    -0.51   0.615    -4.604749    2.743932
          3  |  -3.680561   1.849535    -1.99   0.051    -7.374339    .0132163
             |
       _cons |    19.0864   4.568327     4.18   0.000     9.962823    28.20998
------------------------------------------------------------------------------
  Predicting (advice) in-degree
We can explain 42% of the variance in someone’s (advice) in-degree based
on these four factors, but mainly status (partner vs. associate)
  . reg  AiDegree  STATUS GENDER SENIORITY i.LAW_SCHOOL
      Source |       SS       df       MS
-------------+------------------------------
       Model |  1613.48981     5  322.697963
    Residual |  1859.24258    65   28.603732
-------------+------------------------------
       Total |  3472.73239    70  49.6104628
Number of obs =      71
F(  5,    65) =   11.28
Prob > F      =  0.0000
R-squared     =  0.4646
Adj R-squared =  0.4234
Root MSE      =  5.3482
------------------------------------------------------------------------------
    AiDegree |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
      STATUS |  -7.662197   1.978772    -3.87   0.000    -11.61408   -3.710317
      GENDER |    1.51673   1.641727     0.92   0.359    -1.762025    4.795484
   SENIORITY |   .0842354   .1070736     0.79   0.434    -.1296052    .2980761
             |
  LAW_SCHOOL |
          2  |  -.9304084   1.839803    -0.51   0.615    -4.604749    2.743932
          3  |  -3.680561   1.849535    -1.99   0.051    -7.374339    .0132163
|
  Predicting (advice) in-degree
See-- We can explain ~43% of the variance in someone’s (advice) in-degree based on two factors, but mainly status (partner vs. associate)
. reg AiDegree STATUS i.LAW_SCHOOL
         Source |       SS       df       MS
-------------+------------------------------
       Model |   1577.5335     3    525.8445
    Residual |  1895.19889    67  28.2865506
-------------+------------------------------
       Total |  3472.73239    70  49.6104628
Number of obs =      71
F(  3,    67) =   18.59
Prob > F      =  0.0000
R-squared     =  0.4543
Adj R-squared =  0.4298
Root MSE      =  5.3185
------------------------------------------------------------------------------
    AiDegree |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
      STATUS |  -8.265361    1.32785    -6.22   0.000    -10.91576    -5.61496
             |
  LAW_SCHOOL |
          2  |  -1.227675   1.785575    -0.69   0.494    -4.791698    2.336349
          3  |  -4.246629   1.759182    -2.41   0.019    -7.757971   -.7352864
|
_cons |   23.11843   2.103511    10.99   0.000     18.91981    27.31706
  Predicting (advice) in-degree
Associates have an in-degree centrality score 7.66 points lower than
partners, net gender, seniority and law school attended
  . reg  AiDegree  STATUS GENDER SENIORITY i.LAW_SCHOOL
      Source |       SS       df       MS
-------------+------------------------------
       Model |  1613.48981     5  322.697963
    Residual |  1859.24258    65   28.603732
-------------+------------------------------
       Total |  3472.73239    70  49.6104628
Number of obs =      71
F(  5,    65) =   11.28
Prob > F      =  0.0000
R-squared     =  0.4646
Adj R-squared =  0.4234
Root MSE      =  5.3482
------------------------------------------------------------------------------
    AiDegree |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
      STATUS |  -7.662197   1.978772    -3.87   0.000    -11.61408   -3.710317
      GENDER |    1.51673   1.641727     0.92   0.359    -1.762025    4.795484
   SENIORITY |   .0842354   .1070736     0.79   0.434    -.1296052    .2980761
             |
  LAW_SCHOOL |
          2  |  -.9304084   1.839803    -0.51   0.615    -4.604749    2.743932
          3  |  -3.680561   1.849535    -1.99   0.051    -7.374339    .0132163
|
  Predicting (advice) in-degree
Those lawyers who went to “other” law schools, have an in-degree centrality
3.68+ lower than those who went to “Harvard or Yale,” net of other factors
  . reg  AiDegree  STATUS GENDER SENIORITY i.LAW_SCHOOL
      Source |       SS       df       MS
-------------+------------------------------
       Model |  1613.48981     5  322.697963
    Residual |  1859.24258    65   28.603732
-------------+------------------------------
       Total |  3472.73239    70  49.6104628
Number of obs =      71
F(  5,    65) =   11.28
Prob > F      =  0.0000
R-squared     =  0.4646
Adj R-squared =  0.4234
Root MSE      =  5.3482
------------------------------------------------------------------------------
    AiDegree |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
      STATUS |  -7.662197   1.978772    -3.87   0.000    -11.61408   -3.710317
      GENDER |    1.51673   1.641727     0.92   0.359    -1.762025    4.795484
   SENIORITY |   .0842354   .1070736     0.79   0.434    -.1296052    .2980761
             |
  LAW_SCHOOL |
          2  |  -.9304084   1.839803    -0.51   0.615    -4.604749    2.743932
          3  |  -3.680561   1.849535    -1.99   0.051    -7.374339    .0132163
|
  Bootstraping (advice) in-degree
 . bootstrap: reg  AiDegree  STATUS GENDER SENIORITY i.LAW_SCHOOL
Linear regression
Number of obs
Replications
Wald chi2(5)
Prob > chi2
R-squared
Adj R-squared
Root MSE
=        71
=        50
=     87.09
=    0.0000
=    0.4646
=    0.4234
=    5.3482
------------------------------------------------------------------------------
             |   Observed   Bootstrap                         Normal-based
    AiDegree |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
      STATUS |  -7.662197   1.769646    -4.33   0.000    -11.13064   -4.193753
      GENDER |    1.51673   1.272362     1.19   0.233    -.9770547    4.010514
   SENIORITY |   .0842354    .116689     0.72   0.470    -.1444707    .3129416
             |
  LAW_SCHOOL |
          2  |  -.9304084   2.261982    -0.41   0.681    -5.363812    3.502995
          3  |  -3.680561   2.155769    -1.71   0.088     -7.90579    .5446681
             |
       _cons |    19.0864   4.862125     3.93   0.000     9.556811    28.61599
------------------------------------------------------------------------------
  Bootstraping (advice) in-degree
Status is still highly stat. sig.--actually even more stat. sig (z=-4.33 vs. -3.87 earlier)--, but going to an “other” law school is even less stat. sig. than before . bootstrap: reg AiDegree STATUS GENDER SENIORITY i.LAW_SCHOOL
  Linear regression
Number of obs
Wald chi2(5)
Prob > chi2
R-squared
Adj R-squared
Root MSE
=
=
=
=    0.4646
=    0.4234
=    5.3482
------------------------------------------------------------------------------
             |   Observed   Bootstrap                         Normal-based
    AiDegree |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
      STATUS |  -7.662197   1.769646    -4.33   0.000    -11.13064   -4.193753
[omitted]
             |
  LAW_SCHOOL |
          2  |  -.9304084   2.261982    -0.41   0.681    -5.363812    3.502995
          3  |  -3.680561   2.155769    -1.71   0.088     -7.90579    .5446681
    71
 87.09
0.0000
|
  Remember, this is a count
. bootstrap: nbreg  AiDegree  STATUS GENDER SENIORITY i.LAW_SCHOOL
 Negative binomial regression
Dispersion     = mean
Log likelihood = -208.53934
------------------------------------------------------------------------------
             |   Observed   Bootstrap                         Normal-based
    AiDegree |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
      STATUS |  -1.063602   .2025611    -5.25   0.000    -1.460614   -.6665892
      GENDER |   .2474911   .2428793     1.02   0.308    -.2285437    .7235258
   SENIORITY |   .0117722   .0106451     1.11   0.269    -.0090919    .0326363
             |
  LAW_SCHOOL |
          2  |  -.0166565   .2263294    -0.07   0.941    -.4602539     .426941
          3  |  -.4790638   .2392379    -2.00   0.045    -.9479615   -.0101661
             |
       _cons |   3.313322   .4799291     6.90   0.000     2.372678    4.253966
-------------+----------------------------------------------------------------
    /lnalpha |  -1.030193   .3353133                     -1.687395   -.3729912
-------------+----------------------------------------------------------------
       alpha |    .356938   .1196861                      .1850008    .6886713
------------------------------------------------------------------------------
Likelihood-ratio test of alpha=0:  chibar2(01) =   69.71 Prob>=chibar2 = 0.000
Number of obs   =
Wald chi2(5)    =
Prob > chi2     =
    71
 63.35
0.0000
  Remember, this is a count
Negative binomial regression is appropriate for count outcomes, where the variance (49.6) is much greater than the mean (8.6)
. bootstrap: nbreg AiDegree STATUS GENDER SENIORITY i.LAW_SCHOOL
  Negative binomial regression
Dispersion     = mean
Log likelihood = -208.53934
Number of obs   =
Wald chi2(5)    =
Prob > chi2     =
    71
 63.35
0.0000
------------------------------------------------------------------------------
             |   Observed   Bootstrap                         Normal-based
    AiDegree |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
      STATUS |  -1.063602   .2025611    -5.25   0.000    -1.460614   -.6665892
      GENDER |   .2474911   .2428793     1.02   0.308    -.2285437    .7235258
   SENIORITY |   .0117722   .0106451     1.11   0.269    -.0090919    .0326363
             |
  LAW_SCHOOL |
          2  |  -.0166565   .2263294    -0.07   0.941    -.4602539     .426941
          3  |  -.4790638   .2392379    -2.00   0.045    -.9479615   -.0101661
             |
       _cons |   3.313322   .4799291     6.90   0.000     2.372678    4.253966
 
  Node-level regression
 After running a regular OLS regression, the procedure randomly permutes the elements of the dependent vector and recomputes the regression.
 This step is repeated hundreds of times in order to estimate standard errors for the statistics of interest.
 For each coefficient, the program counts the proportion of random permutations that yielded a coefficient as extreme as the one computed in the typical OLS.
 
  Node-level regression
This is the UCINET output ...
MODEL FIT
         Adjusted                One-Tailed
 R-square R-square    F Value   Probability
 -----------------    -------   -----------
    0.461    0.421     14.114         0.005
 REGRESSION COEFFICIENTS
                  Un-stdized    St'dized  Proportion  Proportion  Proportion
  Independent    Coefficient Coefficient    As Large    As Small  As Extreme
  ----------- -------------- ----------- ----------- ----------- -----------
   Intercept
    STATUS
    GENDER
 SENIORITY
LAW_SCHOOL
21.494812
-7.594669
 1.600105
 0.076265
-1.991644
 0.000000
-0.542912
 0.099531
 0.104029
-0.215399
1.000
0.995
0.261
0.310
0.936
0.000
0.005
0.739 0.691
0.064
1.000 0.011
0.521 0.622
0.119
  Node-level regression
Pretty much same coefficients and R-sq as earlier. E.g., For status, 5
times out of 1000, we would get a coefficient that large by chance
MODEL FIT
         Adjusted                One-Tailed
 R-square R-square    F Value   Probability
 -----------------    -------   -----------
    0.461    0.421     14.114         0.005
 REGRESSION COEFFICIENTS
                  Un-stdized    St'dized  Proportion  Proportion  Proportion
  Independent    Coefficient Coefficient    As Large    As Small  As Extreme
  ----------- -------------- ----------- ----------- ----------- -----------
   Intercept
    STATUS
    GENDER
 SENIORITY
LAW_SCHOOL
21.494812
-7.594669
 1.600105
 0.076265
-1.991644
 0.000000
-0.542912
 0.099531
 0.104029
-0.215399
1.000
0.995
0.261
0.310
0.936
0.000
0.005
0.739 0.691
0.064
1.000 0.011
0.521 0.622
0.119
  More to come ...
 We will still see ERGMs-- Exponential Random Graph Models
 Also, we will see p1 and p* models
 
  Statistical significance in R
  How to do bootstrapping in R
 Here is how to do bootstrapping to at least try to deal with non- independent observations (in node-level regression)
      d=read.csv("C:/Documents and Settings/gme2101/Desktop/R-panel-practice-gss.csv")
      lm = lm(nhappy ~ nattend, data=d)
      summary(lm)
      install.packages("simpleboot")
      library(simpleboot)
      boot = lm.boot(lm, 50)
      summary(boot)
  
  How to do QAP regression in R
 
Install “sna” package and load in new sociomatrices
install.packages("sna")
library(sna)
da=read.csv("C:/Documents and Settings/gme2101/Desktop/QMSS Social Networks/Krack-Advice-no-row.csv")
df=read.csv("C:/Documents and Settings/gme2101/Desktop/QMSS Social Networks/Krack-Friend-no-row.csv")
dr=read.csv("C:/Documents and Settings/gme2101/Desktop/QMSS Social Networks/Krack-Report-no-row.csv")
dam = as.matrix(da)
dfm = as.matrix(df)
drm = as.matrix(dr)
 
  What socio-matrices are these?
 From Krackhardt D. (1987). “Cognitive social structures.” Social Networks, 9, 104-134.
 These data were collected from the managers of a high-tech company. The company manufactured high-tech equipment on the west coast of the United States and had just over 100 employees with 21 managers.
 The 3 socio-matrices are on Courseworks for the code to work
 
  What socio-matrices are these?
 3 socio-matrices were created:
1. Each manager was asked-- "To whom do you go to for
advice?" (da)
2. "Who is your friend?" (df)
3. Data for the item "To whom do you report?" was taken from
company documents. (dr)
 In addition attribute information was collected, like age, tenure, level
in the hierarchy and department.
    
  How to do QAP regression in R
 
Run the regressions and do correlations
nl<-netlm(dam, dfm)
summary(nl)
myxs <- array(NA, c(2, length(dam[1,]),length(dam[1,])))
myxs[1,,] <- dam
myxs[2,,] <- drm
n2<-netlm(dfm, myxs)
summary(n2)
 
  How to do QAP regression in R
 Let’s look at some of the output of these commands: Predicting the advice network from the friendship network (x1) shows that they are
correlated at sqrt(0.0239, which is the R-squared)=0.154, with p=0.029 > nl<-netlm(dam, dfm)
> summary(nl)
OLS Network Model Residuals:
              0%        25%        50%        75%       100%
      -0.5882353 -0.4088050 -0.4088050  0.5911950  0.5911950
      Coefficients:
                  Estimate  Pr(<=b) Pr(>=b) Pr(>=|b|)
(intercept) 0.4088050 1.000 0.000 0.000 x1 0.1794303 0.987 0.015 0.029
Residual standard error: 0.4929 on 418 degrees of freedom
Multiple R-squared: 0.0239 Adjusted R-squared: 0.02156 F-statistic: 10.23 on 1 and 418 degrees of freedom, p-value: 0.001484
  
  How to do QAP regression in R
Predicting the friendship network from the advice (x1) and the “who reports to who”
(drm, or x1) network shows, net of each other, the “who reports” network is 3x
(0.32 [p=0.00] vs. 0.10 [p=0.10]) better as a predictor of friendship ties
> myxs <- array(NA, c(2, length(dam[1,]),length(dam[1,]))) > myxs[1,,] <- dam
> myxs[2,,] <- drm
> n2<-netlm(dfm, myxs)
> summary(n2)
OLS Network Model [omitted]
      Coefficients:
                  Estimate  Pr(<=b) Pr(>=b) Pr(>=|b|)
  (intercept) 0.1812110 0.989
x1          0.1024305 0.955
x2          0.3214801 1.000
0.011   0.011
0.045   0.101
0.000   0.000
Residual standard error: 0.4199 on 417 degrees of freedom
Multiple R-squared: 0.04811     Adjusted R-squared: 0.04355
F-statistic: 10.54 on 2 and 417 degrees of freedom, p-value: 3.428e-05
  How correlated are the 3 matrices on some other measure?
Let’s correlate in-degree across the 3 matrices; we see they are not very correlated, especially friendship and “who reports to who”
      ### This below will show how correlated in-degree is across the matrices ###
      indegA = degree(dam, cmode="indegree")
      indegF = degree(dfm, cmode="indegree")
      indegR = degree(drm, cmode="indegree")
      corrcent = cbind(indegA, indegF, indegR)
      cor(corrcent)
      ### this is the output here ###
                indegA     indegF     indegR
      indegA 1.0000000 0.30530294 0.53999121
      indegF 0.3053029 1.00000000 0.09141057
      indegR 0.5399912 0.09141057 1.00000000
  
  5. From face-to-face networks to online networks
  How are online networks different?
 Web 1.0
 Web 2.0
 Web 3.0?
 
  Remember -Facebook ego network
 Web 1.0
 Web 2.0
 Web 3.0
  



 Social Network Analysis (Class 10)
  Gregory M. Eirich QMSS
  Agenda
1. Positions and roles
2. “Non-people” social networks
 
  1. Positions and roles
  Two weeks ago ...
 We looked at how to determine which nodes belong together to which sub-group
 This is meant to capture group cohesion
 
  Now ...
 We will look at nodes that we might group together but for different reasons
 Namely, because different nodes occupy the same structural positions in the social network (equivalence)
 
  Some examples of this ...
  Finding structural equivalence
 Perfect structural equivalence is when two nodes have the exact same set of relations to exact same other nodes
  Regular equivalence is when two nodes have a similar set of relations to similar types of nodes -- i.e., similar “roles”
  Finding structural equivalence
 To find structurally equivalent nodes, the common technique is blockmodeling, usually via CONCOR (Convergence of iterated Correlations)
 Correlate columns of an adjacency matrix, based on the relations to all other nodes, where complete similarity to other nodes is +1 and complete dissimilarity is -1
 Then, the process is re-done on those correlations, over and over again, until each pair (i, j) is either +1 or -1
 
  Finding structural equivalence
 Then, the columns and rows are permuted to move the highly correlated pairs into 2 big “blocks” -- and then it is broken down further, until the researcher stops it
 A density matrix tells us how many 1s are in each block and how much overlap there is between blocks
 Usually a density cut-off is used to create an image matrix (of positions of positions)
 
 Why worry about structural equivalence?
 
  Effects of structural equivalence
 Negro, G. and S. Goodman. 2015. “Niche Overlap and Discrediting Acts: An Empirical Analysis of Informing in Hollywood.” Sociological Science. Forthcoming.
  Effects of structural equivalence
 What makes an actor inform on another actor in Hollywood in the 1950s during the “Red Scare”?
 
  Finding structural equivalence
 An actor is more likely to inform on actors who are more “structurally equivalent” to them, in terms of genre, past work history, level of accomplishment, etc.
 As they say, “For example, we expect that an Oscar-nominated actor active in the romance genre would perceive another actor with similar artistic achievement in the same genre as having greater overlap in the labor market and vying for the same kind of projects.”
 
  Effects of structural equivalence
 Actors are much more likely to inform on actors who are similar to them (have high niche overlap), net of lots of other relationships and attributes
 
  Effects of structural equivalence
 
  Another example
  Amazon’s book network revealed
 What makes an actor inform on another actor in Hollywood in the 1950s during the “Red Scare”?
  
  What’s bought with what?
 What makes an actor inform on another actor in Hollywood in the 1950s during the “Red Scare”?
  
 What’s bought with what in politics?
 Valdis Krebs, a consultant who runs OrgNet LLC, collected via snowball sampling the strong ties among political books bought together on Amazon in 2003
 This is the picture that emerges ...
  
   What’s bought with what?
 What makes an actor inform on another actor in Hollywood in the 1950s during the “Red Scare”?
 
 What’s bought with what in politics?
 The question becomes: If I weren’t going to read The Bush Dislexicon, what other book was most like reading it, in terms of its connections to other books?
 Or as he writes: “Another common network measure is structural equivalence. It reveals which nodes play a similar role in a network. Equivalent nodes may be substitutable for one another in the network. As an author, I would not like my book to be substitutable with many other books! As a reader, I would like equivalent choices.”
  
 What’s bought with what in politics?
   (BTW, do you see the only book holding the conservative and liberal camps together in 2003?)
  One more example
  Influence vs. equivalence
 Burt, Ronald S. "Social contagion and innovation: Cohesion versus structural equivalence." American journal of Sociology (1987): 1287-1335.
 
  His question
 Should I -- as a doctor -- adopt this new drug?
 Did the physicians resolve this uncertainty through conversations with colleagues (cohesion) or through their perception of the action proper for an occupant of their position in the social structure of colleagues (structural equivalence)?
  His insight
  Sometimes, equivalence
and cohesion look the same
  His insight
  Ego and alter are cohesive,
but not structural equivalent
  His insight
 Ego and alter are not
cohesive, but they are structurally equivalent
 
  What he found
 Doctors monitored the behavior of their most equivalent alters when deciding when to adopt, much more so than simply relying on the alters whom they were most close to emotionally
  A worked example ...
 Sample of 24 countries, recording directed binary interactions in the trade of manufactured goods
 From: Smith D and D White (1988). Structure and dynamics of the global economy: Network analysis of international trade 1965-1980. Unpublished Manuscript. & Wasserman S and K Faust (1994). Social Network Analysis: Methods and Applications.Cambridge University Press, Cambridge.
 
  Manufacturing relations
 
  6 7 8 9
10
11
12
13
14
15
Correlation matrix
 Which countries have manufacturing relations similar to each other?
1 2 3 4 5 6 7 8 9101112131415161718192021 ALGER ARGEN BRAZI CHINA CZECH ECUAD EGYPT ETHIO FINLA HONDU INDON ISRAE JAPAN LIBER MADAG NEW_Z PAKIS SPAIN SWITZ SYRIA THAIL UN ----- ----- ----- ----- ----- ----- ----- ----- ----- ----- ----- ----- ----- ----- ----- ----- ----- ----- ----- ----- ----- --
  1
2
3
4
5 CZECHOSLOVAKIA   0.23  0.37  0.46  0.64  1.00  0.19  0.43  0.21  0.64  0.29  0.42  0.30  0.65  0.27  0.24  0.42  0.39  0.43  0.64  0.21  0.33  0
  ALGERIA   1.00  0.28  0.18  0.39  0.23  0.51  0.64  0.35  0.27  0.57  0.60  0.27  0.29  0.52  0.42  0.50  0.53  0.30  0.20  0.56  0.47  0
ARGENTINA   0.28  1.00  0.46  0.19  0.37  0.43  0.28  0.28  0.52  0.41  0.42  0.36  0.38  0.26  0.17  0.45  0.37  0.42  0.45  0.28  0.57  0
   BRAZIL   0.18  0.46  1.00  0.44  0.46  0.35  0.19  0.03  0.56  0.33  0.51  0.39  0.44  0.18  0.27  0.31  0.47  0.50  0.56  0.14  0.36  0
    CHINA   0.39  0.19  0.44  1.00  0.64  0.27  0.46  0.03  0.48  0.26  0.65  0.45  0.73  0.24  0.20  0.46  0.62  0.51  0.59  0.29  0.46  0
          ECUADOR   0.51  0.43  0.35  0.27  0.19  1.00  0.39  0.35  0.28  0.81  0.33  0.39  0.19  0.62  0.47  0.29  0.35  0.22  0.24  0.59  0.42  0
            EGYPT   0.64  0.28  0.19  0.46  0.43  0.39  1.00  0.53  0.36  0.57  0.63  0.54  0.35  0.42  0.46  0.47  0.57  0.25  0.29  0.44  0.50  0
         ETHIOPIA   0.35  0.28  0.03  0.03  0.21  0.35  0.53  1.00  0.29  0.52  0.25  0.32  0.21  0.45  0.57  0.43  0.28  0.23  0.25  0.54  0.33  0
          FINLAND   0.27  0.52  0.56  0.48  0.64  0.28  0.36  0.29  1.00  0.26  0.54  0.47  0.73  0.24  0.21  0.56  0.40  0.65  0.87  0.29  0.57  0
         HONDURAS   0.57  0.41  0.33  0.26  0.29  0.81  0.57  0.52  0.26  1.00  0.41  0.35  0.18  0.80  0.65  0.47  0.43  0.20  0.22  0.76  0.39  0
        INDONESIA   0.60  0.42  0.51  0.65  0.42  0.33  0.63  0.25  0.54  0.41  1.00  0.53  0.48  0.38  0.33  0.78  0.77  0.52  0.45  0.46  0.67  0
           ISRAEL   0.27  0.36  0.39  0.45  0.30  0.39  0.54  0.32  0.47  0.35  0.53  1.00  0.35  0.19  0.33  0.38  0.48  0.25  0.41  0.33  0.50  0
            JAPAN   0.29  0.38  0.44  0.73  0.65  0.19  0.35  0.21  0.73  0.18  0.48  0.35  1.00  0.17  0.14  0.42  0.46  0.73  0.84  0.21  0.50  0
          LIBERIA   0.52  0.26  0.18  0.24  0.27  0.62  0.42  0.45  0.24  0.80  0.38  0.19  0.17  1.00  0.70  0.44  0.39  0.19  0.21  0.83  0.36  0
       MADAGASCAR   0.42  0.17  0.27  0.20  0.24  0.47  0.46  0.57  0.21  0.65  0.33  0.33  0.14  0.70  1.00  0.38  0.35  0.16  0.17  0.57  0.31  0
16    NEW_ZEALAND   0.50  0.45  0.31  0.46  0.42  0.29  0.47  0.43  0.56  0.47  0.78  0.38  0.42  0.44  0.38  1.00  0.54  0.46  0.48  0.53  0.64  0
17       PAKISTAN   0.53  0.37  0.47  0.62  0.39  0.35  0.57  0.28  0.40  0.43  0.77  0.48  0.46  0.39  0.35  0.54  1.00  0.50  0.42  0.48  0.72  0
18          SPAIN   0.30  0.42  0.50  0.51  0.43  0.22  0.25  0.23  0.65  0.20  0.52  0.25  0.73  0.19  0.16  0.46  0.50  1.00  0.76  0.23  0.55  0
19    SWITZERLAND   0.20  0.45  0.56  0.59  0.64  0.24  0.29  0.25  0.87  0.22  0.45  0.41  0.84  0.21  0.17  0.48  0.42  0.76  1.00  0.25  0.47  0
20          SYRIA   0.56  0.28  0.14  0.29  0.21  0.59  0.44  0.54  0.29  0.76  0.46  0.33  0.21  0.83  0.57  0.53  0.48  0.23  0.25  1.00  0.44  0
21       THAILAND   0.47  0.57  0.36  0.46  0.33  0.42  0.50  0.33  0.57  0.39  0.67  0.50  0.50  0.36  0.31  0.64  0.72  0.55  0.47  0.44  1.00  0
22 UNITED_KINGDOM   0.16  0.37  0.24  0.36  0.43  0.06  0.38  0.24  0.51  0.20  0.40  0.13  0.55  0.19  0.16  0.46  0.37  0.66  0.60  0.23  0.42  1
23  UNITED_STATES   0.24  0.34  0.52  0.49  0.42  0.18  0.31  0.18  0.66  0.17  0.43  0.31  0.69  0.15  0.13  0.37  0.41  0.63  0.76  0.18  0.45  0
24     YUGOSLAVIA   0.36  0.41  0.39  0.48  0.50  0.09  0.56  0.35  0.60  0.31  0.58  0.46  0.61  0.16  0.25  0.58  0.53  0.40  0.47  0.24  0.51  0
   I
-
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
  The blockmodels
 
What if countries are only partitioned once?
111 2 14508670 ALMHEEES
9 4 5
11 1 2 3 1 I J I
1 1 11 3 6 7 89 B N P SS
2 22 2 2 1 23 4 A T UU Y
                   F C C
---------------------------------------------------
 1 14 15 10 8
 4          CHINA | 1 1 1 1 1   1 1 | 1
 5 CZECHOSLOVAKIA | 1 1   1 1 1 1 1 | 1 1
ALGERIA |
1 | | | 1 | 11 | 6 ECUADOR | | 1 1 | 7 EGYPT | 1 | 1 1 1 11 1 1 1 | 20 SYRIA | | | ----------------------------------------------------- 9 FINLAND | 1 1 1 1 1 1 | 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 |
12 13 11
ISRAEL |         1       | 1
 JAPAN | 1 1 1 1 1 1 1 1 | 1 1 1 1
 3
16
17
18
19
 2
21
1
1 1 1 1 1 1 1 1 1 |
  1 1     1 1 1 1 |
1   1 1   1 1 1   |
   LIBERIA |
MADAGASCAR |
  HONDURAS |
  ETHIOPIA |
| 11 1 |
|
|
1
  INDONESIA | 1
     BRAZIL | 1 1
NEW_ZEALAND | 1
   PAKISTAN |   1
  1   | 1 1 1
1 1 1 | 1 1 1 1 1 1
  1   |   1     1 1
    1 | 1 1 1   1 1
      SPAIN | 1 1 1 1
SWITZERLAND | 1 1 1 1 1 1 1 1 | 1 1 1 1 1 1 1 1 1 1
1 1 1 1 1 1 |
  1 1 1 1 1 |
|
1
1 1 1 1 1 1 1 1 1 1 1 1 |
1 1 1 1 1 1 1 1 1 1 1 1 |
1     1   1 1 1 1 1 1 1 |
  1 1 1 1 1 1 1 1 1 1 1 |
      1 1 1 1   1 1 1 1 |
1 1 1 | 1 1 1 1 1 1 1 1 1
                                                              1   1   |
                                                                1 1 1 |
                                                              1   1 1 |
23  UNITED_STATES | 1 1 1 1 1 1 1 1 | 1 1 1 1 1 1 1 1 1 1 1 1 1 1   1 |
24     YUGOSLAVIA | 1       1   1 1 | 1 1 1 1 1 1   1 1 1 1 1 1 1 1   |
        ARGENTINA | 1         1     | 1 1   1 1 1 1   1 1 1
         THAILAND |               1 | 1 1   1 1 1 1 1 1 1 1
22 UNITED_KINGDOM | 1 1 1 1 1 1 1 1 | 1 1 1 1 1 1 1 1 1 1 1
1
----------------------------------------------------
  Image matrix
 One-level partition
 Further reduce our data by 0 if density within cell < 0.562;
1 if density is >= 0.562
  Original Density Matrix
12 ----- -----
1 0.018 0.141
2 0.617 0.883
Image matrix
            1     2
        ----- -----
1 0.000 0.000
2 1.000 1.000

Block 2 interacts amongst itself and initiates the sending of manufactured goods to Block 1, while Block 1 does not initiate (or interact) with anyone, even amongst themselves
 
  The blockmodels
11 12 2 1 1 1 1 2 1 1 2 21 187 54600 1 6 7 2 1 4 2 34 3 9 59 2 38 AEE MLEHS T N P I I Y A JC B S CF U US
------------------------------------------------------- 1 ALGERIA | | | 1 | 1 1 1 | 8 ETHIOPIA | | | | 1 1 | 7 EGYPT | 1 | | 1 | 1 1 11 1 11 |
                  ---------------------------------------------------------
15     MADAGASCAR |       |           |               |             1     |
14        LIBERIA |       |           |               |                   |
6 ECUADOR | | | | 1 1 | 10 HONDURAS | | | | 1| 20 SYRIA | | | | |
 What if countries are partitioned at two levels?
  21
16
17
12
11
24
2
13
 4
 3
19
 5
 9
22
23
18
   THAILAND |
NEW_ZEALAND | 1
   PAKISTAN |
     ISRAEL |
| 1 | | 1 | 1 | 1 1 |
1 11
|   1 1
| 1   1
| 1 1
| 1 1
| 1 1 1
| 1 1 1
| 1
1 1 1 1
1
|1 1 |1 1 |1 1
1 |1 |1 1
1 1
1 1 1 1 1 1 1 1 1 1 1
1
 INDONESIA | 1
YUGOSLAVIA | 1
 ARGENTINA | 1
1 1
1 1 1 1 1 1 1 1
JAPAN |1 1 1|
CHINA |1 1 1| BRAZIL |1 1| SWITZERLAND |1 1 1| CZECHOSLOVAKIA |1 1 1| FINLAND |1 1 1| UNITED_KINGDOM |1 1 1| UNITED_STATES |1 1 1|
1 1 1 11| 1 1 1 1 1 11| 1 1 1 1 1 11| 1 1 1 1 1 1 11| 1 1 1 1 1 11| 1 1 1 1 11| 1 1 1 1 1 1 11| 1 1 1 1 1 1 11| 1 1 1
1 11 1 | 1 11 1 | 1 1 11 1 | 1 1 1 11 1 | 1 1
11 1 | 1 1 1 11 1 | 1 1 1 11 | 1 1 1 11 1 | 1 1 1 11 1 | 1 1
1 1 1 1 1 1 1 |
1 1 1 1 1 1 1 |
  1 1 1 1 1 1 |
1   1 1 1 1 1 |
1 1   1 1 1 1 |
1 1 1   1 1 1 |
1 1 1 1   1 1 |
1 1 1 1 1   1 |
---------------------------------------------------------
                  1
---------------------------------------------------------
| 1
1 1 1
1 |1 1 |1 1
1
1 1
SPAIN |1 --------------------------------------------------------
1| 1
11| 1 1 1
1 1 1 1 1 1
|
1 1
1
11 | 11 | 11 | 11 | 11 | 11 | 11 |
  Image matrix
 Two-level partition
 Further reduce our data by 0 if density within cell < 0.562;
1 if density is >= 0.562
  Original Density Matrix
1234 ----- ----- ----- -----
    1   0.167 0.000 0.095 0.444
    2   0.000 0.000 0.000 0.089
    3   0.429 0.143 0.714 0.794
    4   0.926 0.889 0.952 1.000
Image Matrix
1234 ----- ----- ----- -----
    1   0.000 0.000 0.000 0.000
    2   0.000 0.000 0.000 0.000
    3   0.000 0.000 1.000 1.000
    4   1.000 1.000 1.000 1.000
 Block 4 (mostly most of the most developed countries) interacts amongst itself and initiates the sending of manufactured goods to all other blocks, and Block 3 (pretty developed) also interact with themselves and Block 4
 
  12 2
16 21 17 24 11
4 3 5
13 19 9 22 23 18
        ISRAEL
     ARGENTINA
   NEW_ZEALAND
      THAILAND
      PAKISTAN
    YUGOSLAVIA
     INDONESIA
         CHINA
        BRAZIL
CZECHOSLOVAKIA
         JAPAN
   SWITZERLAND
       FINLAND
UNITED_KINGDOM
 UNITED_STATES
         SPAIN
| 11 | | | | | | | | | 11 | 1 |
| | | 1 | | 11 | | 1 |
|   1 1 1
| 1   1 1
| 1 1
| 1 1 1
| 1 1 1 1
1 |1 1 |1 1 |1 1 |1
|1 1 11 |
The blockmodels
AE E EH LM S I A N T P YI C BC JS F U US ---------------------------------------------------------------
 1 ALGERIA | | | | | | 1 | 1 1 | 1 | 7 EGYPT | | 1 | | | | 1 | 1 | 1 1 1 1 1 1 | ----------------------------------------------------------------- | | | | | | | | 1 1| ----------------------------------------------------------------- |||||||1|1| 10 HONDURAS | | | | | | | | 1 | ----------------------------------------------------------------- 14 LIBERIA | | | | | | | | | 15 MADAGASCAR | | | | | | | | 1 | 20 SYRIA | | | | | | | | | ----------------------------------------------------------------- | |1| | | 1 | 1 1 1 | | 11 1 1 11 | |1 | | 1 | | 1 | 1 1 1 | 1 1 | 1 1 1 1 1 | -----------------------------------------------------------------
 What if countries are partitioned at three levels?
8 6
ETHIOPIA
 ECUADOR
 |1 1 | 1 |1 1 | 1 |1 1 | 1 |1 1 | 1 |1 1 | 1 |1 1 |
|11 | 11 |11 | 11 |11 | |11 | 11 |11 | 11 |11 | 11
1| 1 1 1| 1 1 1| 1 1 1| 1 1| 1 1 1| 1 1
| 1 1 1 11 | 1 11 | | 1 1 1 11 | 1 11 | | 1 1 1 11 | 1 11 | | 1 1 1 11 | 1 11 | | 1 1 1 11 | 1 11 | | 1 1 1 11 | 1 11 |
  1 1 1 1
1   1 1 1
1 1   1 1
1 1 1   1
1 1 1 1
1 1 1 1 1
1 | 1 | 1 | 1 | 1 |
|
1
1
|1 11 1 |1 11 1 |1 11 1 |1 11
1 11 | 1 11 | 1 11 | 1 11 |
11 -----------------------------------------------------------------
| 11 |
| |
|
|1 1 | 1|11 1 | 1 | 1 1 1 11 |
|1 1 |
|1 1 |
|1 1 | -----------------------------------------------------------------
| 1 1|1 1 | 1 1 | 1 1 1 11 | 1 | 1 1|1 1 | 1 | 1 1 1 11 |
11 | 11 1 1 11 | 11 | 11 1 1 11 | 11 | 11 1 1 11 |
  Image matrix
 Three-level partition
 Further reduce our data by 0 if density within cell < 0.562;
 1 if density is >= 0.562
  Original Density Matrix 12345678
Image Matrix 12345678
----- -----
1 0.000 0.500
2 0.000
3 0.000 0.000
4 0.000 0.000
5 0.250 0.500
6 0.600 0.200
7 1.000 0.667
8 1.000 0.833
----- ----- ----- ----- ----- -----
0.000 0.000 0.000 0.200 0.500 0.583
0.000 0.000 0.000 0.000 0.000 0.333
0.000 0.000 0.000 0.000 0.167 0.167
0.000 0.000 0.000 0.000 0.000 0.056
0.250 0.000 1.000 0.600 0.333 0.917
0.000 0.267 0.300 0.950 0.600 0.933
0.833 0.778 0.667 1.000 1.000 1.000
1.000 0.889 0.917 1.000 1.000 1.000
    ----- -----
1   0.000 0.000
2   0.000
3   0.000 0.000
4   0.000 0.000
5   0.000 0.000
6   1.000 0.000
7   1.000 1.000
8   1.000 1.000
----- ----- ----- ----- ----- -----
0.000 0.000 0.000 0.000 0.000 1.000
0.000 0.000 0.000 0.000 0.000 0.000
0.000 0.000 0.000 0.000 0.000 0.000
0.000 0.000 0.000 0.000 0.000 0.000
0.000 0.000 1.000 1.000 0.000 1.000
0.000 0.000 0.000 1.000 1.000 1.000
1.000 1.000 1.000 1.000 1.000 1.000
1.000 1.000 1.000 1.000 1.000 1.000
  Image matrix
 Three-level partition
 Further reduce our data by 0 if density within cell < 0.562;
 1 if density is >= 0.562
  Image Matrix
 Same picture as before, but Blocks 8 and 7 = Block 4 from earlier; Blocks 6 and 5 are like Block 3 from earlier too
12345678 ----- ----- ----- ----- ----- ----- ----- -----
1   0.000 0.000 0.000 0.000 0.000 0.000 0.000 1.000
2   0.000       0.000 0.000 0.000 0.000 0.000 0.000
3   0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000
4   0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000
5 0.000 0.000 0.000 0.000 1.000 1.000 0.000 1.000 
6   1.000 0.000 0.000 0.000 0.000 1.000 1.000 1.000
7   1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000
8   1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000
Some blocks do send goods to Block 8 too
  Thoughts and conclusions ...
 Role ≠ group
 Common reactions can flow from common positions, not direct ties (active group membership)
 Parents, bosses, and the predominance of the “role”
 Really good for finding core-periphery patterns
 “The poor man’s X ...”
 
  Core-periphery in citations
Borgatti, Stephen P., and Martin G. Everett. "Models of core/periphery structures." Social networks 21.4 (2000): 375- 395.
  
  How to do this in R ...
library(statnet)
d=read.csv(file.choose())
dm=as.matrix(d)
net=network(dm,matrix.type="adjacency",directed=TRUE)
eq<-equiv.clust(net)
plot(eq)
b<-blockmodel(net,eq, h=30)
plot(b)
 
  2. “Non-people” social networks
  a. Words
  An example ...
 From a co-occurence, bipartite matrix of words from tweets
  An example ...
 From a co-occurence, bipartite matrix of words from tweets after Paul Ryan’s response to Obama’s 2011 State of the Union
  
  An example ...

  An example ...
 From a co-occurence, bipartite matrix of words that appear in the same verse in the King James Bible
  
  b. What travels over networks?
 An example ...
 Borgatti, Stephen P. "Centrality and network flow." Social networks 27.1 (2005): 55-71.
 
  c. Other instances?




 Social Network Analysis (Class 11)
  Gregory M. Eirich QMSS
  Agenda
1. Small worlds
2. Two-mode (or bipartite) networks
 
  1. Small worlds
  Of note ...
 I am borrowing heavily (and liberally) from:
Easley, David, and Jon Kleinberg. Networks, Crowds, and Markets: Reasoning about a highly connected world. (2012). Chapter 20.
 
  Small worlds
 When would I say and, why, that: “Isn’t it a small world?”
 
  Small worlds
 The idea of a small world in common usage is that you come across a seeming stranger, whom you actually “know” to some degree because you share something in common, usually a friend, but sometimes common background (same college, same city, etc.)
 What makes this a case of a “small world” is that there are so many people in the world whom I don’t know at all and would have no basis to know-- and it is so surprising to run into someone whom I almost know through a common connection
 
  The small world experiment
 Stanley Milgram asked randomly-selected people to send a letter along on the way to a specific person in a Boston suburb
 About a third of the letters made it to their target, typically in 6 steps from sender to receiver
 Hence-- “Six Degrees of Separation”
 
  Small world vs. big network
 Obviously, we need to look at big networks to be surprised how small they are
 No lawyers here!
 
  Features of the small world
 What did Milgram’s experiment teach us about large social networks? 1. Short paths exist in abundance
2. People, acting without any sort of global “map” of the network, are effective at collectively finding these short paths
 
  What is a path and what makes it short?
 A path is series of steps from one node to another, or the length of a path is the number of edges it contains
 “Short paths” doesn’t have a precise meaning, but it generally means that it is possible to get from one node to another node in only a few steps
 
  What is a path and what makes it short?
 A measure of the shortness of paths is based on “average distance,” which is the average, for each node, of how many steps it takes to get to each other node in the network
 Of course, when a network is not fully connected, we cannot exactly define the geodesic distances among all pairs. Then we can treat the geodesic distance between unconnected actors as a length greater than that of any real distance in the data.
 
  Diameter of a network
 As an aside: In contrast to average distance, researchers often calculate diameter, which is the largest geodesic distance in the (connected) network
 This gives an approximate sense of the width of a network: how many steps it takes to get across it from unfamiliar nodes
 
  What about search in the small
world?
 We will return to that issue shortly
 
  How abundant are short paths?
 Should we be surprised by the fact that the paths between seemingly arbitrary pairs of people are so short? Maybe not.
 Suppose you know on a first-name basis 100 other people
 Now, suppose each of your friends has at least 100 friends other than you-- so you could in principle be two steps away from over 100 · 100 = 10,000 people
 
   What about search in the small
world?
 We will return to that issue shortly
 
  How abundant are short paths?
 The 100 friends of these people brings us to more than 100 · 100 · 100 = 1,000,000 people who in principle could be three steps away
 In other words, the numbers are growing by powers of 100 with each step, bringing us to 100 million after four steps, and 10 billion after five steps
 But there is a problem with this way of thinking ...
 
  The problem -- Real networks
 The problem is that social networks are full of complete triads — sets of three people who mutually know each other
 So it is likely that many of your 100 friends will know each other. That means that those links are not going out to new friends, but to people you already know and who know others in your network too
 
   What about search in the small
world?
 We will return to that issue shortly
 
  The problem -- Real networks
 That initial number of 10,000 came from assuming that each of your 100 friends was linked to 100 new people
 Without this, the number of friends you could reach in two steps could be much smaller
 So the effect of triadic closure in social networks works to limit the number of people you can reach by following short paths
 
  The problem -- Too clustered?
 Many people intuitively think they live in a very narrow, clustered world, unable to reach the far away branches
 
  The Watts-Strogatz model
 Duncan Watts and Steve Strogatz built a simple model that exhibits both of the features we’ve been discussing: many closed triads, but also very short paths
 To build their model, they combined two other basic social-network ideas:
1. homophily (the principle that we connect to others who are like ourselves); and
2. weak ties (the links to acquaintances that connect us to parts of the network that would otherwise be far away)
 
  The Watts-Strogatz model
 Homophily creates many triangles, while the weak ties still produce the kind of widely branching structure that reaches many nodes in a few steps.
 
  The Watts-Strogatz model
 Take a network of nodes laid out in a grid, where closer nodes are “more alike.”
 Homophily is captured by having each node form a link to all other nodes that lie within a radius of up to r grid steps away, for some constant value of r: these are the links you form to people because you are similar to them.
 
  The Watts-Strogatz model
 Then, for some other constant value k, each node also forms a link to k other nodes selected uniformly at random from the grid — these correspond to weak ties, connecting nodes who lie very far apart on the grid.
 This is all that is necessary to make it possible to have short paths for all nodes on the graph
 
  The Watts-Strogatz model
 What’s more-- only a very small amount of randomness is necessary to make a highly clustered graph into a small world
 We can only allow one out of every k nodes to have a single random friend.
 This model with fewer random friends might correspond to a technologically earlier time, when most people only knew their near neighbors, and a few people knew someone far away.
 
  From a grid to a little randomness
   
  The clustering coefficient, CC
 How much do networks have very cohesive subgroups within them?
 That is what the clustering coefficient is meant to get at, but it is really just an average of each nodes neighborhood density (it can be unweighted or weighted by the size of the ego networks)
 Captures what percentage of triads in the network are closed
 Ranges from 0 to 1, then
 
  The clustering coefficient, CC
 How much do networks have very cohesive subgroups within them?
 That is what the (local) clustering coefficient is meant to get at, but it is really just an average of each nodes neighborhood density (it can be unweighted or weighted by the size of the ego networks)
 Captures what percentage of triads in the network are closed
 Ranges from 0 to 1, then
 Relationship to transitivity
 
  Remember: Average path length
 Average path length tells us whether on average, nodes can find each other in a few short steps or they will take many, many more
 
  Why do we care about small worlds?
  Small worlds and creativity
 Uzzi, Brian and Jarrett Spiro (2005). “Collaboration and Creativity: The Small World Problem.” American Journal of Sociology 111(2): 447-504.
 Guimerà, Roger, Brian Uzzi, Jarrett Spiro, and Luís A. Nunes Amaral (2005). “Team Assembly Mechanisms Determine Collaboration Network Structure and Team Performance.” Science 308(5722): 697-702.
 
  The question
 What features of the overall network environment are conducive to creativity?
 For Broadway musicals, do they have a better chance of success if they are operating in a milieu that is not such a small world or one that is a very small world?
 
  The small world of Broadway
 Broadway shows have a team made up of a composer, a lyricist, a librettist who writes the plot and dialogue, a choreographer, a director, and a producer.
 From show to show, some members of these teams will have worked together before and sometimes they will be new to each other
 If everyone is always working with new people, the world is not very small, but if everyone is always working with the same people, it is quite small
 
   The clustering coefficient
 How much do networks have very cohesive subgroups within them?
 That is what the clustering coefficient is meant to get at, but it is really just an average of each nodes neighborhood density (it can be unweighted or weighted by the size of the ego networks)
 Ranges from 0 to 1, then
 
  What is Q?
 Q is the small world quotient, or: Q= CC ratio/PL ratio
where each of these ratios is a measure of the actual measure over the “random” measure derived from a random graph
 
  The results
  There is a quadratic relationship of Q with success
  The results
  There is a quadratic relationship of Q with success
  Note well:
“Uzzi and Spiro found little or no relation between success and local measures, such as the extent to which team members had worked with each other on previous shows. The success or failure of a Broadway show had less to do with the relationships between the names in the Playbill than the shape of the broader network at the time the show was produced.”
-- Jordan Ellenberg. “Six Degrees of Innovation: What Broadway Musicals Tell Us About Creativity.” Slate.com (March 23, 2012)
 
  Small worlds and science creativity
 Ebadi, Ashkan, and Andrea Schiffauerova. "On the Relation between the Small World Structure and Scientific Activities." PloS one 10.3 (2015): e0121129.
 For Canadian scientists and engineers, their co-authorship network: Small world network is positively correlated with the quality of the articles in terms of both citation count and journal impact factor (no quadratic shape, though)
 
  Six degrees ...
  Six Degrees of Kevin Bacon
 Is Kevin Bacon at the center of Hollywood? Is he the most central actor in the modern history of films?
 Is Hollywood a big network to begin with? (1.5M actors in 1M+ films and TV shows) ... Why would we even think it would be hard to link Kevin Bacon to most other actors in a few steps?
 What started out as a joke and parlor game has become a science, of sorts
 
  Six Degrees of Kevin Bacon
 Is Kevin Bacon at the center of Hollywood?
 Is he the most central actor in the modern history of films?
 What started out as a joke and parlor game has become a science, of sorts
  
  Six Degrees of Kevin Bacon
 Is Kevin Bacon at the center of Hollywood?
 Is he the most central actor in the modern history of films?
 What started out as a joke and parlor game has become a science, of sorts
  
  Kevin Bacon
 Kevin Bacon is not the most linkable actor in Hollywood -- not even the top 100
 While always changing, Harvey Keitel and Donald Sutherland are among the most at the center
 
  Visualizing movie stars
 Is Kevin Bacon at the center of Hollywood?
 Is he the most central actor in the modern history of films?
 What started out as a joke and parlor game has become a science, of sorts
  
  Visualizing movie stars
 Is Kevin Bacon at the center of Hollywood?
 Is he the most central actor in the modern history of films?
 What started out as a joke and parlor game has become a science, of sorts
  
  Search in small worlds
  What about search in the small world?
 That there are short paths through the network doesn’t mean that we can find the shortest paths through the network ourselves, does it?
 
  What about search in the small world?
 “As a mathematical model, the Watts- Strogatz network is thus effective at capturing the density of triangles and the existence of short paths, but not the ability of people, working together in the network, to actually find the paths. Essentially, the problem is that the weak ties that make the world small are “too random” in this model: since they’re completely unrelated to the similarity among nodes that produces the homophily-based links, they’re hard for people to use reliably.”
 
  Search in the small world?
   That there are short paths through the network doesn’t mean that we can find the shortest paths through the network ourselves, does it?
  What about search in the small world?
 Kleinberg suggests adding in a “distance” parameter in the network, q, which gives a higher probability of linking to near nodes than far nodes (such that if q=0, then the links are too random, while if q>2, the world is too small and links don’t reach far enough away from the focal node)
 
  Search time in the small world?
 Delivery time is minimized when q=2
 When q = 2, long-range weak ties are being formed in a way that’s spread roughly uniformly over all different scales of resolution
  
  Search time in the small world?
 Analogy with the post office delivery mail based on pieces of the address
 
  Other related ideas
 Zipf’s law
 Power law
 “Nobody knows” in Hollywood
 80/20 rule
 Assortativity
 Cumulative advantage
 
  2. Two-mode (or bipartite) networks
  Who is Paul Revere?
  
  How he answered the question

   He uses the database collected by historian David Hackett
 Fischer on 254 men’s memberships in 7 different Boston
 organizations prior to the Revolutionary war.
   It looks like this (an adjacency 254x7 matrix):
 
  From two-mode to one-mode
 Healey turned a two-mode network into a one-mode network through matrix manipulation (from a person-group matrix into a person-person one)
 
  “Duality of persons and groups”
 With bipartite data, we can ask two questions (at least)”
1. Which groups are most like each other (by virtue of who attends)?
2. Which people are most like each other (by virtue of which groups they belong to)?
(It is just hard to ask both of those questions simultaneously)
 
  Southern ladies socializing
 Data from the events attended by a group of ladies in the South in the 1941
 Used here in:
Freeman, Linton C., and Douglas R. White. "Using Galois lattices to represent network data." Sociological methodology 23.127 (1993): 146+.
 
  Southern ladies socializing
 
  Southern ladies socializing
 
  Person-by-person network
Who bridges this group together?
From: Borgatti, Stephen P. "2-Mode concepts in social network analysis." Encyclopedia of complexity and system science (2009): 8279-8291.
  
  Event-by-event network
  What event bridges these events together?
  Can we show all this at once?
  Correspondence analysis
 
  Southern ladies socializing
 Correspondence analysis is a way to represent two types of categorical information (derived from cross-tabulations) in the same space, similar to PCA for continuous measures
 To learn more about CA, see this: http://gastonsanchez.com/blog/how- to/2012/07/19/Correspondence-Analysis.html
(From: Borgatti, Stephen P., and Martin G. Everett. "Network analysis of 2-mode data." Social networks 19.3 (1997): 243-269.)
 
  Another correspondence analysis
  From: http://www.r-bloggers. com/correspondence-analysis-in- r/
  Galois lattice of socializing
 
  Southern ladies socializing
 A lattice is a way to represent correspondence (or overlaps) relationships between two sets
 
  What do we see here?
  
  What do we see here?
 
  What do we see here?
 
  What do we see here?
 
  What do we see here?
  
  Some additional considerations
 The nature of what sort of interaction can be captured in two- mode data?
 Other examples
 
  Another example
  Person-by-candidate matrix
 
  Person-by-candidate matrix
 They asked Republicans to indicate all the candidates that they would be willing to vote for in their state’s primary or caucus. The also asked them to rank these candidates
 They then created a map of the Republican field based on what they call “shared supporters.” If a voter selected both Bush and Rubio in response to the first question, those two candidates are connected by at least one shared supporter. The more supporters two candidates share in common, the stronger the connection (or tie) between those candidates. This is represented in the graph below by wider and darker lines.
 
  Person-by-candidate matrix
 
  Republicans will take almost anyone
We do not find two clear clusters of “outsider” candidates and “establishment” candidates. We might expect Trump, Carson and Fiorina to have the same base of voters, while Bush and Rubio would have a different base of voters. But no.
  
  Exchanging voters
  How many voters would move from one candidate to another if their first choice dropped out?
Carson, Cruz, Trump, and Rubio are all tied together in the center of the plot. If any one of them were to drop out, most of their supporters would shift to another of the front-runners.
  Another example
  Pew poll on trust in media
From Valdis Krebs
    
  Re-envisioning that poll
  How many voters would move from one candidate to another if their first choice dropped out?
Carson, Cruz, Trump, and Rubio are all tied together in the center of the plot. If any one of them were to drop out, most of their
supporters would shift
  Re-envisioning the poll
From Krebs: * Conservative media sources are far fewer than the ones tinged various shades of blue and purple. * The red cluster is isolated form the rest of the media sources. * Communities of very similarly ranked news sources are all visually clustered in Figure 2 -- those sources in an obvious cluster are basically substitutable for each other.
  
  Re-envisioning that poll
From Krebs: * The largest nodes (those that received the highest trust rankings) are all purple -- The Economist, Wall Street Journal, BBC, and Google News. * More isolated yet, is Buzz Feed(tiny dot), which was ranked the lowest in trust, and did not have enough similarity in rankings to be connected to any other media source.
  
  Another example
 Why do I think of this as a bipartite graph?
 
  The question
 Why do I think of this as a bipartite graph? A “political-profile- by-source” graph
 


 Social Network Analysis (Class 14)
  Gregory M. Eirich QMSS
  Agenda
1. Network evolution
2. Network dynamics over time
 Selection vs. influence
 Diffusion = adoption = contagion = cascades
 
  1. Network evolution
  Network evolution
Answers questions, like --
 Who are most likely to form ties (or increase the value of those ties) with each other in time2, where they weren’t there in time1?
 Who are most likely to break ties with each other in time in time2, where they were there in time1?
 
  Network evolution
Who are most likely to form ties (or increase the value of those ties) with each other in time2, where they weren’t there in time1?
 
  Network evolution
Who are most likely to form ties (or increase the value of those ties) with each other in time2, where they weren’t there in time1?
 Most central nodes already will get more matches (“rich get richer”) - Assortivity
 Completing triangles
 Matching on attributes
 Placed in the same “group” by an algorithm
 
  Network evolution
Who are most likely to form ties (or increase the value of those ties) with each other in time2, where they weren’t there in time1?
 But let’s think more about time and how it changes relationships (low-hanging fruit vs. established patterns; long-run vs. short-run dynamics)
 
  Link prediction
D. Liben-Nowell and J. Kleinberg. The link prediction problem for social networks. In Proc. CIKM ’03, pages 556–559, 2003.
T. Murata and S. Moriyasu. Link prediction based on structural properties of online social networks. New Generation Comput., 26(3):245–257, 200
D. Corlette and F. M. Shipman, III. Link prediction applied to an open large-scale online social network. In Proceedings of the 21st ACM conference on Hypertext and hypermedia, HT ’10, 2010.
LINK PREDICTION IN SOCIAL NETWORKS. “Link Prediction.” Mohammad Al Hasan, Mohammed J. Zaki. At http://cs.iupui.edu/~alhasan/papers/SNDA11.pdf
 
  An example
Pittinsky, Matthew, and Thomas A. DiPrete. "Peer group ties and executive compensation networks." Social science research 42.6 (2013): 1675-1692.
 
   Another example
  Their question
 What makes a company choose another company as in its CEO’ s peer group?
 
   Another example
 What about who are most likely to break ties with each other in time in time2, where they were there in time1?
 
  What about this?
Answers questions, like --
 Who are most likely to break ties with each other in time in time2, where they were there in time1?
 
  Breaking ties
Kivran-Swaine, F., Govindan, P., & Naaman, M. (2011, May). The impact of network structure on breaking ties in online social networks: unfollowing on twitter. In Proceedings of the SIGCHI conference on human factors in computing systems (pp. 1101-1104). ACM.
 
  Network evolution
  Many attributes and structural properties affect the rate of unfollowing on Twitter
  Another example ...
 Remember from the midterm ...
 The data on the electronic communication project involving the 34 network scientists from Statistics, Sociology, Anthropology and Other departments
 In re-analysis of that data, Snijders finds that be-friending colleagues of the same discipline was most strong for Statistics and Mathematics, and less for the others
 
  An example ...
 Overall, density in the network went from .52 to .66 after 8 months of communicating
 But Snijders also finds that be-friending choices in every discipline, there was a tendency to choose the already highly popular scientists
 
  2. Network dynamics over time
  a. Selection vs. influence
  Selection
 People who share a similar behavior are more likely to form ties
 Homophily on some trait or attitude
 
  Influence
 People who form ties with each other influence each other’s subsequent behavior
 
  The problem
 We cannot separate selection from influence in the cross- section
 We need longitudinal data
 
  An example ...
  Facebook friendships
 Lewis, Kevin, Marco Gonzalez, and Jason Kaufman. "Social selection and peer influence in an online social network." Proceedings of the National Academy of Sciences 109.1 (2012): 68-72.
 Using a 4-year panel of 1,001 students who started as freshman at Harvard in 2006 until they graduated in 2010
 Looking at their Facebook information and friendships
 
  Facebook friending ...
 Proximity on campus and in studies is the biggest determinant of making and keeping friends at Harvard on Facebook
 Other homophilies help too
  
  What about cultural tastes?
  
  What about cultural tastes?
  
  Sorting things out
   Selection effects =
 tendency for a tie to
 develop between 2
 students who both
 express tastes in the
 given cluster

  Sorting things out
   Influence effects =
 measure the tendency
 for students whose
 friends express tastes
 in the given cluster to
 themselves adopt
 tastes in that cluster

  Methodology
 They used the RSiena program to look into this effect
 RSiena has some similarities with exponential random graph models, known as p* models
 It also incorporates agent-based decisions
 
   
Other evidence for influence
Two voting experiments:
Nickerson, David W. 2008. "Is Voting Contagious? Evidence from Two Field Experiments," American Political Science Review 102 (Feb):49-57. -- Involving members of a household, when only 1 answered the door
○ Bond, Robert M., et al. "A 61-million-person experiment in social influence and political mobilization." Nature 489.7415 (2012): 295-298. -- Facebook 61 million person experiment in 2010
  Bond, Robert M., et al. "A 61-million-person experiment in social influence and political mobilization." Nature 489.7415 (2012): 295-298. -- Facebook 61 million person experiment in 2011
 
  b. Network dynamics over time (Contagion=diffusion=cascades)
  The believers
 Christatis and Fowler find many health outcomes (and divorce) to be contagious, up to 2 or 3 degrees of separation
 
  Their study
 Christakis, Nicholas A., and James H. Fowler. "The spread of obesity in a large social network over 32 years." New England journal of medicine 357.4 (2007): 370-379.
 Obesity spreads across social networks, up to two degrees away; controls for lots of stuff and lags of obesity, too, for both ego and alter
 http://www.nejm.org/action/showMediaPlayer?doi=10.1056% 2FNEJMsa066082&aid=NEJMsa066082_attach_1&area=
   
  Their results
 
  Their argument against endogeneity
  
  The skeptics
 Cohen-Cole, Ethan, and Jason M. Fletcher. "Detecting implausible social network effects in acne, height, and headaches: longitudinal analysis." BMJ: British Medical Journal 337 (2008).
 
  Their results
 
  Why is friend’s heightt-1 negative?
 From Christakos and Fowler: “The coefficient for alter obesity at t is negative. Given the fact that the models also control for alter obesity at t+1 and for ego obesity at t and t+1, this may be interpreted as a tendency for heterophily, or the tendency of egos to nominate alters who are not of the same obesity status as egos (the “Laurel and Hardy” effect); models of familial ties tend not to have any negative coefficients, as would be expected. As shown in Table S3, there is no evidence for heterophily among friends when it comes to smoking behavior.”
 
  Their results
 Cohen-Cole, Ethan, and Jason M. Fletcher. "Detecting implausible social network effects in acne, height, and headaches: longitudinal analysis." BMJ: British Medical Journal 337 (2008).
  
  Models for diffusion
(as outlined in Carolan, Brian. 2010. Social Network Analysis and Education. Sage.)
  Model 1 for diffusion
 Opinion (highly central) leaders
 
  Remember?
Watts, Duncan J., and Peter Sheridan Dodds. "Influentials, networks, and public opinion formation." Journal of consumer research 34.4 (2007): 441-458.
   
 The classic “two-step” model
of diffusion
It looks like this ...
   
  Model 2 for diffusion
 Structural opportunities
(Structural holes, density, and small-worldliness)
 
  Model 3 for diffusion
 Threshold (or critical level) models (I.e., Tipping points)
 
  Model 4 for diffusion
 Network exposure, dynamic models
 
  Diffusion ...
Rossman, Gabriel. "The Diffusion of the Legitimate and the Diffusion of Legitimacy." Sociological Science 1 (2014): 46-69.
 
  Legitimate vs. illegitimate categories
 
  “Exogenous” diffusion
 
  “Endogenous” diffusion
 



